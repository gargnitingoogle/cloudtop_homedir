
  Mem[||||||||||||||||||||||||||||||                                 11.8G/189G] Tasks: 249, 4228 thr, 489 kthr; 2 running                                      
  Swp[                                                                 0K/1.86G] Load average: 1.16 1.39 1.10                                                    
  Avg[|||                                                          2.6% 2249MHz] Uptime: 11 days, 03:27:18                                                       

  Mem[||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||                                                                23.2G/189G] Tasks: 279, 5111 thr, 493 kthr; 1 running                                                                                                               
  Swp[                                                                                                                                          0K/1.86G] Load average: 1.61 1.28 1.31 
  Avg[||||                                                                                                                                  1.5% 2249MHz] Uptime: 13 days, 07:51:17
  Disk IO: 1.5% read: 0KiB/s write: 167KiB/s                                                                                                                                                                                                                                                                      

gargnitin@gargnitin:~$ bash
htop -gargnitin@gargnitin:~$ htop -F gcsfuse
gargnitin@gargnitin:~$ htop -F gcsfuse
gargnitin@gargnitin:~$ htop -F gcsfuse
gargnitin@gargnitin:~$ htop -F gcsfuse
gargnitin@gargnitin:~$ cd ~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ ls
config.yml  creationSituation.sh  go.work  go.work.sum
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ ls
config.yml  creationSituation.sh  go.work  go.work.sum
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ declare -x bucket="gargnitin-test-empty-dirname-asia-se1"
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ declare -x logfile="/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log"
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ declare -x mountpath="/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4"
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ ./creationSituation.sh 1 debug
+ echo Number of args: 2
Number of args: 2
+ debug=0
+ run=1
+ '[' 2 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 2 -gt 1 ']'
+ debug=1
+ '[' 1 -ne 0 ']'
+ echo 'Debugging ...'
Debugging ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 1 = 0 ']'
+ dlv debug --check-go-version=false /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/. -- --config-file=config.yml --foreground --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
WARNING: undefined behavior - Go version go0.0 is too old for this version of Delve (minimum supported version 1.19)
Type 'help' for list of commands.
(dlv) r
Process restarted with PID 1661476
(dlv) c
{"timestamp":{"seconds":1714654249,"nanos":556136578},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
received SIGINT, stopping process (will not forward signal)
> internal/runtime/syscall.Syscall6() /usr/lib/google-golang/src/internal/runtime/syscall/asm_linux_amd64.s:36 (PC: 0x4881ce)
Warning: debugging optimized function
    31:         MOVQ    DI, DX  // a3
    32:         MOVQ    CX, SI  // a2
    33:         MOVQ    BX, DI  // a1
    34:         // num already in AX.
    35:         SYSCALL
=>  36:         CMPQ    AX, $0xfffffffffffff001
    37:         JLS     ok
    38:         NEGQ    AX
    39:         MOVQ    AX, CX  // errno
    40:         MOVQ    $-1, AX // r1
    41:         MOVQ    $0, BX  // r2
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284
Breakpoint 1 set at 0x188deea for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286
Breakpoint 2 set at 0x188dfb9 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290
Breakpoint 3 set at 0x188e0cb for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293
Breakpoint 4 set at 0x188e194 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293 at 188e194
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293 (hits goroutine(388):1 total:1) (PC: 0x188e194)
   288:                 } else {
   289:                         if util.IsUnsupportedObjectName(attrs.Name) {
   290:                                 logger.Warnf("Ignoring unsupported object-name: \"%s\"", attrs.Name)
   291:                         } else {
   292:                                 // Converting attrs to *Object type.
=> 293:                                 currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   294:                                 list.Objects = append(list.Objects, currObject)
   295:                         }
   296:                 }
   297:
   298:                 // itr.next returns all the objects present in the bucket. Hence adding a
(dlv) p attrs.Name
"14"
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284 (hits goroutine(388):1 total:1) (PC: 0x188deea)
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
=> 284:                                 logger.Warnf("Ignoring unsupported directory-name: \"%s\"", attrs.Prefix)
   285:                         } else {
   286:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   287:                         }
   288:                 } else {
   289:                         if util.IsUnsupportedObjectName(attrs.Name) {
(dlv) p attrs.Prefix
"../"
(dlv) c 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284 (hits goroutine(388):2 total:2) (PC: 0x188deea)
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
=> 284:                                 logger.Warnf("Ignoring unsupported directory-name: \"%s\"", attrs.Prefix)
   285:                         } else {
   286:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   287:                         }
   288:                 } else {
   289:                         if util.IsUnsupportedObjectName(attrs.Name) {
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284 (hits goroutine(388):3 total:3) (PC: 0x188deea)
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
=> 284:                                 logger.Warnf("Ignoring unsupported directory-name: \"%s\"", attrs.Prefix)
   285:                         } else {
   286:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   287:                         }
   288:                 } else {
   289:                         if util.IsUnsupportedObjectName(attrs.Name) {
(dlv) p attrs.Prefix
"/"
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286 (hits goroutine(388):1 total:1) (PC: 0x188dfb9)
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 logger.Warnf("Ignoring unsupported directory-name: \"%s\"", attrs.Prefix)
   285:                         } else {
=> 286:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   287:                         }
   288:                 } else {
   289:                         if util.IsUnsupportedObjectName(attrs.Name) {
   290:                                 logger.Warnf("Ignoring unsupported object-name: \"%s\"", attrs.Name)
   291:                         } else {
(dlv) p attrs.Prefix
"a/"
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*debugBucket).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/debug_bucket.go:205 (PC: 0x189259d)
Values returned:
        listing: ("*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing")(0xc0008ebb00)
*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing {
                Objects: []*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object len: 1, cap: 1, [
                        *(*"github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object")(0xc0009ac640),
                ],
                CollapsedRuns: []string len: 1, cap: 1, ["a/"],
                ContinuationToken: "",}
        err: error nil

   200:         ctx context.Context,
   201:         req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   202:         id, desc, start := b.startRequest("ListObjects(%q)", req.Prefix)
   203:         defer b.finishRequest(id, desc, start, &err)
   204:
=> 205:         listing, err = b.wrapped.ListObjects(ctx, req)
   206:         return
   207: }
   208:
   209: func (b *debugBucket) UpdateObject(
   210:         ctx context.Context,
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*debugBucket).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/debug_bucket.go:206 (PC: 0x1892625)
   201:         req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   202:         id, desc, start := b.startRequest("ListObjects(%q)", req.Prefix)
   203:         defer b.finishRequest(id, desc, start, &err)
   204:
   205:         listing, err = b.wrapped.ListObjects(ctx, req)
=> 206:         return
   207: }
   208:
   209: func (b *debugBucket) UpdateObject(
   210:         ctx context.Context,
   211:         req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
(dlv) p listing.Objects
[]*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object len: 1, cap: 1, [
        *{
                Name: "14",
                ContentType: "text/plain",
                ContentLanguage: "",
                CacheControl: "",
                Owner: "",
                Size: 6,
                ContentEncoding: "",
                MD5: *[16]uint8 [177,148,106,201,36,146,210,52,124,98,53,180,210,97,17,132],
                CRC32C: *893245630,
                MediaLink: "https://storage.googleapis.com/download/storage/v1/b/gargnitin-t...+69 more",
                Metadata: map[string]string nil,
                Generation: 1714642904966145,
                MetaGeneration: 1,
                StorageClass: "STANDARD",
                Deleted: (*time.Time)(0xc0009ac6f0),
                Updated: (*time.Time)(0xc0009ac708),
                ComponentCount: 0,
                ContentDisposition: "",
                CustomTime: "0001-01-01T00:00:00Z",
                EventBasedHold: false,
                Acl: []*google.golang.org/api/storage/v1.ObjectAccessControl len: 0, cap: 0, nil,},
]
(dlv) p listing        
("*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing")(0xc0008ebb00)
*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing {
        Objects: []*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object len: 1, cap: 1, [
                *(*"github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object")(0xc0009ac640),
        ],
        CollapsedRuns: []string len: 1, cap: 1, ["a/"],
        ContinuationToken: "",}
(dlv) p listing.CollapsedRuns
[]string len: 1, cap: 1, ["a/"]
(dlv) l
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*debugBucket).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/debug_bucket.go:206 (PC: 0x1892625)
   201:         req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   202:         id, desc, start := b.startRequest("ListObjects(%q)", req.Prefix)
   203:         defer b.finishRequest(id, desc, start, &err)
   204:
   205:         listing, err = b.wrapped.ListObjects(ctx, req)
=> 206:         return
   207: }
   208:
   209: func (b *debugBucket) UpdateObject(
   210:         ctx context.Context,
   211:         req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:559 (PC: 0x18e4dd3)
Values returned:
        ~r0: ("*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing")(0xc0008ebb00)
*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing {
                Objects: []*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object len: 1, cap: 1, [
                        *(*"github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object")(0xc0009ac640),
                ],
                CollapsedRuns: []string len: 1, cap: 1, ["a/"],
                ContinuationToken: "",}
        ~r1: error nil

   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
=> 559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:560 (PC: 0x18e4e4b)
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
=> 560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
(dlv) p listing.objects
Command failed: listing has no member objects
(dlv) p listing        
("*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing")(0xc0008ebb00)
*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing {
        Objects: []*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object len: 1, cap: 1, [
                *(*"github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object")(0xc0009ac640),
        ],
        CollapsedRuns: []string len: 1, cap: 1, ["a/"],
        ContinuationToken: "",}
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:632 (PC: 0x18e5e45)
Values returned:
        cores: map[github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Name]*github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Core [
                {bucketName: "", objectName: "14"}: *{
                        FullName: (*"github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Name")(0xc000cb2000),
                        Bucket: *(*"github.com/googlecloudplatform/gcsfuse/v2/internal/gcsx.SyncerBucket")(0xc000836620),
                        MinObject: *(*"github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.MinObject")(0xc000cb0000),
                        Local: false,}, 
                {bucketName: "", objectName: "a/"}: *{
                        FullName: (*"github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Name")(0xc000cb2040),
                        Bucket: *(*"github.com/googlecloudplatform/gcsfuse/v2/internal/gcsx.SyncerBucket")(0xc000836620),
                        MinObject: *github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.MinObject nil,
                        Local: false,}, 
        ]
        newTok: ""
        err: error nil

   627:
   628: func (d *dirInode) ReadEntries(
   629:         ctx context.Context,
   630:         tok string) (entries []fuseutil.Dirent, newTok string, err error) {
   631:         var cores map[Name]*Core
=> 632:         cores, newTok, err = d.readObjects(ctx, tok)
   633:         if err != nil {
   634:                 err = fmt.Errorf("read objects: %w", err)
   635:                 return
   636:         }
   637:
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:633 (PC: 0x18e5f07)
   628: func (d *dirInode) ReadEntries(
   629:         ctx context.Context,
   630:         tok string) (entries []fuseutil.Dirent, newTok string, err error) {
   631:         var cores map[Name]*Core
   632:         cores, newTok, err = d.readObjects(ctx, tok)
=> 633:         if err != nil {
   634:                 err = fmt.Errorf("read objects: %w", err)
   635:                 return
   636:         }
   637:
   638:         for fullName, core := range cores {
(dlv) p cores
map[github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Name]*github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Core [
        {bucketName: "", objectName: "14"}: *{
                FullName: (*"github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Name")(0xc000cb2000),
                Bucket: *(*"github.com/googlecloudplatform/gcsfuse/v2/internal/gcsx.SyncerBucket")(0xc000836620),
                MinObject: *(*"github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.MinObject")(0xc000cb0000),
                Local: false,}, 
        {bucketName: "", objectName: "a/"}: *{
                FullName: (*"github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Name")(0xc000cb2040),
                Bucket: *(*"github.com/googlecloudplatform/gcsfuse/v2/internal/gcsx.SyncerBucket")(0xc000836620),
                MinObject: *github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.MinObject nil,
                Local: false,}, 
]
(dlv) l
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:633 (PC: 0x18e5f07)
   628: func (d *dirInode) ReadEntries(
   629:         ctx context.Context,
   630:         tok string) (entries []fuseutil.Dirent, newTok string, err error) {
   631:         var cores map[Name]*Core
   632:         cores, newTok, err = d.readObjects(ctx, tok)
=> 633:         if err != nil {
   634:                 err = fmt.Errorf("read objects: %w", err)
   635:                 return
   636:         }
   637:
   638:         for fullName, core := range cores {
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:638 (PC: 0x18e6044)
   633:         if err != nil {
   634:                 err = fmt.Errorf("read objects: %w", err)
   635:                 return
   636:         }
   637:
=> 638:         for fullName, core := range cores {
   639:                 entry := fuseutil.Dirent{
   640:                         Name: path.Base(fullName.LocalName()),
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
   643:                 switch core.Type() {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:640 (PC: 0x18e60f0)
   635:                 return
   636:         }
   637:
   638:         for fullName, core := range cores {
   639:                 entry := fuseutil.Dirent{
=> 640:                         Name: path.Base(fullName.LocalName()),
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
   643:                 switch core.Type() {
   644:                 case metadata.SymlinkType:
   645:                         entry.Type = fuseutil.DT_Link
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:639 (PC: 0x18e6137)
   634:                 err = fmt.Errorf("read objects: %w", err)
   635:                 return
   636:         }
   637:
   638:         for fullName, core := range cores {
=> 639:                 entry := fuseutil.Dirent{
   640:                         Name: path.Base(fullName.LocalName()),
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
   643:                 switch core.Type() {
   644:                 case metadata.SymlinkType:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:640 (PC: 0x18e6152)
   635:                 return
   636:         }
   637:
   638:         for fullName, core := range cores {
   639:                 entry := fuseutil.Dirent{
=> 640:                         Name: path.Base(fullName.LocalName()),
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
   643:                 switch core.Type() {
   644:                 case metadata.SymlinkType:
   645:                         entry.Type = fuseutil.DT_Link
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:643 (PC: 0x18e6172)
   638:         for fullName, core := range cores {
   639:                 entry := fuseutil.Dirent{
   640:                         Name: path.Base(fullName.LocalName()),
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
=> 643:                 switch core.Type() {
   644:                 case metadata.SymlinkType:
   645:                         entry.Type = fuseutil.DT_Link
   646:                 case metadata.RegularFileType:
   647:                         entry.Type = fuseutil.DT_File
   648:                 case metadata.ImplicitDirType, metadata.ExplicitDirType:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:644 (PC: 0x18e6189)
   639:                 entry := fuseutil.Dirent{
   640:                         Name: path.Base(fullName.LocalName()),
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
   643:                 switch core.Type() {
=> 644:                 case metadata.SymlinkType:
   645:                         entry.Type = fuseutil.DT_Link
   646:                 case metadata.RegularFileType:
   647:                         entry.Type = fuseutil.DT_File
   648:                 case metadata.ImplicitDirType, metadata.ExplicitDirType:
   649:                         entry.Type = fuseutil.DT_Directory
(dlv) p core
("*github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Core")(0xc000cb2040)
*github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Core {
        FullName: github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Name {bucketName: "", objectName: "a/"},
        Bucket: *github.com/googlecloudplatform/gcsfuse/v2/internal/gcsx.SyncerBucket {
                Bucket: (unreadable invalid interface type),
                Syncer: (unreadable invalid interface type),},
        MinObject: *github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.MinObject nil,
        Local: false,}
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:646 (PC: 0x18e61a2)
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
   643:                 switch core.Type() {
   644:                 case metadata.SymlinkType:
   645:                         entry.Type = fuseutil.DT_Link
=> 646:                 case metadata.RegularFileType:
   647:                         entry.Type = fuseutil.DT_File
   648:                 case metadata.ImplicitDirType, metadata.ExplicitDirType:
   649:                         entry.Type = fuseutil.DT_Directory
   650:                 }
   651:                 entries = append(entries, entry)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:648 (PC: 0x18e61b9)
   643:                 switch core.Type() {
   644:                 case metadata.SymlinkType:
   645:                         entry.Type = fuseutil.DT_Link
   646:                 case metadata.RegularFileType:
   647:                         entry.Type = fuseutil.DT_File
=> 648:                 case metadata.ImplicitDirType, metadata.ExplicitDirType:
   649:                         entry.Type = fuseutil.DT_Directory
   650:                 }
   651:                 entries = append(entries, entry)
   652:         }
   653:         return
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:649 (PC: 0x18e61cc)
   644:                 case metadata.SymlinkType:
   645:                         entry.Type = fuseutil.DT_Link
   646:                 case metadata.RegularFileType:
   647:                         entry.Type = fuseutil.DT_File
   648:                 case metadata.ImplicitDirType, metadata.ExplicitDirType:
=> 649:                         entry.Type = fuseutil.DT_Directory
   650:                 }
   651:                 entries = append(entries, entry)
   652:         }
   653:         return
   654: }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:651 (PC: 0x18e61e4)
   646:                 case metadata.RegularFileType:
   647:                         entry.Type = fuseutil.DT_File
   648:                 case metadata.ImplicitDirType, metadata.ExplicitDirType:
   649:                         entry.Type = fuseutil.DT_Directory
   650:                 }
=> 651:                 entries = append(entries, entry)
   652:         }
   653:         return
   654: }
   655:
   656: // LOCKS_REQUIRED(d)
(dlv) p entries
[]github.com/jacobsa/fuse/fuseutil.Dirent len: 0, cap: 0, nil
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:638 (PC: 0x18e62d0)
   633:         if err != nil {
   634:                 err = fmt.Errorf("read objects: %w", err)
   635:                 return
   636:         }
   637:
=> 638:         for fullName, core := range cores {
   639:                 entry := fuseutil.Dirent{
   640:                         Name: path.Base(fullName.LocalName()),
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
   643:                 switch core.Type() {
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:640 (PC: 0x18e60f0)
   635:                 return
   636:         }
   637:
   638:         for fullName, core := range cores {
   639:                 entry := fuseutil.Dirent{
=> 640:                         Name: path.Base(fullName.LocalName()),
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
   643:                 switch core.Type() {
   644:                 case metadata.SymlinkType:
   645:                         entry.Type = fuseutil.DT_Link
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:639 (PC: 0x18e6137)
   634:                 err = fmt.Errorf("read objects: %w", err)
   635:                 return
   636:         }
   637:
   638:         for fullName, core := range cores {
=> 639:                 entry := fuseutil.Dirent{
   640:                         Name: path.Base(fullName.LocalName()),
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
   643:                 switch core.Type() {
   644:                 case metadata.SymlinkType:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:640 (PC: 0x18e6152)
   635:                 return
   636:         }
   637:
   638:         for fullName, core := range cores {
   639:                 entry := fuseutil.Dirent{
=> 640:                         Name: path.Base(fullName.LocalName()),
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
   643:                 switch core.Type() {
   644:                 case metadata.SymlinkType:
   645:                         entry.Type = fuseutil.DT_Link
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:643 (PC: 0x18e6172)
   638:         for fullName, core := range cores {
   639:                 entry := fuseutil.Dirent{
   640:                         Name: path.Base(fullName.LocalName()),
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
=> 643:                 switch core.Type() {
   644:                 case metadata.SymlinkType:
   645:                         entry.Type = fuseutil.DT_Link
   646:                 case metadata.RegularFileType:
   647:                         entry.Type = fuseutil.DT_File
   648:                 case metadata.ImplicitDirType, metadata.ExplicitDirType:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:644 (PC: 0x18e6189)
   639:                 entry := fuseutil.Dirent{
   640:                         Name: path.Base(fullName.LocalName()),
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
   643:                 switch core.Type() {
=> 644:                 case metadata.SymlinkType:
   645:                         entry.Type = fuseutil.DT_Link
   646:                 case metadata.RegularFileType:
   647:                         entry.Type = fuseutil.DT_File
   648:                 case metadata.ImplicitDirType, metadata.ExplicitDirType:
   649:                         entry.Type = fuseutil.DT_Directory
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:646 (PC: 0x18e61a2)
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
   643:                 switch core.Type() {
   644:                 case metadata.SymlinkType:
   645:                         entry.Type = fuseutil.DT_Link
=> 646:                 case metadata.RegularFileType:
   647:                         entry.Type = fuseutil.DT_File
   648:                 case metadata.ImplicitDirType, metadata.ExplicitDirType:
   649:                         entry.Type = fuseutil.DT_Directory
   650:                 }
   651:                 entries = append(entries, entry)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:647 (PC: 0x18e61ac)
   642:                 }
   643:                 switch core.Type() {
   644:                 case metadata.SymlinkType:
   645:                         entry.Type = fuseutil.DT_Link
   646:                 case metadata.RegularFileType:
=> 647:                         entry.Type = fuseutil.DT_File
   648:                 case metadata.ImplicitDirType, metadata.ExplicitDirType:
   649:                         entry.Type = fuseutil.DT_Directory
   650:                 }
   651:                 entries = append(entries, entry)
   652:         }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:651 (PC: 0x18e61e4)
   646:                 case metadata.RegularFileType:
   647:                         entry.Type = fuseutil.DT_File
   648:                 case metadata.ImplicitDirType, metadata.ExplicitDirType:
   649:                         entry.Type = fuseutil.DT_Directory
   650:                 }
=> 651:                 entries = append(entries, entry)
   652:         }
   653:         return
   654: }
   655:
   656: // LOCKS_REQUIRED(d)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:638 (PC: 0x18e62d0)
   633:         if err != nil {
   634:                 err = fmt.Errorf("read objects: %w", err)
   635:                 return
   636:         }
   637:
=> 638:         for fullName, core := range cores {
   639:                 entry := fuseutil.Dirent{
   640:                         Name: path.Base(fullName.LocalName()),
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
   643:                 switch core.Type() {
(dlv) p entries
[]github.com/jacobsa/fuse/fuseutil.Dirent len: 2, cap: 2, [
        {Offset: 0, Inode: 0, Name: "a", Type: DT_Directory (4)},
        {Offset: 0, Inode: 0, Name: "14", Type: DT_File (8)},
]
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:653 (PC: 0x18e62e5)
   648:                 case metadata.ImplicitDirType, metadata.ExplicitDirType:
   649:                         entry.Type = fuseutil.DT_Directory
   650:                 }
   651:                 entries = append(entries, entry)
   652:         }
=> 653:         return
   654: }
   655:
   656: // LOCKS_REQUIRED(d)
   657: func (d *dirInode) CreateChildFile(ctx context.Context, name string) (*Core, error) {
   658:         childMetadata := map[string]string{
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:172 (PC: 0x18f332b)
Values returned:
        entries: []github.com/jacobsa/fuse/fuseutil.Dirent len: 2, cap: 2, [
                {Offset: 0, Inode: 0, Name: "a", Type: DT_Directory (4)},
                {Offset: 0, Inode: 0, Name: "14", Type: DT_File (8)},
        ]
        newTok: ""
        err: error nil

   167:         var tok string
   168:         for {
   169:                 // Read a batch.
   170:                 var batch []fuseutil.Dirent
   171:
=> 172:                 batch, tok, err = in.ReadEntries(ctx, tok)
   173:                 if err != nil {
   174:                         err = fmt.Errorf("ReadEntries: %w", err)
   175:                         return
   176:                 }
   177:
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:173 (PC: 0x18f3437)
   168:         for {
   169:                 // Read a batch.
   170:                 var batch []fuseutil.Dirent
   171:
   172:                 batch, tok, err = in.ReadEntries(ctx, tok)
=> 173:                 if err != nil {
   174:                         err = fmt.Errorf("ReadEntries: %w", err)
   175:                         return
   176:                 }
   177:
   178:                 // Accumulate.
(dlv) p batch
[]github.com/jacobsa/fuse/fuseutil.Dirent len: 2, cap: 2, [
        {Offset: 0, Inode: 0, Name: "a", Type: DT_Directory (4)},
        {Offset: 0, Inode: 0, Name: "14", Type: DT_File (8)},
]
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:179 (PC: 0x18f3562)
   174:                         err = fmt.Errorf("ReadEntries: %w", err)
   175:                         return
   176:                 }
   177:
   178:                 // Accumulate.
=> 179:                 entries = append(entries, batch...)
   180:
   181:                 // Are we done?
   182:                 if tok == "" {
   183:                         break
   184:                 }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:188 (PC: 0x18f366e)
   183:                         break
   184:                 }
   185:         }
   186:
   187:         // Append local file entries (not synced to GCS).
=> 188:         entries = append(entries, localEntries...)
   189:
   190:         // Ensure that the entries are sorted, for use in fixConflictingNames
   191:         // below.
   192:         sort.Sort(sortedDirents(entries))
   193:
(dlv) n        
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:182 (PC: 0x18f368e)
   177:
   178:                 // Accumulate.
   179:                 entries = append(entries, batch...)
   180:
   181:                 // Are we done?
=> 182:                 if tok == "" {
   183:                         break
   184:                 }
   185:         }
   186:
   187:         // Append local file entries (not synced to GCS).
(dlv) p entries
[]github.com/jacobsa/fuse/fuseutil.Dirent len: 2, cap: 2, [
        {Offset: 0, Inode: 0, Name: "a", Type: DT_Directory (4)},
        {Offset: 0, Inode: 0, Name: "14", Type: DT_File (8)},
]
(dlv) p tok
""
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:183 (PC: 0x18f369b)
   178:                 // Accumulate.
   179:                 entries = append(entries, batch...)
   180:
   181:                 // Are we done?
   182:                 if tok == "" {
=> 183:                         break
   184:                 }
   185:         }
   186:
   187:         // Append local file entries (not synced to GCS).
   188:         entries = append(entries, localEntries...)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:188 (PC: 0x18f369d)
   183:                         break
   184:                 }
   185:         }
   186:
   187:         // Append local file entries (not synced to GCS).
=> 188:         entries = append(entries, localEntries...)
   189:
   190:         // Ensure that the entries are sorted, for use in fixConflictingNames
   191:         // below.
   192:         sort.Sort(sortedDirents(entries))
   193:
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:192 (PC: 0x18f37a6)
   187:         // Append local file entries (not synced to GCS).
   188:         entries = append(entries, localEntries...)
   189:
   190:         // Ensure that the entries are sorted, for use in fixConflictingNames
   191:         // below.
=> 192:         sort.Sort(sortedDirents(entries))
   193:
   194:         // Fix name conflicts.
   195:         // When a local file is synced to GCS but not removed from the local file map,
   196:         // the entries list will have two duplicate entries.
   197:         // To handle this scenario, we had 2 options:
(dlv) p entries
[]github.com/jacobsa/fuse/fuseutil.Dirent len: 2, cap: 2, [
        {Offset: 0, Inode: 0, Name: "a", Type: DT_Directory (4)},
        {Offset: 0, Inode: 0, Name: "14", Type: DT_File (8)},
]
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:206 (PC: 0x18f37c5)
   201:         // Option 2: [Not Selected]
   202:         // Restrict fixConflictingNames to only GCS entries and show duplicate
   203:         // entries when ReadDir is called. In this case, a local file can have
   204:         // same name as directory and LookUpInode call will fetch directory details
   205:         // for both of them.
=> 206:         err = fixConflictingNames(entries)
   207:         if err != nil {
   208:                 err = fmt.Errorf("fixConflictingNames: %w", err)
   209:                 return
   210:         }
   211:
(dlv) p entries
[]github.com/jacobsa/fuse/fuseutil.Dirent len: 2, cap: 2, [
        {Offset: 0, Inode: 0, Name: "14", Type: DT_File (8)},
        {Offset: 0, Inode: 0, Name: "a", Type: DT_Directory (4)},
]
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:207 (PC: 0x18f37ef)
   202:         // Restrict fixConflictingNames to only GCS entries and show duplicate
   203:         // entries when ReadDir is called. In this case, a local file can have
   204:         // same name as directory and LookUpInode call will fetch directory details
   205:         // for both of them.
   206:         err = fixConflictingNames(entries)
=> 207:         if err != nil {
   208:                 err = fmt.Errorf("fixConflictingNames: %w", err)
   209:                 return
   210:         }
   211:
   212:         // Fix up offset fields.
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:213 (PC: 0x18f391c)
   208:                 err = fmt.Errorf("fixConflictingNames: %w", err)
   209:                 return
   210:         }
   211:
   212:         // Fix up offset fields.
=> 213:         for i := 0; i < len(entries); i++ {
   214:                 entries[i].Offset = fuseops.DirOffset(i) + 1
   215:         }
   216:
   217:         // Return a bogus inode ID for each entry, but not the root inode ID.
   218:         //
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:214 (PC: 0x18f3949)
   209:                 return
   210:         }
   211:
   212:         // Fix up offset fields.
   213:         for i := 0; i < len(entries); i++ {
=> 214:                 entries[i].Offset = fuseops.DirOffset(i) + 1
   215:         }
   216:
   217:         // Return a bogus inode ID for each entry, but not the root inode ID.
   218:         //
   219:         // NOTE: As far as I can tell this is harmless. Minting and
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:213 (PC: 0x18f397d)
   208:                 err = fmt.Errorf("fixConflictingNames: %w", err)
   209:                 return
   210:         }
   211:
   212:         // Fix up offset fields.
=> 213:         for i := 0; i < len(entries); i++ {
   214:                 entries[i].Offset = fuseops.DirOffset(i) + 1
   215:         }
   216:
   217:         // Return a bogus inode ID for each entry, but not the root inode ID.
   218:         //
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:214 (PC: 0x18f3949)
   209:                 return
   210:         }
   211:
   212:         // Fix up offset fields.
   213:         for i := 0; i < len(entries); i++ {
=> 214:                 entries[i].Offset = fuseops.DirOffset(i) + 1
   215:         }
   216:
   217:         // Return a bogus inode ID for each entry, but not the root inode ID.
   218:         //
   219:         // NOTE: As far as I can tell this is harmless. Minting and
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:213 (PC: 0x18f397d)
   208:                 err = fmt.Errorf("fixConflictingNames: %w", err)
   209:                 return
   210:         }
   211:
   212:         // Fix up offset fields.
=> 213:         for i := 0; i < len(entries); i++ {
   214:                 entries[i].Offset = fuseops.DirOffset(i) + 1
   215:         }
   216:
   217:         // Return a bogus inode ID for each entry, but not the root inode ID.
   218:         //
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:230 (PC: 0x18f3984)
   225:         // If it turns out this is not harmless, we'll need to switch to something
   226:         // like inode IDs based on (object name, generation) hashes. But then what
   227:         // about the birthday problem? And more importantly, what about our
   228:         // semantic of not minting a new inode ID when the generation changes due
   229:         // to a local action?
=> 230:         for i := range entries {
   231:                 entries[i].Inode = fuseops.RootInodeID + 1
   232:         }
   233:
   234:         return
   235: }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:231 (PC: 0x18f39b4)
   226:         // like inode IDs based on (object name, generation) hashes. But then what
   227:         // about the birthday problem? And more importantly, what about our
   228:         // semantic of not minting a new inode ID when the generation changes due
   229:         // to a local action?
   230:         for i := range entries {
=> 231:                 entries[i].Inode = fuseops.RootInodeID + 1
   232:         }
   233:
   234:         return
   235: }
   236:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:230 (PC: 0x18f39e2)
   225:         // If it turns out this is not harmless, we'll need to switch to something
   226:         // like inode IDs based on (object name, generation) hashes. But then what
   227:         // about the birthday problem? And more importantly, what about our
   228:         // semantic of not minting a new inode ID when the generation changes due
   229:         // to a local action?
=> 230:         for i := range entries {
   231:                 entries[i].Inode = fuseops.RootInodeID + 1
   232:         }
   233:
   234:         return
   235: }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:231 (PC: 0x18f39b4)
   226:         // like inode IDs based on (object name, generation) hashes. But then what
   227:         // about the birthday problem? And more importantly, what about our
   228:         // semantic of not minting a new inode ID when the generation changes due
   229:         // to a local action?
   230:         for i := range entries {
=> 231:                 entries[i].Inode = fuseops.RootInodeID + 1
   232:         }
   233:
   234:         return
   235: }
   236:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:230 (PC: 0x18f39e2)
   225:         // If it turns out this is not harmless, we'll need to switch to something
   226:         // like inode IDs based on (object name, generation) hashes. But then what
   227:         // about the birthday problem? And more importantly, what about our
   228:         // semantic of not minting a new inode ID when the generation changes due
   229:         // to a local action?
=> 230:         for i := range entries {
   231:                 entries[i].Inode = fuseops.RootInodeID + 1
   232:         }
   233:
   234:         return
   235: }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:234 (PC: 0x18f39e9)
   229:         // to a local action?
   230:         for i := range entries {
   231:                 entries[i].Inode = fuseops.RootInodeID + 1
   232:         }
   233:
=> 234:         return
   235: }
   236:
   237: // LOCKS_REQUIRED(dh.Mu)
   238: // LOCKS_EXCLUDED(dh.in)
   239: func (dh *DirHandle) ensureEntries(ctx context.Context, localFileEntries []fuseutil.Dirent) (err error) {
(dlv) p entries
[]github.com/jacobsa/fuse/fuseutil.Dirent len: 2, cap: 2, [
        {Offset: 1, Inode: 2, Name: "14", Type: DT_File (8)},
        {Offset: 2, Inode: 2, Name: "a", Type: DT_Directory (4)},
]
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ensureEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:245 (PC: 0x18f3c13)
Values returned:
        entries: []github.com/jacobsa/fuse/fuseutil.Dirent len: 2, cap: 2, [
                {Offset: 1, Inode: 2, Name: "14", Type: DT_File (8)},
                {Offset: 2, Inode: 2, Name: "a", Type: DT_Directory (4)},
        ]
        err: error nil

   240:         dh.in.Lock()
   241:         defer dh.in.Unlock()
   242:
   243:         // Read entries.
   244:         var entries []fuseutil.Dirent
=> 245:         entries, err = readAllEntries(ctx, dh.in, localFileEntries)
   246:         if err != nil {
   247:                 err = fmt.Errorf("readAllEntries: %w", err)
   248:                 return
   249:         }
   250:
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ensureEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:246 (PC: 0x18f3cd2)
   241:         defer dh.in.Unlock()
   242:
   243:         // Read entries.
   244:         var entries []fuseutil.Dirent
   245:         entries, err = readAllEntries(ctx, dh.in, localFileEntries)
=> 246:         if err != nil {
   247:                 err = fmt.Errorf("readAllEntries: %w", err)
   248:                 return
   249:         }
   250:
   251:         // Update state.
(dlv) p entries
[]github.com/jacobsa/fuse/fuseutil.Dirent len: 2, cap: 2, [
        {Offset: 1, Inode: 2, Name: "14", Type: DT_File (8)},
        {Offset: 2, Inode: 2, Name: "a", Type: DT_Directory (4)},
]
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ensureEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:252 (PC: 0x18f3de7)
   247:                 err = fmt.Errorf("readAllEntries: %w", err)
   248:                 return
   249:         }
   250:
   251:         // Update state.
=> 252:         dh.entries = entries
   253:         dh.entriesValid = true
   254:
   255:         return
   256: }
   257:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ensureEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:253 (PC: 0x18f3e36)
   248:                 return
   249:         }
   250:
   251:         // Update state.
   252:         dh.entries = entries
=> 253:         dh.entriesValid = true
   254:
   255:         return
   256: }
   257:
   258: ////////////////////////////////////////////////////////////////////////
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ensureEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:255 (PC: 0x18f3e44)
   250:
   251:         // Update state.
   252:         dh.entries = entries
   253:         dh.entriesValid = true
   254:
=> 255:         return
   256: }
   257:
   258: ////////////////////////////////////////////////////////////////////////
   259: // Public interface
   260: ////////////////////////////////////////////////////////////////////////
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:283 (PC: 0x18f401b)
Values returned:
        err: error nil

   278:                 dh.entriesValid = false
   279:         }
   280:
   281:         // Do we need to read entries from GCS?
   282:         if !dh.entriesValid {
=> 283:                 err = dh.ensureEntries(ctx, localFileEntries)
   284:                 if err != nil {
   285:                         return
   286:                 }
   287:         }
   288:
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:284 (PC: 0x18f4025)
   279:         }
   280:
   281:         // Do we need to read entries from GCS?
   282:         if !dh.entriesValid {
   283:                 err = dh.ensureEntries(ctx, localFileEntries)
=> 284:                 if err != nil {
   285:                         return
   286:                 }
   287:         }
   288:
   289:         // Is the offset past the end of what we have buffered? If so, this must be
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:291 (PC: 0x18f4037)
   286:                 }
   287:         }
   288:
   289:         // Is the offset past the end of what we have buffered? If so, this must be
   290:         // an invalid seekdir according to posix.
=> 291:         index := int(op.Offset)
   292:         if index > len(dh.entries) {
   293:                 err = fuse.EINVAL
   294:                 return
   295:         }
   296:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:292 (PC: 0x18f404a)
   287:         }
   288:
   289:         // Is the offset past the end of what we have buffered? If so, this must be
   290:         // an invalid seekdir according to posix.
   291:         index := int(op.Offset)
=> 292:         if index > len(dh.entries) {
   293:                 err = fuse.EINVAL
   294:                 return
   295:         }
   296:
   297:         // We copy out entries until we run out of entries or space.
(dlv) p index
0
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:298 (PC: 0x18f4094)
   293:                 err = fuse.EINVAL
   294:                 return
   295:         }
   296:
   297:         // We copy out entries until we run out of entries or space.
=> 298:         for i := index; i < len(dh.entries); i++ {
   299:                 n := fuseutil.WriteDirent(op.Dst[op.BytesRead:], dh.entries[i])
   300:                 if n == 0 {
   301:                         break
   302:                 }
   303:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:299 (PC: 0x18f40c5)
   294:                 return
   295:         }
   296:
   297:         // We copy out entries until we run out of entries or space.
   298:         for i := index; i < len(dh.entries); i++ {
=> 299:                 n := fuseutil.WriteDirent(op.Dst[op.BytesRead:], dh.entries[i])
   300:                 if n == 0 {
   301:                         break
   302:                 }
   303:
   304:                 op.BytesRead += n
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:300 (PC: 0x18f41cc)
   295:         }
   296:
   297:         // We copy out entries until we run out of entries or space.
   298:         for i := index; i < len(dh.entries); i++ {
   299:                 n := fuseutil.WriteDirent(op.Dst[op.BytesRead:], dh.entries[i])
=> 300:                 if n == 0 {
   301:                         break
   302:                 }
   303:
   304:                 op.BytesRead += n
   305:         }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:304 (PC: 0x18f41d5)
   299:                 n := fuseutil.WriteDirent(op.Dst[op.BytesRead:], dh.entries[i])
   300:                 if n == 0 {
   301:                         break
   302:                 }
   303:
=> 304:                 op.BytesRead += n
   305:         }
   306:
   307:         return
   308: }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:298 (PC: 0x18f41f7)
   293:                 err = fuse.EINVAL
   294:                 return
   295:         }
   296:
   297:         // We copy out entries until we run out of entries or space.
=> 298:         for i := index; i < len(dh.entries); i++ {
   299:                 n := fuseutil.WriteDirent(op.Dst[op.BytesRead:], dh.entries[i])
   300:                 if n == 0 {
   301:                         break
   302:                 }
   303:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:299 (PC: 0x18f40c5)
   294:                 return
   295:         }
   296:
   297:         // We copy out entries until we run out of entries or space.
   298:         for i := index; i < len(dh.entries); i++ {
=> 299:                 n := fuseutil.WriteDirent(op.Dst[op.BytesRead:], dh.entries[i])
   300:                 if n == 0 {
   301:                         break
   302:                 }
   303:
   304:                 op.BytesRead += n
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:300 (PC: 0x18f41cc)
   295:         }
   296:
   297:         // We copy out entries until we run out of entries or space.
   298:         for i := index; i < len(dh.entries); i++ {
   299:                 n := fuseutil.WriteDirent(op.Dst[op.BytesRead:], dh.entries[i])
=> 300:                 if n == 0 {
   301:                         break
   302:                 }
   303:
   304:                 op.BytesRead += n
   305:         }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:304 (PC: 0x18f41d5)
   299:                 n := fuseutil.WriteDirent(op.Dst[op.BytesRead:], dh.entries[i])
   300:                 if n == 0 {
   301:                         break
   302:                 }
   303:
=> 304:                 op.BytesRead += n
   305:         }
   306:
   307:         return
   308: }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:298 (PC: 0x18f41f7)
   293:                 err = fuse.EINVAL
   294:                 return
   295:         }
   296:
   297:         // We copy out entries until we run out of entries or space.
=> 298:         for i := index; i < len(dh.entries); i++ {
   299:                 n := fuseutil.WriteDirent(op.Dst[op.BytesRead:], dh.entries[i])
   300:                 if n == 0 {
   301:                         break
   302:                 }
   303:
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:307 (PC: 0x18f4207)
   302:                 }
   303:
   304:                 op.BytesRead += n
   305:         }
   306:
=> 307:         return
   308: }
(dlv) p op
("*github.com/jacobsa/fuse/fuseops.ReadDirOp")(0xc0009c20f0)
*github.com/jacobsa/fuse/fuseops.ReadDirOp {
        Inode: 1,
        Handle: 26,
        Offset: 0,
        Dst: []uint8 len: 4096, cap: 4096, [2,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,2,0,0,0,8,0,0,0,49,52,0,0,0,0,0,0,2,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,1,0,0,0,4,0,0,0,97,0,0,0,0,0,0,0,...+4032 more],
        BytesRead: 64,
        OpContext: github.com/jacobsa/fuse/fuseops.OpContext {FuseID: 418, Pid: 1662072, Uid: 1012083},}
(dlv) l
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:307 (PC: 0x18f4207)
   302:                 }
   303:
   304:                 op.BytesRead += n
   305:         }
   306:
=> 307:         return
   308: }
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2092 (PC: 0x19103a9)
Values returned:
        err: error nil

  2087:         fs.mu.Unlock()
  2088:
  2089:         dh.Mu.Lock()
  2090:         defer dh.Mu.Unlock()
  2091:         // Serve the request.
=>2092:         if err := dh.ReadDir(ctx, op, localFileEntries); err != nil {
  2093:                 return err
  2094:         }
  2095:
  2096:         return
  2097: }
(dlv) p op
("*github.com/jacobsa/fuse/fuseops.ReadDirOp")(0xc0009c20f0)
*github.com/jacobsa/fuse/fuseops.ReadDirOp {
        Inode: 1,
        Handle: 26,
        Offset: 0,
        Dst: []uint8 len: 4096, cap: 4096, [2,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,2,0,0,0,8,0,0,0,49,52,0,0,0,0,0,0,2,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,1,0,0,0,4,0,0,0,97,0,0,0,0,0,0,0,...+4032 more],
        BytesRead: 64,
        OpContext: github.com/jacobsa/fuse/fuseops.OpContext {FuseID: 418, Pid: 1662072, Uid: 1012083},}
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2096 (PC: 0x19103f0)
  2091:         // Serve the request.
  2092:         if err := dh.ReadDir(ctx, op, localFileEntries); err != nil {
  2093:                 return err
  2094:         }
  2095:
=>2096:         return
  2097: }
  2098:
  2099: // LOCKS_EXCLUDED(fs.mu)
  2100: func (fs *fileSystem) ReleaseDirHandle(
  2101:         ctx context.Context,
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/wrappers.(*errorMapping).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/wrappers/error_mapping.go:252 (PC: 0x18f7c69)
Values returned:
        err: error nil

   247: func (em *errorMapping) ReadDir(
   248:         ctx context.Context,
   249:         op *fuseops.ReadDirOp) error {
   250:         defer em.handlePanic()
   251:
=> 252:         err := em.wrapped.ReadDir(ctx, op)
   253:         return em.mapError("ReadDir", err)
   254: }
   255:
   256: func (em *errorMapping) ReleaseDirHandle(
   257:         ctx context.Context,
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/wrappers.(*errorMapping).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/wrappers/error_mapping.go:253 (PC: 0x18f7c73)
   248:         ctx context.Context,
   249:         op *fuseops.ReadDirOp) error {
   250:         defer em.handlePanic()
   251:
   252:         err := em.wrapped.ReadDir(ctx, op)
=> 253:         return em.mapError("ReadDir", err)
   254: }
   255:
   256: func (em *errorMapping) ReleaseDirHandle(
   257:         ctx context.Context,
   258:         op *fuseops.ReleaseDirHandleOp) error {
(dlv) p err
error nil
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/wrappers.(*monitoring).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/wrappers/monitoring.go:282 (PC: 0x18fbcee)
Values returned:
        ~r0: error nil

   277:
   278: func (fs *monitoring) ReadDir(
   279:         ctx context.Context,
   280:         op *fuseops.ReadDirOp) error {
   281:         startTime := time.Now()
=> 282:         err := fs.wrapped.ReadDir(ctx, op)
   283:         recordOp(ctx, "ReadDir", startTime, err)
   284:         return err
   285: }
   286:
   287: func (fs *monitoring) ReleaseDirHandle(
(dlv) so
> github.com/jacobsa/fuse/fuseutil.(*fileSystemServer).handleOp() /usr/local/google/home/gargnitin/go/pkg/mod/github.com/jacobsa/fuse@v0.0.0-20231003132804-d0f3daf365c3/fuseutil/file_system.go:199 (PC: 0x18dea1b)
Values returned:
        ~r0: error nil

   194:
   195:         case *fuseops.OpenDirOp:
   196:                 err = s.fs.OpenDir(ctx, typed)
   197:
   198:         case *fuseops.ReadDirOp:
=> 199:                 err = s.fs.ReadDir(ctx, typed)
   200:
   201:         case *fuseops.ReleaseDirHandleOp:
   202:                 err = s.fs.ReleaseDirHandle(ctx, typed)
   203:
   204:         case *fuseops.OpenFileOp:
(dlv) so
> runtime.goexit() /usr/lib/google-golang/src/runtime/asm_amd64.s:1696 (PC: 0x4817c1)
Warning: debugging optimized function
Values returned:

  1691:
  1692: // The top-most function running on a goroutine
  1693: // returns to goexit+PCQuantum.
  1694: TEXT runtime·goexit(SB),NOSPLIT|TOPFRAME|NOFRAME,$0-0
  1695:         BYTE    $0x90   // NOP
=>1696:         CALL    runtime·goexit1(SB)     // does not return
  1697:         // traceback from goexit1 must hit code range of goexit
  1698:         BYTE    $0x90   // NOP
  1699:
  1700: // This is called from .init_array and follows the platform, not Go, ABI.
  1701: TEXT runtime·addmoduledata(SB),NOSPLIT,$0-0
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290 (hits goroutine(451):1 total:1) (PC: 0x188e0cb)
   285:                         } else {
   286:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   287:                         }
   288:                 } else {
   289:                         if util.IsUnsupportedObjectName(attrs.Name) {
=> 290:                                 logger.Warnf("Ignoring unsupported object-name: \"%s\"", attrs.Name)
   291:                         } else {
   292:                                 // Converting attrs to *Object type.
   293:                                 currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   294:                                 list.Objects = append(list.Objects, currObject)
   295:                         }
(dlv) p attrs.Nam
Command failed: attrs has no member Nam
(dlv) exite
Command failed: command not available
(dlv) p attrs.Name
"a/../8"
(dlv) bt
0  0x000000000188e0cb in github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects
   at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290
1  0x000000000189259d in github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*debugBucket).ListObjects
   at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/debug_bucket.go:205
2  0x00000000018d8d28 in github.com/googlecloudplatform/gcsfuse/v2/internal/gcsx.(*contentTypeBucket).ListObjects
   at <autogenerated>:1
3  0x00000000018e28a8 in github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.findDirInode
   at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:335
4  0x00000000018e3f8c in github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func3
   at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454
5  0x0000000000e9c4b1 in github.com/jacobsa/syncutil.(*Bundle).Add.func1
   at /usr/local/google/home/gargnitin/go/pkg/mod/github.com/jacobsa/syncutil@v0.0.0-20180201203307-228ac8e5a6c3/bundle.go:89
6  0x00000000004817c1 in runtime.goexit
   at /usr/lib/google-golang/src/runtime/asm_amd64.s:1695
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*debugBucket).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/debug_bucket.go:205 (PC: 0x189259d)
Values returned:
        listing: ("*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing")(0xc0008ea440)
*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing {
                Objects: []*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object len: 0, cap: 0, nil,
                CollapsedRuns: []string len: 0, cap: 0, nil,
                ContinuationToken: "CgZhLy4uLzg=",}
        err: error nil

   200:         ctx context.Context,
   201:         req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   202:         id, desc, start := b.startRequest("ListObjects(%q)", req.Prefix)
   203:         defer b.finishRequest(id, desc, start, &err)
   204:
=> 205:         listing, err = b.wrapped.ListObjects(ctx, req)
   206:         return
   207: }
   208:
   209: func (b *debugBucket) UpdateObject(
   210:         ctx context.Context,
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.findDirInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:335 (PC: 0x18e28a8)
Values returned:
        ~r0: ("*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing")(0xc0008ea440)
*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing {
                Objects: []*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object len: 0, cap: 0, nil,
                CollapsedRuns: []string len: 0, cap: 0, nil,
                ContinuationToken: "CgZhLy4uLzg=",}
        ~r1: error nil

   330:
   331:         req := &gcs.ListObjectsRequest{
   332:                 Prefix:     name.GcsObjectName(),
   333:                 MaxResults: 1,
   334:         }
=> 335:         listing, err := bucket.ListObjects(ctx, req)
   336:         if err != nil {
   337:                 return nil, fmt.Errorf("list objects: %w", err)
   338:         }
   339:
   340:         if len(listing.Objects) == 0 {
(dlv) bt
0  0x00000000018e28a8 in github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.findDirInode
   at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:335
1  0x00000000018e3f8c in github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func3
   at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454
2  0x0000000000e9c4b1 in github.com/jacobsa/syncutil.(*Bundle).Add.func1
   at /usr/local/google/home/gargnitin/go/pkg/mod/github.com/jacobsa/syncutil@v0.0.0-20180201203307-228ac8e5a6c3/bundle.go:89
3  0x00000000004817c1 in runtime.goexit
   at /usr/lib/google-golang/src/runtime/asm_amd64.s:1695
(dlv) c
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x4835c3)
Warning: debugging optimized function
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
(dlv) q
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ ./creationSituation.sh 1 debug
+ echo Number of args: 2
Number of args: 2
+ debug=0
+ run=1
+ '[' 2 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 2 -gt 1 ']'
+ debug=1
+ '[' 1 -ne 0 ']'
+ echo 'Debugging ...'
Debugging ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
mkdir: cannot stat ‘/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4’: Transport endpoint is not connected
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ unmountGcsfuse $mountpath             
unmountGcsfuse: passed argument \'/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4\' is not a directory
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ unmountGcsfuse $mountpath 
Unmounting gcsfuse mount /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 ...
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
... Unmounted /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ ./creationSituation.sh 1 debug
+ echo Number of args: 2
Number of args: 2
+ debug=0
+ run=1
+ '[' 2 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 2 -gt 1 ']'
+ debug=1
+ '[' 1 -ne 0 ']'
+ echo 'Debugging ...'
Debugging ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 1 = 0 ']'
+ dlv debug --check-go-version=false /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/. -- --config-file=config.yml --foreground --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
WARNING: undefined behavior - Go version go0.0 is too old for this version of Delve (minimum supported version 1.19)
Type 'help' for list of commands.
(dlv) r
Process restarted with PID 2572264
(dlv) c
{"timestamp":{"seconds":1714715489,"nanos":949379548},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x4835c3)
Warning: debugging optimized function
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284
Breakpoint 1 set at 0x188deea for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286
Breakpoint 2 set at 0x188dfb9 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290
Breakpoint 3 set at 0x188e0cb for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293
Breakpoint 4 set at 0x188e194 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290 (hits goroutine(285):1 total:1) (PC: 0x188e0cb)
   285:                         } else {
   286:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   287:                         }
   288:                 } else {
   289:                         if util.IsUnsupportedObjectName(attrs.Name) {
=> 290:                                 logger.Warnf("Ignoring unsupported object-name: \"%s\"", attrs.Name)
   291:                         } else {
   292:                                 // Converting attrs to *Object type.
   293:                                 currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   294:                                 list.Objects = append(list.Objects, currObject)
   295:                         }
(dlv) p attrs.Name
"a/../8"
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290 (hits goroutine(377):1 total:2) (PC: 0x188e0cb)
   285:                         } else {
   286:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   287:                         }
   288:                 } else {
   289:                         if util.IsUnsupportedObjectName(attrs.Name) {
=> 290:                                 logger.Warnf("Ignoring unsupported object-name: \"%s\"", attrs.Name)
   291:                         } else {
   292:                                 // Converting attrs to *Object type.
   293:                                 currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   294:                                 list.Objects = append(list.Objects, currObject)
   295:                         }
(dlv) p attrs.Name
"a/../8"
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290 (hits goroutine(419):1 total:3) (PC: 0x188e0cb)
   285:                         } else {
   286:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   287:                         }
   288:                 } else {
   289:                         if util.IsUnsupportedObjectName(attrs.Name) {
=> 290:                                 logger.Warnf("Ignoring unsupported object-name: \"%s\"", attrs.Name)
   291:                         } else {
   292:                                 // Converting attrs to *Object type.
   293:                                 currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   294:                                 list.Objects = append(list.Objects, currObject)
   295:                         }
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262
Breakpoint 5 set at 0x188dc08 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262 (hits goroutine(288):1 total:1) (PC: 0x188dc08)
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
=> 262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
(dlv) bp
Breakpoint runtime-fatal-throw (enabled) at 0x446724,0x446804,0x45f40e for (multiple functions)() <multiple locations>:0 (0)
Breakpoint unrecovered-panic (enabled) at 0x446cc4 for runtime.fatalpanic() /usr/lib/google-golang/src/runtime/panic.go:1219 (0)
        print runtime.curg._panic.arg
Breakpoint 1 (enabled) at 0x188deea for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284 (0)
Breakpoint 2 (enabled) at 0x188dfb9 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286 (0)
Breakpoint 3 (enabled) at 0x188e0cb for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290 (3)
Breakpoint 4 (enabled) at 0x188e194 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293 (0)
Breakpoint 5 (enabled) at 0x188dc08 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262 (1)
(dlv) l
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262 (hits goroutine(288):1 total:1) (PC: 0x188dc08)
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
=> 262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290 (hits goroutine(288):1 total:4) (PC: 0x188e0cb)
   285:                         } else {
   286:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   287:                         }
   288:                 } else {
   289:                         if util.IsUnsupportedObjectName(attrs.Name) {
=> 290:                                 logger.Warnf("Ignoring unsupported object-name: \"%s\"", attrs.Name)
   291:                         } else {
   292:                                 // Converting attrs to *Object type.
   293:                                 currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   294:                                 list.Objects = append(list.Objects, currObject)
   295:                         }
(dlv) p attrs.Name                                                                                                          
"a/../8"
(dlv) c
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x4835c3)
Warning: debugging optimized function
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
(dlv) b internal/fs/fs.go:2103
Breakpoint 6 set at 0x1910520 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReleaseDirHandle() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2103
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadFile
Breakpoint 7 set at 0x1910a76 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadFile() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2142
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenFile
Breakpoint 8 set at 0x1910753 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenFile() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2116
(dlv) bp
Breakpoint runtime-fatal-throw (enabled) at 0x446724,0x446804,0x45f40e for (multiple functions)() <multiple locations>:0 (0)
Breakpoint unrecovered-panic (enabled) at 0x446cc4 for runtime.fatalpanic() /usr/lib/google-golang/src/runtime/panic.go:1219 (0)
        print runtime.curg._panic.arg
Breakpoint 1 (enabled) at 0x188deea for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284 (0)
Breakpoint 2 (enabled) at 0x188dfb9 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286 (0)
Breakpoint 3 (enabled) at 0x188e0cb for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290 (4)
Breakpoint 4 (enabled) at 0x188e194 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293 (0)
Breakpoint 5 (enabled) at 0x188dc08 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262 (1)
Breakpoint 6 (enabled) at 0x1910520 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReleaseDirHandle() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2103 (0)
Breakpoint 7 (enabled) at 0x1910a76 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadFile() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2142 (0)
Breakpoint 8 (enabled) at 0x1910753 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenFile() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2116 (0)
(dlv) clear 6
Breakpoint 6 cleared at 0x1910520 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReleaseDirHandle() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2103
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir 
Breakpoint 9 set at 0x1910176 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2077
(dlv) bp                                                                           
Breakpoint runtime-fatal-throw (enabled) at 0x446724,0x446804,0x45f40e for (multiple functions)() <multiple locations>:0 (0)
Breakpoint unrecovered-panic (enabled) at 0x446cc4 for runtime.fatalpanic() /usr/lib/google-golang/src/runtime/panic.go:1219 (0)
        print runtime.curg._panic.arg
Breakpoint 1 (enabled) at 0x188deea for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284 (0)
Breakpoint 2 (enabled) at 0x188dfb9 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286 (0)
Breakpoint 3 (enabled) at 0x188e0cb for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290 (4)
Breakpoint 4 (enabled) at 0x188e194 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293 (0)
Breakpoint 5 (enabled) at 0x188dc08 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262 (1)
Breakpoint 7 (enabled) at 0x1910a76 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadFile() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2142 (0)
Breakpoint 8 (enabled) at 0x1910753 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenFile() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2116 (0)
Breakpoint 9 (enabled) at 0x1910176 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2077 (0)
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262 (hits goroutine(433):1 total:2) (PC: 0x188dc08)
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
=> 262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
(dlv) q
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ ./creationSituation.sh 1 debug
+ echo Number of args: 2
Number of args: 2
+ debug=0
+ run=1
+ '[' 2 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 2 -gt 1 ']'
+ debug=1
+ '[' 1 -ne 0 ']'
+ echo 'Debugging ...'
Debugging ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
mkdir: cannot stat ‘/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4’: Transport endpoint is not connected
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ unmountGcsfuse $mountpath         
unmountGcsfuse: passed argument \'/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4\' is not a directory
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ ./creationSituation.sh 1 debug
+ echo Number of args: 2
Number of args: 2
+ debug=0
+ run=1
+ '[' 2 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 2 -gt 1 ']'
+ debug=1
+ '[' 1 -ne 0 ']'
+ echo 'Debugging ...'
Debugging ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
mkdir: cannot stat ‘/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4’: Transport endpoint is not connected
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ unmountGcsfuse $mountpath         
unmountGcsfuse: passed argument \'/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4\' is not a directory
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ ./creationSituation.sh 1 debug
+ echo Number of args: 2
Number of args: 2
+ debug=0
+ run=1
+ '[' 2 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 2 -gt 1 ']'
+ debug=1
+ '[' 1 -ne 0 ']'
+ echo 'Debugging ...'
Debugging ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 1 = 0 ']'
+ dlv debug --check-go-version=false /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/. -- --config-file=config.yml --foreground --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
WARNING: undefined behavior - Go version go0.0 is too old for this version of Delve (minimum supported version 1.19)
Type 'help' for list of commands.
(dlv) r
Process restarted with PID 2604451
(dlv) c
{"timestamp":{"seconds":1714717138,"nanos":299855577},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x4835c3)
Warning: debugging optimized function
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir
Breakpoint 1 set at 0x1910176 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2077
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadFile
Breakpoint 2 set at 0x1910a76 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadFile() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2142
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenFile
Breakpoint 3 set at 0x1910753 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenFile() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2116
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284
Breakpoint 4 set at 0x188deea for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286
Breakpoint 5 set at 0x188dfb9 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290
Breakpoint 6 set at 0x188e0cb for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293
Breakpoint 7 set at 0x188e194 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293
(dlv) c
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x4835c3)
Warning: debugging optimized function
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262
Breakpoint 8 set at 0x188dc08 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262 (hits goroutine(90):1 total:1) (PC: 0x188dc08)
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
=> 262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262 (hits goroutine(361):1 total:2) (PC: 0x188dc08)
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
=> 262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
(dlv) c
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x4835c3)
Warning: debugging optimized function
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
(dlv) q
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ unmountGcsfuse $mountpath && ./creationSituation.sh 1      
Unmounting gcsfuse mount /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 ...
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
... Unmounted /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo Number of args: 1
Number of args: 1
+ debug=0
+ run=1
+ '[' 1 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 1 -gt 1 ']'
+ '[' 0 -ne 0 ']'
+ echo 'Running ...'
Running ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 0 = 0 ']'
+ go run /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse --config-file=config.yml --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
{"timestamp":{"seconds":1714720900,"nanos":238698369},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
time="03/05/2024 07:21:40.239046" severity=INFO message="Start gcsfuse/unknown (Go version go1.23-20240317-RC00 cl/616607620 +0a6f05e30f X:fieldtrack,boringcrypto) for app \"\" using mount point: /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4\n"
time="03/05/2024 07:21:40.400472" severity=INFO message="File system has been successfully mounted."
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ unmountGcsfuse $mountpath                             
Unmounting gcsfuse mount /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 ...
... Unmounted /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ unmountGcsfuse $mountpath 
Unmounting gcsfuse mount /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 ...
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
... Unmounted /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ 
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ export | grep 'bucket\|mountpath\|logfile'
declare -x bucket="gargnitin-test-empty-dirname-asia-se1"
declare -x logfile="/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log"
declare -x mountpath="/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4"
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ unmountGcsfuse $mountpath && ./creationSituation.sh 1 debug
Unmounting gcsfuse mount /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 ...
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
... Unmounted /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo Number of args: 2
Number of args: 2
+ debug=0
+ run=1
+ '[' 2 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 2 -gt 1 ']'
+ debug=1
+ '[' 1 -ne 0 ']'
+ echo 'Debugging ...'
Debugging ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 1 = 0 ']'
+ dlv debug --check-go-version=false /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/. -- --config-file=config.yml --foreground --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
WARNING: undefined behavior - Go version go0.0 is too old for this version of Delve (minimum supported version 1.19)
Type 'help' for list of commands.
(dlv) r
Process restarted with PID 4030451
(dlv) config source-list-line-count 20
(dlv) c
{"timestamp":{"seconds":1714847167,"nanos":729931000},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x4835c3)
Warning: debugging optimized function
   539: TEXT runtime·madvise(SB),NOSPLIT,$0
   540:         MOVQ    addr+0(FP), DI
   541:         MOVQ    n+8(FP), SI
   542:         MOVL    flags+16(FP), DX
   543:         MOVQ    $SYS_madvise, AX
   544:         SYSCALL
   545:         MOVL    AX, ret+24(FP)
   546:         RET
   547:
   548: // int64 futex(int32 *uaddr, int32 op, int32 val,
   549: //      struct timespec *timeout, int32 *uaddr2, int32 val2);
   550: TEXT runtime·futex(SB),NOSPLIT,$0
   551:         MOVQ    addr+0(FP), DI
   552:         MOVL    op+8(FP), SI
   553:         MOVL    val+12(FP), DX
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
   565:         MOVQ    stk+8(FP), SI
   566:         MOVQ    $0, DX
   567:         MOVQ    $0, R10
   568:         MOVQ    $0, R8
   569:         // Copy mp, gp, fn off parent stack for use by child.
   570:         // Careful: Linux system call clobbers CX and R11.
   571:         MOVQ    mp+16(FP), R13
   572:         MOVQ    gp+24(FP), R9
   573:         MOVQ    fn+32(FP), R12
   574:         CMPQ    R13, $0    // m
   575:         JEQ     nog1
   576:         CMPQ    R9, $0    // g
   577:         JEQ     nog1
   578:         LEAQ    m_tls(R13), R8
   579: #ifdef GOOS_android
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode
Breakpoint 1 set at 0x193b496 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314
(dlv) /usr/local/google/home/gargnitin/wo│message="fuse_debug: Op 0x00001220        connection.go:415] <- GetInodeAttributes (inode 1, PID 3916123)"
Command failed: command not available
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir                
Breakpoint 2 set at 0x19451d6 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir
Breakpoint 3 set at 0x1944ed3 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2126
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262
Breakpoint 4 set at 0x18c21a8 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284
Breakpoint 5 set at 0x18c248a for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286
Breakpoint 6 set at 0x18c2559 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290
Breakpoint 7 set at 0x18c266b for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293
Breakpoint 8 set at 0x18c2734 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.findDirInode
Breakpoint 9 set at 0x1916c96 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.findDirInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:326
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:612
Breakpoint 10 set at 0x1919d80 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:612
(dlv) bp
Breakpoint runtime-fatal-throw (enabled) at 0x45f40e,0x446724,0x446804 for (multiple functions)() <multiple locations>:0 (0)
Breakpoint unrecovered-panic (enabled) at 0x446cc4 for runtime.fatalpanic() /usr/lib/google-golang/src/runtime/panic.go:1219 (0)
        print runtime.curg._panic.arg
Breakpoint 1 (enabled) at 0x193b496 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 (0)
Breakpoint 2 (enabled) at 0x19451d6 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148 (0)
Breakpoint 3 (enabled) at 0x1944ed3 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2126 (0)
Breakpoint 4 (enabled) at 0x18c21a8 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262 (0)
Breakpoint 5 (enabled) at 0x18c248a for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284 (0)
Breakpoint 6 (enabled) at 0x18c2559 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286 (0)
Breakpoint 7 (enabled) at 0x18c266b for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290 (0)
Breakpoint 8 (enabled) at 0x18c2734 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293 (0)
Breakpoint 9 (enabled) at 0x1916c96 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.findDirInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:326 (0)
Breakpoint 10 (enabled) at 0x1919d80 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:612 (0)
(dlv) on 10 cond /usr/local/google/home/gargnitin/wo│message="fuse_debug: Op 0x00001220        connection.go:415] <- GetInodeAttributes (inode 1, PID 3916123)"
Command failed: 1:1: expected operand, found '/' (and 1 more errors)
(dlv) rk/cloud/storage/client/gcsfuse/src2/googlecloudplatform/gcsfuse/internal/fs/inode/dir.go:612^C
(dlv) on 10 cond p=="a//"                                                                                                                                      
Command failed: not enough arguments
(dlv) cond 10 p=="a//"   
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 (hits goroutine(348):1 total:1) (PC: 0x193b496)
  1294:         // Simulate a large amount of free space so that the Finder doesn't refuse to
  1295:         // copy in files. (See issue #125.) Use 2^17 as the block size because that
  1296:         // is the largest that OS X will pass on.
  1297:         op.BlockSize = 1 << 17
  1298:         op.Blocks = 1 << 33
  1299:         op.BlocksFree = op.Blocks
  1300:         op.BlocksAvailable = op.Blocks
  1301:
  1302:         // Similarly with inodes.
  1303:         op.Inodes = 1 << 50
  1304:         op.InodesFree = op.Inodes
  1305:
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
=>1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
(dlv) clear all
Command failed: no breakpoint with name all
(dlv) clearall 
Breakpoint 1 cleared at 0x193b496 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314
Breakpoint 5 cleared at 0x18c248a for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284
Breakpoint 6 cleared at 0x18c2559 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286
Breakpoint 7 cleared at 0x18c266b for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290
Breakpoint 8 cleared at 0x18c2734 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293
Breakpoint 10 cleared at 0x1919d80 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:612
Breakpoint 2 cleared at 0x19451d6 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148
Breakpoint 3 cleared at 0x1944ed3 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2126
Breakpoint 4 cleared at 0x18c21a8 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262
Breakpoint 9 cleared at 0x1916c96 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.findDirInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:326
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir
Breakpoint 11 set at 0x19451d6 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148
(dlv) bp
Breakpoint runtime-fatal-throw (enabled) at 0x45f40e,0x446724,0x446804 for (multiple functions)() <multiple locations>:0 (0)
Breakpoint unrecovered-panic (enabled) at 0x446cc4 for runtime.fatalpanic() /usr/lib/google-golang/src/runtime/panic.go:1219 (0)
        print runtime.curg._panic.arg
Breakpoint 11 (enabled) at 0x19451d6 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148 (0)
(dlv) c
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x4835c3)
Warning: debugging optimized function
   539: TEXT runtime·madvise(SB),NOSPLIT,$0
   540:         MOVQ    addr+0(FP), DI
   541:         MOVQ    n+8(FP), SI
   542:         MOVL    flags+16(FP), DX
   543:         MOVQ    $SYS_madvise, AX
   544:         SYSCALL
   545:         MOVL    AX, ret+24(FP)
   546:         RET
   547:
   548: // int64 futex(int32 *uaddr, int32 op, int32 val,
   549: //      struct timespec *timeout, int32 *uaddr2, int32 val2);
   550: TEXT runtime·futex(SB),NOSPLIT,$0
   551:         MOVQ    addr+0(FP), DI
   552:         MOVL    op+8(FP), SI
   553:         MOVL    val+12(FP), DX
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
   565:         MOVQ    stk+8(FP), SI
   566:         MOVQ    $0, DX
   567:         MOVQ    $0, R10
   568:         MOVQ    $0, R8
   569:         // Copy mp, gp, fn off parent stack for use by child.
   570:         // Careful: Linux system call clobbers CX and R11.
   571:         MOVQ    mp+16(FP), R13
   572:         MOVQ    gp+24(FP), R9
   573:         MOVQ    fn+32(FP), R12
   574:         CMPQ    R13, $0    // m
   575:         JEQ     nog1
   576:         CMPQ    R9, $0    // g
   577:         JEQ     nog1
   578:         LEAQ    m_tls(R13), R8
   579: #ifdef GOOS_android
(dlv) q
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ unmountGcsfuse $mountpath && ./creationSituation.sh 1 debug
unmountGcsfuse: passed argument \'/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4\' is not a directory
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ sudo unmount $mountpath && ./creationSituation.sh 1 debug       
[sudo] password for gargnitin: 
sudo: unmount: command not found
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ sudo umount $mountpath ; ./creationSituation.sh 1 debug         
+ echo Number of args: 2
Number of args: 2
+ debug=0
+ run=1
+ '[' 2 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 2 -gt 1 ']'
+ debug=1
+ '[' 1 -ne 0 ']'
+ echo 'Debugging ...'
Debugging ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 1 = 0 ']'
+ dlv debug --check-go-version=false /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/. -- --config-file=config.yml --foreground --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
WARNING: undefined behavior - Go version go0.0 is too old for this version of Delve (minimum supported version 1.19)
Type 'help' for list of commands.
(dlv) r
Process restarted with PID 4037728
(dlv) c
{"timestamp":{"seconds":1714847501,"nanos":244976289},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x4835c3)
Warning: debugging optimized function
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode
Breakpoint 1 set at 0x193b496 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 at 193b496
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir
Breakpoint 3 set at 0x19451d6 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148 at 19451d6
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir
Breakpoint 5 set at 0x1944ed3 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2126
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 (hits goroutine(279):1 total:1) (PC: 0x193b496)
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
=>1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
(dlv) config source-list-line-count 20
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1317 (PC: 0x193b4c6)
  1297:         op.BlockSize = 1 << 17
  1298:         op.Blocks = 1 << 33
  1299:         op.BlocksFree = op.Blocks
  1300:         op.BlocksAvailable = op.Blocks
  1301:
  1302:         // Similarly with inodes.
  1303:         op.Inodes = 1 << 50
  1304:         op.InodesFree = op.Inodes
  1305:
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
=>1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1325 (PC: 0x193b5d2)
  1305:
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
=>1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
  1345:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1326 (PC: 0x193b5ef)
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
=>1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
  1345:
  1346:         return
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1327 (PC: 0x193b621)
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
=>1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
  1345:
  1346:         return
  1347: }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1330 (PC: 0x193b63e)
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
=>1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
  1345:
  1346:         return
  1347: }
  1348:
  1349: // LOCKS_EXCLUDED(fs.mu)
  1350: func (fs *fileSystem) GetInodeAttributes(
(dlv) bp
Breakpoint runtime-fatal-throw (enabled) at 0x446804,0x45f40e,0x446724 for (multiple functions)() <multiple locations>:0 (0)
Breakpoint unrecovered-panic (enabled) at 0x446cc4 for runtime.fatalpanic() /usr/lib/google-golang/src/runtime/panic.go:1219 (0)
        print runtime.curg._panic.arg
Breakpoint 1 (enabled) at 0x193b496 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 (1)
Breakpoint 3 (enabled) at 0x19451d6 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148 (0)
Breakpoint 5 (enabled) at 0x1944ed3 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2126 (0)
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 (hits goroutine(354):1 total:2) (PC: 0x193b496)
  1294:         // Simulate a large amount of free space so that the Finder doesn't refuse to
  1295:         // copy in files. (See issue #125.) Use 2^17 as the block size because that
  1296:         // is the largest that OS X will pass on.
  1297:         op.BlockSize = 1 << 17
  1298:         op.Blocks = 1 << 33
  1299:         op.BlocksFree = op.Blocks
  1300:         op.BlocksAvailable = op.Blocks
  1301:
  1302:         // Similarly with inodes.
  1303:         op.Inodes = 1 << 50
  1304:         op.InodesFree = op.Inodes
  1305:
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
=>1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
(dlv) c
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x4835c3)
Warning: debugging optimized function
   539: TEXT runtime·madvise(SB),NOSPLIT,$0
   540:         MOVQ    addr+0(FP), DI
   541:         MOVQ    n+8(FP), SI
   542:         MOVL    flags+16(FP), DX
   543:         MOVQ    $SYS_madvise, AX
   544:         SYSCALL
   545:         MOVL    AX, ret+24(FP)
   546:         RET
   547:
   548: // int64 futex(int32 *uaddr, int32 op, int32 val,
   549: //      struct timespec *timeout, int32 *uaddr2, int32 val2);
   550: TEXT runtime·futex(SB),NOSPLIT,$0
   551:         MOVQ    addr+0(FP), DI
   552:         MOVL    op+8(FP), SI
   553:         MOVL    val+12(FP), DX
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
   565:         MOVQ    stk+8(FP), SI
   566:         MOVQ    $0, DX
   567:         MOVQ    $0, R10
   568:         MOVQ    $0, R8
   569:         // Copy mp, gp, fn off parent stack for use by child.
   570:         // Careful: Linux system call clobbers CX and R11.
   571:         MOVQ    mp+16(FP), R13
   572:         MOVQ    gp+24(FP), R9
   573:         MOVQ    fn+32(FP), R12
   574:         CMPQ    R13, $0    // m
   575:         JEQ     nog1
   576:         CMPQ    R9, $0    // g
   577:         JEQ     nog1
   578:         LEAQ    m_tls(R13), R8
   579: #ifdef GOOS_android
(dlv) q
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ sudo umount $mountpath ; ./creationSituation.sh 1 debug
+ echo Number of args: 2
Number of args: 2
+ debug=0
+ run=1
+ '[' 2 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 2 -gt 1 ']'
+ debug=1
+ '[' 1 -ne 0 ']'
+ echo 'Debugging ...'
Debugging ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 1 = 0 ']'
+ dlv debug --check-go-version=false /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/. -- --config-file=config.yml --foreground --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
WARNING: undefined behavior - Go version go0.0 is too old for this version of Delve (minimum supported version 1.19)
Type 'help' for list of commands.
(dlv) r
Process restarted with PID 4039814
(dlv) c
{"timestamp":{"seconds":1714847614,"nanos":538317420},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x4835c3)
Warning: debugging optimized function
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
(dlv) config source-list-line-count 20
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode
Breakpoint 1 set at 0x193b496 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 (hits goroutine(370):1 total:1) (PC: 0x193b496)
  1294:         // Simulate a large amount of free space so that the Finder doesn't refuse to
  1295:         // copy in files. (See issue #125.) Use 2^17 as the block size because that
  1296:         // is the largest that OS X will pass on.
  1297:         op.BlockSize = 1 << 17
  1298:         op.Blocks = 1 << 33
  1299:         op.BlocksFree = op.Blocks
  1300:         op.BlocksAvailable = op.Blocks
  1301:
  1302:         // Similarly with inodes.
  1303:         op.Inodes = 1 << 50
  1304:         op.InodesFree = op.Inodes
  1305:
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
=>1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1317 (PC: 0x193b4c6)
  1297:         op.BlockSize = 1 << 17
  1298:         op.Blocks = 1 << 33
  1299:         op.BlocksFree = op.Blocks
  1300:         op.BlocksAvailable = op.Blocks
  1301:
  1302:         // Similarly with inodes.
  1303:         op.Inodes = 1 << 50
  1304:         op.InodesFree = op.Inodes
  1305:
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
=>1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1325 (PC: 0x193b5d2)
  1305:
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
=>1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
  1345:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1326 (PC: 0x193b5ef)
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
=>1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
  1345:
  1346:         return
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1327 (PC: 0x193b621)
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
=>1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
  1345:
  1346:         return
  1347: }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1330 (PC: 0x193b63e)
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
=>1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
  1345:
  1346:         return
  1347: }
  1348:
  1349: // LOCKS_EXCLUDED(fs.mu)
  1350: func (fs *fileSystem) GetInodeAttributes(
(dlv) p op.Name
"a"
(dlv) s
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:911 (PC: 0x19383d6)
   891:                 // Replace it with a newly-mintend inode and then go around, acquiring its
   892:                 // lock in accordance with our lock ordering rules.
   893:                 existingInode.Unlock()
   894:
   895:                 in = fs.mintInode(ic)
   896:                 fs.generationBackedInodes[in.Name()] = in.(inode.GenerationBackedInode)
   897:
   898:                 continue
   899:         }
   900: }
   901:
   902: // Look up the child with the given name within the parent, then return an
   903: // existing inode for that child or create a new one if necessary. Return
   904: // ENOENT if the child doesn't exist.
   905: //
   906: // Return the child locked, incrementing its lookup count.
   907: //
   908: // LOCKS_EXCLUDED(fs.mu)
   909: // LOCKS_EXCLUDED(parent)
   910: // LOCK_FUNCTION(child)
=> 911: func (fs *fileSystem) lookUpOrCreateChildInode(
   912:         ctx context.Context,
   913:         parent inode.DirInode,
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
   916:         child = fs.lookUpLocalFileInode(parent, childName)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:916 (PC: 0x1938421)
   896:                 fs.generationBackedInodes[in.Name()] = in.(inode.GenerationBackedInode)
   897:
   898:                 continue
   899:         }
   900: }
   901:
   902: // Look up the child with the given name within the parent, then return an
   903: // existing inode for that child or create a new one if necessary. Return
   904: // ENOENT if the child doesn't exist.
   905: //
   906: // Return the child locked, incrementing its lookup count.
   907: //
   908: // LOCKS_EXCLUDED(fs.mu)
   909: // LOCKS_EXCLUDED(parent)
   910: // LOCK_FUNCTION(child)
   911: func (fs *fileSystem) lookUpOrCreateChildInode(
   912:         ctx context.Context,
   913:         parent inode.DirInode,
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
=> 916:         child = fs.lookUpLocalFileInode(parent, childName)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
(dlv) p parent
(unreadable invalid interface type)
(dlv) p childNa
Command failed: could not find symbol value for childNa
(dlv) p childName
"a"
(dlv) s
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpLocalFileInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:965 (PC: 0x1938c56)
   945:                         return
   946:                 }
   947:
   948:                 // Attempt to create the inode. Return if successful.
   949:                 child = fs.lookUpOrCreateInodeIfNotStale(*core)
   950:                 if child != nil {
   951:                         return
   952:                 }
   953:         }
   954:
   955:         err = fmt.Errorf("cannot find %q in %q with %v tries", childName, parent.Name(), maxTries)
   956:         return
   957: }
   958:
   959: // Look up the localFileInodes to check if a file with given name exists.
   960: // Return inode if it exists, else return nil.
   961: // LOCKS_EXCLUDED(fs.mu)
   962: // LOCKS_EXCLUDED(parent)
   963: // UNLOCK_FUNCTION(fs.mu)
   964: // LOCK_FUNCTION(child)
=> 965: func (fs *fileSystem) lookUpLocalFileInode(parent inode.DirInode, childName string) (child inode.Inode) {
   966:         defer func() {
   967:                 if child != nil {
   968:                         child.IncrementLookupCount()
   969:                 }
   970:                 fs.mu.Unlock()
   971:         }()
   972:
   973:         // Trim the suffix assigned to fix conflicting names.
   974:         childName = strings.TrimSuffix(childName, inode.ConflictingFileNameSuffix)
   975:         fileName := inode.NewFileName(parent.Name(), childName)
   976:
   977:         fs.mu.Lock()
   978:         var maxTriesToLookupInode = 3
   979:         for n := 0; n < maxTriesToLookupInode; n++ {
   980:                 child = fs.localFileInodes[fileName]
   981:
   982:                 if child == nil {
   983:                         return
   984:                 }
   985:
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpLocalFileInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:966 (PC: 0x1938c8e)
   946:                 }
   947:
   948:                 // Attempt to create the inode. Return if successful.
   949:                 child = fs.lookUpOrCreateInodeIfNotStale(*core)
   950:                 if child != nil {
   951:                         return
   952:                 }
   953:         }
   954:
   955:         err = fmt.Errorf("cannot find %q in %q with %v tries", childName, parent.Name(), maxTries)
   956:         return
   957: }
   958:
   959: // Look up the localFileInodes to check if a file with given name exists.
   960: // Return inode if it exists, else return nil.
   961: // LOCKS_EXCLUDED(fs.mu)
   962: // LOCKS_EXCLUDED(parent)
   963: // UNLOCK_FUNCTION(fs.mu)
   964: // LOCK_FUNCTION(child)
   965: func (fs *fileSystem) lookUpLocalFileInode(parent inode.DirInode, childName string) (child inode.Inode) {
=> 966:         defer func() {
   967:                 if child != nil {
   968:                         child.IncrementLookupCount()
   969:                 }
   970:                 fs.mu.Unlock()
   971:         }()
   972:
   973:         // Trim the suffix assigned to fix conflicting names.
   974:         childName = strings.TrimSuffix(childName, inode.ConflictingFileNameSuffix)
   975:         fileName := inode.NewFileName(parent.Name(), childName)
   976:
   977:         fs.mu.Lock()
   978:         var maxTriesToLookupInode = 3
   979:         for n := 0; n < maxTriesToLookupInode; n++ {
   980:                 child = fs.localFileInodes[fileName]
   981:
   982:                 if child == nil {
   983:                         return
   984:                 }
   985:
   986:                 // If the inode already exists, we need to follow the lock ordering rules
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpLocalFileInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:974 (PC: 0x1938d3a)
   954:
   955:         err = fmt.Errorf("cannot find %q in %q with %v tries", childName, parent.Name(), maxTries)
   956:         return
   957: }
   958:
   959: // Look up the localFileInodes to check if a file with given name exists.
   960: // Return inode if it exists, else return nil.
   961: // LOCKS_EXCLUDED(fs.mu)
   962: // LOCKS_EXCLUDED(parent)
   963: // UNLOCK_FUNCTION(fs.mu)
   964: // LOCK_FUNCTION(child)
   965: func (fs *fileSystem) lookUpLocalFileInode(parent inode.DirInode, childName string) (child inode.Inode) {
   966:         defer func() {
   967:                 if child != nil {
   968:                         child.IncrementLookupCount()
   969:                 }
   970:                 fs.mu.Unlock()
   971:         }()
   972:
   973:         // Trim the suffix assigned to fix conflicting names.
=> 974:         childName = strings.TrimSuffix(childName, inode.ConflictingFileNameSuffix)
   975:         fileName := inode.NewFileName(parent.Name(), childName)
   976:
   977:         fs.mu.Lock()
   978:         var maxTriesToLookupInode = 3
   979:         for n := 0; n < maxTriesToLookupInode; n++ {
   980:                 child = fs.localFileInodes[fileName]
   981:
   982:                 if child == nil {
   983:                         return
   984:                 }
   985:
   986:                 // If the inode already exists, we need to follow the lock ordering rules
   987:                 // to get the lock. First get inode lock and then fs lock.
   988:                 fs.mu.Unlock()
   989:                 child.Lock()
   990:                 // Acquiring fs lock early to use common defer function even though it is
   991:                 // not required to check if local file inode has been unlinked.
   992:                 // Filesystem lock will be held till we increment lookUpCount to avoid
   993:                 // deletion of inode from fs.inodes/fs.localFileInodes map by other flows.
   994:                 fs.mu.Lock()
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpLocalFileInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:975 (PC: 0x1938d6b)
   955:         err = fmt.Errorf("cannot find %q in %q with %v tries", childName, parent.Name(), maxTries)
   956:         return
   957: }
   958:
   959: // Look up the localFileInodes to check if a file with given name exists.
   960: // Return inode if it exists, else return nil.
   961: // LOCKS_EXCLUDED(fs.mu)
   962: // LOCKS_EXCLUDED(parent)
   963: // UNLOCK_FUNCTION(fs.mu)
   964: // LOCK_FUNCTION(child)
   965: func (fs *fileSystem) lookUpLocalFileInode(parent inode.DirInode, childName string) (child inode.Inode) {
   966:         defer func() {
   967:                 if child != nil {
   968:                         child.IncrementLookupCount()
   969:                 }
   970:                 fs.mu.Unlock()
   971:         }()
   972:
   973:         // Trim the suffix assigned to fix conflicting names.
   974:         childName = strings.TrimSuffix(childName, inode.ConflictingFileNameSuffix)
=> 975:         fileName := inode.NewFileName(parent.Name(), childName)
   976:
   977:         fs.mu.Lock()
   978:         var maxTriesToLookupInode = 3
   979:         for n := 0; n < maxTriesToLookupInode; n++ {
   980:                 child = fs.localFileInodes[fileName]
   981:
   982:                 if child == nil {
   983:                         return
   984:                 }
   985:
   986:                 // If the inode already exists, we need to follow the lock ordering rules
   987:                 // to get the lock. First get inode lock and then fs lock.
   988:                 fs.mu.Unlock()
   989:                 child.Lock()
   990:                 // Acquiring fs lock early to use common defer function even though it is
   991:                 // not required to check if local file inode has been unlinked.
   992:                 // Filesystem lock will be held till we increment lookUpCount to avoid
   993:                 // deletion of inode from fs.inodes/fs.localFileInodes map by other flows.
   994:                 fs.mu.Lock()
   995:                 // Check if local file inode has been unlinked?
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpLocalFileInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:977 (PC: 0x1938dd8)
   957: }
   958:
   959: // Look up the localFileInodes to check if a file with given name exists.
   960: // Return inode if it exists, else return nil.
   961: // LOCKS_EXCLUDED(fs.mu)
   962: // LOCKS_EXCLUDED(parent)
   963: // UNLOCK_FUNCTION(fs.mu)
   964: // LOCK_FUNCTION(child)
   965: func (fs *fileSystem) lookUpLocalFileInode(parent inode.DirInode, childName string) (child inode.Inode) {
   966:         defer func() {
   967:                 if child != nil {
   968:                         child.IncrementLookupCount()
   969:                 }
   970:                 fs.mu.Unlock()
   971:         }()
   972:
   973:         // Trim the suffix assigned to fix conflicting names.
   974:         childName = strings.TrimSuffix(childName, inode.ConflictingFileNameSuffix)
   975:         fileName := inode.NewFileName(parent.Name(), childName)
   976:
=> 977:         fs.mu.Lock()
   978:         var maxTriesToLookupInode = 3
   979:         for n := 0; n < maxTriesToLookupInode; n++ {
   980:                 child = fs.localFileInodes[fileName]
   981:
   982:                 if child == nil {
   983:                         return
   984:                 }
   985:
   986:                 // If the inode already exists, we need to follow the lock ordering rules
   987:                 // to get the lock. First get inode lock and then fs lock.
   988:                 fs.mu.Unlock()
   989:                 child.Lock()
   990:                 // Acquiring fs lock early to use common defer function even though it is
   991:                 // not required to check if local file inode has been unlinked.
   992:                 // Filesystem lock will be held till we increment lookUpCount to avoid
   993:                 // deletion of inode from fs.inodes/fs.localFileInodes map by other flows.
   994:                 fs.mu.Lock()
   995:                 // Check if local file inode has been unlinked?
   996:                 fileInode, ok := child.(*inode.FileInode)
   997:                 if ok && fileInode.IsUnlinked() {
(dlv) p childNa
Command failed: could not find symbol value for childNa
(dlv) p childName
"a"
(dlv) p fileName 
github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Name {bucketName: "", objectName: "a"}
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpLocalFileInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:978 (PC: 0x1938df5)
   958:
   959: // Look up the localFileInodes to check if a file with given name exists.
   960: // Return inode if it exists, else return nil.
   961: // LOCKS_EXCLUDED(fs.mu)
   962: // LOCKS_EXCLUDED(parent)
   963: // UNLOCK_FUNCTION(fs.mu)
   964: // LOCK_FUNCTION(child)
   965: func (fs *fileSystem) lookUpLocalFileInode(parent inode.DirInode, childName string) (child inode.Inode) {
   966:         defer func() {
   967:                 if child != nil {
   968:                         child.IncrementLookupCount()
   969:                 }
   970:                 fs.mu.Unlock()
   971:         }()
   972:
   973:         // Trim the suffix assigned to fix conflicting names.
   974:         childName = strings.TrimSuffix(childName, inode.ConflictingFileNameSuffix)
   975:         fileName := inode.NewFileName(parent.Name(), childName)
   976:
   977:         fs.mu.Lock()
=> 978:         var maxTriesToLookupInode = 3
   979:         for n := 0; n < maxTriesToLookupInode; n++ {
   980:                 child = fs.localFileInodes[fileName]
   981:
   982:                 if child == nil {
   983:                         return
   984:                 }
   985:
   986:                 // If the inode already exists, we need to follow the lock ordering rules
   987:                 // to get the lock. First get inode lock and then fs lock.
   988:                 fs.mu.Unlock()
   989:                 child.Lock()
   990:                 // Acquiring fs lock early to use common defer function even though it is
   991:                 // not required to check if local file inode has been unlinked.
   992:                 // Filesystem lock will be held till we increment lookUpCount to avoid
   993:                 // deletion of inode from fs.inodes/fs.localFileInodes map by other flows.
   994:                 fs.mu.Lock()
   995:                 // Check if local file inode has been unlinked?
   996:                 fileInode, ok := child.(*inode.FileInode)
   997:                 if ok && fileInode.IsUnlinked() {
   998:                         child.Unlock()
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpLocalFileInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:979 (PC: 0x1938dfe)
   959: // Look up the localFileInodes to check if a file with given name exists.
   960: // Return inode if it exists, else return nil.
   961: // LOCKS_EXCLUDED(fs.mu)
   962: // LOCKS_EXCLUDED(parent)
   963: // UNLOCK_FUNCTION(fs.mu)
   964: // LOCK_FUNCTION(child)
   965: func (fs *fileSystem) lookUpLocalFileInode(parent inode.DirInode, childName string) (child inode.Inode) {
   966:         defer func() {
   967:                 if child != nil {
   968:                         child.IncrementLookupCount()
   969:                 }
   970:                 fs.mu.Unlock()
   971:         }()
   972:
   973:         // Trim the suffix assigned to fix conflicting names.
   974:         childName = strings.TrimSuffix(childName, inode.ConflictingFileNameSuffix)
   975:         fileName := inode.NewFileName(parent.Name(), childName)
   976:
   977:         fs.mu.Lock()
   978:         var maxTriesToLookupInode = 3
=> 979:         for n := 0; n < maxTriesToLookupInode; n++ {
   980:                 child = fs.localFileInodes[fileName]
   981:
   982:                 if child == nil {
   983:                         return
   984:                 }
   985:
   986:                 // If the inode already exists, we need to follow the lock ordering rules
   987:                 // to get the lock. First get inode lock and then fs lock.
   988:                 fs.mu.Unlock()
   989:                 child.Lock()
   990:                 // Acquiring fs lock early to use common defer function even though it is
   991:                 // not required to check if local file inode has been unlinked.
   992:                 // Filesystem lock will be held till we increment lookUpCount to avoid
   993:                 // deletion of inode from fs.inodes/fs.localFileInodes map by other flows.
   994:                 fs.mu.Lock()
   995:                 // Check if local file inode has been unlinked?
   996:                 fileInode, ok := child.(*inode.FileInode)
   997:                 if ok && fileInode.IsUnlinked() {
   998:                         child.Unlock()
   999:                         child = nil
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpLocalFileInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:980 (PC: 0x1938e38)
   960: // Return inode if it exists, else return nil.
   961: // LOCKS_EXCLUDED(fs.mu)
   962: // LOCKS_EXCLUDED(parent)
   963: // UNLOCK_FUNCTION(fs.mu)
   964: // LOCK_FUNCTION(child)
   965: func (fs *fileSystem) lookUpLocalFileInode(parent inode.DirInode, childName string) (child inode.Inode) {
   966:         defer func() {
   967:                 if child != nil {
   968:                         child.IncrementLookupCount()
   969:                 }
   970:                 fs.mu.Unlock()
   971:         }()
   972:
   973:         // Trim the suffix assigned to fix conflicting names.
   974:         childName = strings.TrimSuffix(childName, inode.ConflictingFileNameSuffix)
   975:         fileName := inode.NewFileName(parent.Name(), childName)
   976:
   977:         fs.mu.Lock()
   978:         var maxTriesToLookupInode = 3
   979:         for n := 0; n < maxTriesToLookupInode; n++ {
=> 980:                 child = fs.localFileInodes[fileName]
   981:
   982:                 if child == nil {
   983:                         return
   984:                 }
   985:
   986:                 // If the inode already exists, we need to follow the lock ordering rules
   987:                 // to get the lock. First get inode lock and then fs lock.
   988:                 fs.mu.Unlock()
   989:                 child.Lock()
   990:                 // Acquiring fs lock early to use common defer function even though it is
   991:                 // not required to check if local file inode has been unlinked.
   992:                 // Filesystem lock will be held till we increment lookUpCount to avoid
   993:                 // deletion of inode from fs.inodes/fs.localFileInodes map by other flows.
   994:                 fs.mu.Lock()
   995:                 // Check if local file inode has been unlinked?
   996:                 fileInode, ok := child.(*inode.FileInode)
   997:                 if ok && fileInode.IsUnlinked() {
   998:                         child.Unlock()
   999:                         child = nil
  1000:                         return
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpLocalFileInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:982 (PC: 0x1938ec0)
   962: // LOCKS_EXCLUDED(parent)
   963: // UNLOCK_FUNCTION(fs.mu)
   964: // LOCK_FUNCTION(child)
   965: func (fs *fileSystem) lookUpLocalFileInode(parent inode.DirInode, childName string) (child inode.Inode) {
   966:         defer func() {
   967:                 if child != nil {
   968:                         child.IncrementLookupCount()
   969:                 }
   970:                 fs.mu.Unlock()
   971:         }()
   972:
   973:         // Trim the suffix assigned to fix conflicting names.
   974:         childName = strings.TrimSuffix(childName, inode.ConflictingFileNameSuffix)
   975:         fileName := inode.NewFileName(parent.Name(), childName)
   976:
   977:         fs.mu.Lock()
   978:         var maxTriesToLookupInode = 3
   979:         for n := 0; n < maxTriesToLookupInode; n++ {
   980:                 child = fs.localFileInodes[fileName]
   981:
=> 982:                 if child == nil {
   983:                         return
   984:                 }
   985:
   986:                 // If the inode already exists, we need to follow the lock ordering rules
   987:                 // to get the lock. First get inode lock and then fs lock.
   988:                 fs.mu.Unlock()
   989:                 child.Lock()
   990:                 // Acquiring fs lock early to use common defer function even though it is
   991:                 // not required to check if local file inode has been unlinked.
   992:                 // Filesystem lock will be held till we increment lookUpCount to avoid
   993:                 // deletion of inode from fs.inodes/fs.localFileInodes map by other flows.
   994:                 fs.mu.Lock()
   995:                 // Check if local file inode has been unlinked?
   996:                 fileInode, ok := child.(*inode.FileInode)
   997:                 if ok && fileInode.IsUnlinked() {
   998:                         child.Unlock()
   999:                         child = nil
  1000:                         return
  1001:                 }
  1002:                 // Once we get fs lock, validate if the inode is still valid. If not
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpLocalFileInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:983 (PC: 0x19390e7)
   963: // UNLOCK_FUNCTION(fs.mu)
   964: // LOCK_FUNCTION(child)
   965: func (fs *fileSystem) lookUpLocalFileInode(parent inode.DirInode, childName string) (child inode.Inode) {
   966:         defer func() {
   967:                 if child != nil {
   968:                         child.IncrementLookupCount()
   969:                 }
   970:                 fs.mu.Unlock()
   971:         }()
   972:
   973:         // Trim the suffix assigned to fix conflicting names.
   974:         childName = strings.TrimSuffix(childName, inode.ConflictingFileNameSuffix)
   975:         fileName := inode.NewFileName(parent.Name(), childName)
   976:
   977:         fs.mu.Lock()
   978:         var maxTriesToLookupInode = 3
   979:         for n := 0; n < maxTriesToLookupInode; n++ {
   980:                 child = fs.localFileInodes[fileName]
   981:
   982:                 if child == nil {
=> 983:                         return
   984:                 }
   985:
   986:                 // If the inode already exists, we need to follow the lock ordering rules
   987:                 // to get the lock. First get inode lock and then fs lock.
   988:                 fs.mu.Unlock()
   989:                 child.Lock()
   990:                 // Acquiring fs lock early to use common defer function even though it is
   991:                 // not required to check if local file inode has been unlinked.
   992:                 // Filesystem lock will be held till we increment lookUpCount to avoid
   993:                 // deletion of inode from fs.inodes/fs.localFileInodes map by other flows.
   994:                 fs.mu.Lock()
   995:                 // Check if local file inode has been unlinked?
   996:                 fileInode, ok := child.(*inode.FileInode)
   997:                 if ok && fileInode.IsUnlinked() {
   998:                         child.Unlock()
   999:                         child = nil
  1000:                         return
  1001:                 }
  1002:                 // Once we get fs lock, validate if the inode is still valid. If not
  1003:                 // try to fetch it again. Eg: If the inode is deleted by other thread after
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:916 (PC: 0x193844e)
Values returned:
        child: github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Inode nil

   896:                 fs.generationBackedInodes[in.Name()] = in.(inode.GenerationBackedInode)
   897:
   898:                 continue
   899:         }
   900: }
   901:
   902: // Look up the child with the given name within the parent, then return an
   903: // existing inode for that child or create a new one if necessary. Return
   904: // ENOENT if the child doesn't exist.
   905: //
   906: // Return the child locked, incrementing its lookup count.
   907: //
   908: // LOCKS_EXCLUDED(fs.mu)
   909: // LOCKS_EXCLUDED(parent)
   910: // LOCK_FUNCTION(child)
   911: func (fs *fileSystem) lookUpOrCreateChildInode(
   912:         ctx context.Context,
   913:         parent inode.DirInode,
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
=> 916:         child = fs.lookUpLocalFileInode(parent, childName)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:917 (PC: 0x1938458)
   897:
   898:                 continue
   899:         }
   900: }
   901:
   902: // Look up the child with the given name within the parent, then return an
   903: // existing inode for that child or create a new one if necessary. Return
   904: // ENOENT if the child doesn't exist.
   905: //
   906: // Return the child locked, incrementing its lookup count.
   907: //
   908: // LOCKS_EXCLUDED(fs.mu)
   909: // LOCKS_EXCLUDED(parent)
   910: // LOCK_FUNCTION(child)
   911: func (fs *fileSystem) lookUpOrCreateChildInode(
   912:         ctx context.Context,
   913:         parent inode.DirInode,
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
   916:         child = fs.lookUpLocalFileInode(parent, childName)
=> 917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
   937:                 core, err = getLookupResult()
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:926 (PC: 0x1938472)
   906: // Return the child locked, incrementing its lookup count.
   907: //
   908: // LOCKS_EXCLUDED(fs.mu)
   909: // LOCKS_EXCLUDED(parent)
   910: // LOCK_FUNCTION(child)
   911: func (fs *fileSystem) lookUpOrCreateChildInode(
   912:         ctx context.Context,
   913:         parent inode.DirInode,
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
   916:         child = fs.lookUpLocalFileInode(parent, childName)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
=> 926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
   937:                 core, err = getLookupResult()
   938:
   939:                 if err != nil {
   940:                         return
   941:                 }
   942:
   943:                 if core == nil {
   944:                         err = fuse.ENOENT
   945:                         return
   946:                 }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:934 (PC: 0x1938574)
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
   916:         child = fs.lookUpLocalFileInode(parent, childName)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
=> 934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
   937:                 core, err = getLookupResult()
   938:
   939:                 if err != nil {
   940:                         return
   941:                 }
   942:
   943:                 if core == nil {
   944:                         err = fuse.ENOENT
   945:                         return
   946:                 }
   947:
   948:                 // Attempt to create the inode. Return if successful.
   949:                 child = fs.lookUpOrCreateInodeIfNotStale(*core)
   950:                 if child != nil {
   951:                         return
   952:                 }
   953:         }
   954:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:936 (PC: 0x193858c)
   916:         child = fs.lookUpLocalFileInode(parent, childName)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
=> 936:                 var core *inode.Core
   937:                 core, err = getLookupResult()
   938:
   939:                 if err != nil {
   940:                         return
   941:                 }
   942:
   943:                 if core == nil {
   944:                         err = fuse.ENOENT
   945:                         return
   946:                 }
   947:
   948:                 // Attempt to create the inode. Return if successful.
   949:                 child = fs.lookUpOrCreateInodeIfNotStale(*core)
   950:                 if child != nil {
   951:                         return
   952:                 }
   953:         }
   954:
   955:         err = fmt.Errorf("cannot find %q in %q with %v tries", childName, parent.Name(), maxTries)
   956:         return
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:937 (PC: 0x1938595)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
=> 937:                 core, err = getLookupResult()
   938:
   939:                 if err != nil {
   940:                         return
   941:                 }
   942:
   943:                 if core == nil {
   944:                         err = fuse.ENOENT
   945:                         return
   946:                 }
   947:
   948:                 // Attempt to create the inode. Return if successful.
   949:                 child = fs.lookUpOrCreateInodeIfNotStale(*core)
   950:                 if child != nil {
   951:                         return
   952:                 }
   953:         }
   954:
   955:         err = fmt.Errorf("cannot find %q in %q with %v tries", childName, parent.Name(), maxTries)
   956:         return
   957: }
(dlv) s
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode.func1() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:926 (PC: 0x19389b6)
   906: // Return the child locked, incrementing its lookup count.
   907: //
   908: // LOCKS_EXCLUDED(fs.mu)
   909: // LOCKS_EXCLUDED(parent)
   910: // LOCK_FUNCTION(child)
   911: func (fs *fileSystem) lookUpOrCreateChildInode(
   912:         ctx context.Context,
   913:         parent inode.DirInode,
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
   916:         child = fs.lookUpLocalFileInode(parent, childName)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
=> 926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
   937:                 core, err = getLookupResult()
   938:
   939:                 if err != nil {
   940:                         return
   941:                 }
   942:
   943:                 if core == nil {
   944:                         err = fuse.ENOENT
   945:                         return
   946:                 }
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode.func1() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:927 (PC: 0x1938a0e)
   907: //
   908: // LOCKS_EXCLUDED(fs.mu)
   909: // LOCKS_EXCLUDED(parent)
   910: // LOCK_FUNCTION(child)
   911: func (fs *fileSystem) lookUpOrCreateChildInode(
   912:         ctx context.Context,
   913:         parent inode.DirInode,
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
   916:         child = fs.lookUpLocalFileInode(parent, childName)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
=> 927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
   937:                 core, err = getLookupResult()
   938:
   939:                 if err != nil {
   940:                         return
   941:                 }
   942:
   943:                 if core == nil {
   944:                         err = fuse.ENOENT
   945:                         return
   946:                 }
   947:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode.func1() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:928 (PC: 0x1938a23)
   908: // LOCKS_EXCLUDED(fs.mu)
   909: // LOCKS_EXCLUDED(parent)
   910: // LOCK_FUNCTION(child)
   911: func (fs *fileSystem) lookUpOrCreateChildInode(
   912:         ctx context.Context,
   913:         parent inode.DirInode,
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
   916:         child = fs.lookUpLocalFileInode(parent, childName)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
=> 928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
   937:                 core, err = getLookupResult()
   938:
   939:                 if err != nil {
   940:                         return
   941:                 }
   942:
   943:                 if core == nil {
   944:                         err = fuse.ENOENT
   945:                         return
   946:                 }
   947:
   948:                 // Attempt to create the inode. Return if successful.
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode.func1() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:929 (PC: 0x1938aca)
   909: // LOCKS_EXCLUDED(parent)
   910: // LOCK_FUNCTION(child)
   911: func (fs *fileSystem) lookUpOrCreateChildInode(
   912:         ctx context.Context,
   913:         parent inode.DirInode,
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
   916:         child = fs.lookUpLocalFileInode(parent, childName)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
=> 929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
   937:                 core, err = getLookupResult()
   938:
   939:                 if err != nil {
   940:                         return
   941:                 }
   942:
   943:                 if core == nil {
   944:                         err = fuse.ENOENT
   945:                         return
   946:                 }
   947:
   948:                 // Attempt to create the inode. Return if successful.
   949:                 child = fs.lookUpOrCreateInodeIfNotStale(*core)
(dlv) p childName
"a"
(dlv) s
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:437 (PC: 0x19179f6)
   417:         // Set up basic attributes.
   418:         attrs = d.attrs
   419:         attrs.Nlink = 1
   420:
   421:         return
   422: }
   423:
   424: func (d *dirInode) Bucket() *gcsx.SyncerBucket {
   425:         return d.bucket
   426: }
   427:
   428: // A suffix that can be used to unambiguously tag a file system name.
   429: // (Unambiguous because U+000A is not allowed in GCS object names.) This is
   430: // used to refer to the file/symlink in a (file/symlink, directory) pair with
   431: // conflicting object names.
   432: //
   433: // See also the notes on DirInode.LookUpChild.
   434: const ConflictingFileNameSuffix = "\n"
   435:
   436: // LOCKS_REQUIRED(d)
=> 437: func (d *dirInode) LookUpChild(ctx context.Context, name string) (*Core, error) {
   438:         // Is this a conflict marker name?
   439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:439 (PC: 0x1917a34)
   419:         attrs.Nlink = 1
   420:
   421:         return
   422: }
   423:
   424: func (d *dirInode) Bucket() *gcsx.SyncerBucket {
   425:         return d.bucket
   426: }
   427:
   428: // A suffix that can be used to unambiguously tag a file system name.
   429: // (Unambiguous because U+000A is not allowed in GCS object names.) This is
   430: // used to refer to the file/symlink in a (file/symlink, directory) pair with
   431: // conflicting object names.
   432: //
   433: // See also the notes on DirInode.LookUpChild.
   434: const ConflictingFileNameSuffix = "\n"
   435:
   436: // LOCKS_REQUIRED(d)
   437: func (d *dirInode) LookUpChild(ctx context.Context, name string) (*Core, error) {
   438:         // Is this a conflict marker name?
=> 439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:443 (PC: 0x1917b24)
   423:
   424: func (d *dirInode) Bucket() *gcsx.SyncerBucket {
   425:         return d.bucket
   426: }
   427:
   428: // A suffix that can be used to unambiguously tag a file system name.
   429: // (Unambiguous because U+000A is not allowed in GCS object names.) This is
   430: // used to refer to the file/symlink in a (file/symlink, directory) pair with
   431: // conflicting object names.
   432: //
   433: // See also the notes on DirInode.LookUpChild.
   434: const ConflictingFileNameSuffix = "\n"
   435:
   436: // LOCKS_REQUIRED(d)
   437: func (d *dirInode) LookUpChild(ctx context.Context, name string) (*Core, error) {
   438:         // Is this a conflict marker name?
   439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
=> 443:         var fileResult *Core
   444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:444 (PC: 0x1917b5a)
   424: func (d *dirInode) Bucket() *gcsx.SyncerBucket {
   425:         return d.bucket
   426: }
   427:
   428: // A suffix that can be used to unambiguously tag a file system name.
   429: // (Unambiguous because U+000A is not allowed in GCS object names.) This is
   430: // used to refer to the file/symlink in a (file/symlink, directory) pair with
   431: // conflicting object names.
   432: //
   433: // See also the notes on DirInode.LookUpChild.
   434: const ConflictingFileNameSuffix = "\n"
   435:
   436: // LOCKS_REQUIRED(d)
   437: func (d *dirInode) LookUpChild(ctx context.Context, name string) (*Core, error) {
   438:         // Is this a conflict marker name?
   439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
=> 444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:445 (PC: 0x1917b91)
   425:         return d.bucket
   426: }
   427:
   428: // A suffix that can be used to unambiguously tag a file system name.
   429: // (Unambiguous because U+000A is not allowed in GCS object names.) This is
   430: // used to refer to the file/symlink in a (file/symlink, directory) pair with
   431: // conflicting object names.
   432: //
   433: // See also the notes on DirInode.LookUpChild.
   434: const ConflictingFileNameSuffix = "\n"
   435:
   436: // LOCKS_REQUIRED(d)
   437: func (d *dirInode) LookUpChild(ctx context.Context, name string) (*Core, error) {
   438:         // Is this a conflict marker name?
   439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
=> 445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:449 (PC: 0x1917c6d)
   429: // (Unambiguous because U+000A is not allowed in GCS object names.) This is
   430: // used to refer to the file/symlink in a (file/symlink, directory) pair with
   431: // conflicting object names.
   432: //
   433: // See also the notes on DirInode.LookUpChild.
   434: const ConflictingFileNameSuffix = "\n"
   435:
   436: // LOCKS_REQUIRED(d)
   437: func (d *dirInode) LookUpChild(ctx context.Context, name string) (*Core, error) {
   438:         // Is this a conflict marker name?
   439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
=> 449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:453 (PC: 0x1917d48)
   433: // See also the notes on DirInode.LookUpChild.
   434: const ConflictingFileNameSuffix = "\n"
   435:
   436: // LOCKS_REQUIRED(d)
   437: func (d *dirInode) LookUpChild(ctx context.Context, name string) (*Core, error) {
   438:         // Is this a conflict marker name?
   439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
=> 453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:458 (PC: 0x1917e25)
   438:         // Is this a conflict marker name?
   439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
=> 458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
   476:                 if d.implicitDirs {
   477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:460 (PC: 0x1917e42)
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
=> 460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
   476:                 if d.implicitDirs {
   477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
   479:                         b.Add(lookUpExplicitDir)
   480:                 }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:461 (PC: 0x1917ec8)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
=> 461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
   476:                 if d.implicitDirs {
   477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
   479:                         b.Add(lookUpExplicitDir)
   480:                 }
   481:         }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:470 (PC: 0x1917ed1)
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
=> 470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
   476:                 if d.implicitDirs {
   477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
   479:                         b.Add(lookUpExplicitDir)
   480:                 }
   481:         }
   482:
   483:         if err := b.Join(); err != nil {
   484:                 return nil, err
   485:         }
   486:
   487:         var result *Core
   488:         if dirResult != nil {
   489:                 result = dirResult
   490:         } else if fileResult != nil {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:474 (PC: 0x1917ed8)
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
=> 474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
   476:                 if d.implicitDirs {
   477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
   479:                         b.Add(lookUpExplicitDir)
   480:                 }
   481:         }
   482:
   483:         if err := b.Join(); err != nil {
   484:                 return nil, err
   485:         }
   486:
   487:         var result *Core
   488:         if dirResult != nil {
   489:                 result = dirResult
   490:         } else if fileResult != nil {
   491:                 result = fileResult
   492:         }
   493:
   494:         if result != nil {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:475 (PC: 0x1917ee2)
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
=> 475:                 b.Add(lookUpFile)
   476:                 if d.implicitDirs {
   477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
   479:                         b.Add(lookUpExplicitDir)
   480:                 }
   481:         }
   482:
   483:         if err := b.Join(); err != nil {
   484:                 return nil, err
   485:         }
   486:
   487:         var result *Core
   488:         if dirResult != nil {
   489:                 result = dirResult
   490:         } else if fileResult != nil {
   491:                 result = fileResult
   492:         }
   493:
   494:         if result != nil {
   495:                 d.cache.Insert(d.cacheClock.Now(), name, result.Type())
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:476 (PC: 0x1917ef7)
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
=> 476:                 if d.implicitDirs {
   477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
   479:                         b.Add(lookUpExplicitDir)
   480:                 }
   481:         }
   482:
   483:         if err := b.Join(); err != nil {
   484:                 return nil, err
   485:         }
   486:
   487:         var result *Core
   488:         if dirResult != nil {
   489:                 result = dirResult
   490:         } else if fileResult != nil {
   491:                 result = fileResult
   492:         }
   493:
   494:         if result != nil {
   495:                 d.cache.Insert(d.cacheClock.Now(), name, result.Type())
   496:         } else if d.enableNonexistentTypeCache && cachedType == metadata.UnknownType {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:477 (PC: 0x1917f09)
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
   476:                 if d.implicitDirs {
=> 477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
   479:                         b.Add(lookUpExplicitDir)
   480:                 }
   481:         }
   482:
   483:         if err := b.Join(); err != nil {
   484:                 return nil, err
   485:         }
   486:
   487:         var result *Core
   488:         if dirResult != nil {
   489:                 result = dirResult
   490:         } else if fileResult != nil {
   491:                 result = fileResult
   492:         }
   493:
   494:         if result != nil {
   495:                 d.cache.Insert(d.cacheClock.Now(), name, result.Type())
   496:         } else if d.enableNonexistentTypeCache && cachedType == metadata.UnknownType {
   497:                 d.cache.Insert(d.cacheClock.Now(), name, metadata.NonexistentType)
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:446
Breakpoint 2 set at 0x19187f7 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func1() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:446
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:446 at 19187f7
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:450
Breakpoint 4 set at 0x1918637 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func2() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:450
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:450 at 1918637
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454
Breakpoint 6 set at 0x1918477 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func3() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454 at 1918477
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:488
Breakpoint 8 set at 0x1918202 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:488
(dlv) bp
Breakpoint runtime-fatal-throw (enabled) at 0x446804,0x446724,0x45f40e for (multiple functions)() <multiple locations>:0 (0)
Breakpoint unrecovered-panic (enabled) at 0x446cc4 for runtime.fatalpanic() /usr/lib/google-golang/src/runtime/panic.go:1219 (0)
        print runtime.curg._panic.arg
Breakpoint 1 (enabled) at 0x193b496 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 (1)
Breakpoint 2 (enabled) at 0x19187f7 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func1() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:446 (0)
Breakpoint 4 (enabled) at 0x1918637 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func2() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:450 (0)
Breakpoint 6 (enabled) at 0x1918477 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func3() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454 (0)
Breakpoint 8 (enabled) at 0x1918202 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:488 (0)
(dlv) l
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:477 (PC: 0x1917f09)
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
   476:                 if d.implicitDirs {
=> 477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
   479:                         b.Add(lookUpExplicitDir)
   480:                 }
   481:         }
   482:
   483:         if err := b.Join(); err != nil {
   484:                 return nil, err
   485:         }
   486:
   487:         var result *Core
   488:         if dirResult != nil {
   489:                 result = dirResult
   490:         } else if fileResult != nil {
   491:                 result = fileResult
   492:         }
   493:
   494:         if result != nil {
   495:                 d.cache.Insert(d.cacheClock.Now(), name, result.Type())
   496:         } else if d.enableNonexistentTypeCache && cachedType == metadata.UnknownType {
   497:                 d.cache.Insert(d.cacheClock.Now(), name, metadata.NonexistentType)
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func3() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454 (hits goroutine(401):1 total:1) (PC: 0x1918477)
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:476 (PC: 0x1917f34)
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
=> 476:                 if d.implicitDirs {
   477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
   479:                         b.Add(lookUpExplicitDir)
   480:                 }
   481:         }
   482:
   483:         if err := b.Join(); err != nil {
   484:                 return nil, err
   485:         }
   486:
   487:         var result *Core
   488:         if dirResult != nil {
   489:                 result = dirResult
   490:         } else if fileResult != nil {
   491:                 result = fileResult
   492:         }
   493:
   494:         if result != nil {
   495:                 d.cache.Insert(d.cacheClock.Now(), name, result.Type())
   496:         } else if d.enableNonexistentTypeCache && cachedType == metadata.UnknownType {
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:483 (PC: 0x19181a4)
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
   476:                 if d.implicitDirs {
   477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
   479:                         b.Add(lookUpExplicitDir)
   480:                 }
   481:         }
   482:
=> 483:         if err := b.Join(); err != nil {
   484:                 return nil, err
   485:         }
   486:
   487:         var result *Core
   488:         if dirResult != nil {
   489:                 result = dirResult
   490:         } else if fileResult != nil {
   491:                 result = fileResult
   492:         }
   493:
   494:         if result != nil {
   495:                 d.cache.Insert(d.cacheClock.Now(), name, result.Type())
   496:         } else if d.enableNonexistentTypeCache && cachedType == metadata.UnknownType {
   497:                 d.cache.Insert(d.cacheClock.Now(), name, metadata.NonexistentType)
   498:         }
   499:
   500:         return result, nil
   501: }
   502:
   503: // LOCKS_REQUIRED(d)
(dlv) b 494
Breakpoint 9 set at 0x191824a for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:494
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:487 (PC: 0x19181f9)
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
   476:                 if d.implicitDirs {
   477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
   479:                         b.Add(lookUpExplicitDir)
   480:                 }
   481:         }
   482:
   483:         if err := b.Join(); err != nil {
   484:                 return nil, err
   485:         }
   486:
=> 487:         var result *Core
   488:         if dirResult != nil {
   489:                 result = dirResult
   490:         } else if fileResult != nil {
   491:                 result = fileResult
   492:         }
   493:
   494:         if result != nil {
   495:                 d.cache.Insert(d.cacheClock.Now(), name, result.Type())
   496:         } else if d.enableNonexistentTypeCache && cachedType == metadata.UnknownType {
   497:                 d.cache.Insert(d.cacheClock.Now(), name, metadata.NonexistentType)
   498:         }
   499:
   500:         return result, nil
   501: }
   502:
   503: // LOCKS_REQUIRED(d)
   504: func (d *dirInode) ReadDescendants(ctx context.Context, limit int) (map[Name]*Core, error) {
   505:         var tok string
   506:         descendants := make(map[Name]*Core)
   507:         for {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:488 (hits goroutine(370):1 total:1) (PC: 0x1918202)
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
   476:                 if d.implicitDirs {
   477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
   479:                         b.Add(lookUpExplicitDir)
   480:                 }
   481:         }
   482:
   483:         if err := b.Join(); err != nil {
   484:                 return nil, err
   485:         }
   486:
   487:         var result *Core
=> 488:         if dirResult != nil {
   489:                 result = dirResult
   490:         } else if fileResult != nil {
   491:                 result = fileResult
   492:         }
   493:
   494:         if result != nil {
   495:                 d.cache.Insert(d.cacheClock.Now(), name, result.Type())
   496:         } else if d.enableNonexistentTypeCache && cachedType == metadata.UnknownType {
   497:                 d.cache.Insert(d.cacheClock.Now(), name, metadata.NonexistentType)
   498:         }
   499:
   500:         return result, nil
   501: }
   502:
   503: // LOCKS_REQUIRED(d)
   504: func (d *dirInode) ReadDescendants(ctx context.Context, limit int) (map[Name]*Core, error) {
   505:         var tok string
   506:         descendants := make(map[Name]*Core)
   507:         for {
   508:                 listing, err := d.bucket.ListObjects(ctx, &gcs.ListObjectsRequest{
(dlv) p result
*github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Core nil
(dlv) p dirResult
*github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Core nil
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:494 (hits goroutine(370):1 total:1) (PC: 0x191824a)
   474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
   476:                 if d.implicitDirs {
   477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
   479:                         b.Add(lookUpExplicitDir)
   480:                 }
   481:         }
   482:
   483:         if err := b.Join(); err != nil {
   484:                 return nil, err
   485:         }
   486:
   487:         var result *Core
   488:         if dirResult != nil {
   489:                 result = dirResult
   490:         } else if fileResult != nil {
   491:                 result = fileResult
   492:         }
   493:
=> 494:         if result != nil {
   495:                 d.cache.Insert(d.cacheClock.Now(), name, result.Type())
   496:         } else if d.enableNonexistentTypeCache && cachedType == metadata.UnknownType {
   497:                 d.cache.Insert(d.cacheClock.Now(), name, metadata.NonexistentType)
   498:         }
   499:
   500:         return result, nil
   501: }
   502:
   503: // LOCKS_REQUIRED(d)
   504: func (d *dirInode) ReadDescendants(ctx context.Context, limit int) (map[Name]*Core, error) {
   505:         var tok string
   506:         descendants := make(map[Name]*Core)
   507:         for {
   508:                 listing, err := d.bucket.ListObjects(ctx, &gcs.ListObjectsRequest{
   509:                         Delimiter:         "", // recursively
   510:                         Prefix:            d.Name().GcsObjectName(),
   511:                         ContinuationToken: tok,
   512:                         MaxResults:        limit + 1, // to exclude itself
   513:                 })
   514:                 if err != nil {
(dlv) p result
*github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Core nil
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode.func1() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:929 (PC: 0x1938b14)
Values returned:
        ~r0: *github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Core nil
        ~r1: error nil

   909: // LOCKS_EXCLUDED(parent)
   910: // LOCK_FUNCTION(child)
   911: func (fs *fileSystem) lookUpOrCreateChildInode(
   912:         ctx context.Context,
   913:         parent inode.DirInode,
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
   916:         child = fs.lookUpLocalFileInode(parent, childName)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
=> 929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
   937:                 core, err = getLookupResult()
   938:
   939:                 if err != nil {
   940:                         return
   941:                 }
   942:
   943:                 if core == nil {
   944:                         err = fuse.ENOENT
   945:                         return
   946:                 }
   947:
   948:                 // Attempt to create the inode. Return if successful.
   949:                 child = fs.lookUpOrCreateInodeIfNotStale(*core)
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:937 (PC: 0x19385b4)
Values returned:
        ~r0: *github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Core nil
        ~r1: error nil

   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
=> 937:                 core, err = getLookupResult()
   938:
   939:                 if err != nil {
   940:                         return
   941:                 }
   942:
   943:                 if core == nil {
   944:                         err = fuse.ENOENT
   945:                         return
   946:                 }
   947:
   948:                 // Attempt to create the inode. Return if successful.
   949:                 child = fs.lookUpOrCreateInodeIfNotStale(*core)
   950:                 if child != nil {
   951:                         return
   952:                 }
   953:         }
   954:
   955:         err = fmt.Errorf("cannot find %q in %q with %v tries", childName, parent.Name(), maxTries)
   956:         return
   957: }
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:939 (PC: 0x1938620)
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
   937:                 core, err = getLookupResult()
   938:
=> 939:                 if err != nil {
   940:                         return
   941:                 }
   942:
   943:                 if core == nil {
   944:                         err = fuse.ENOENT
   945:                         return
   946:                 }
   947:
   948:                 // Attempt to create the inode. Return if successful.
   949:                 child = fs.lookUpOrCreateInodeIfNotStale(*core)
   950:                 if child != nil {
   951:                         return
   952:                 }
   953:         }
   954:
   955:         err = fmt.Errorf("cannot find %q in %q with %v tries", childName, parent.Name(), maxTries)
   956:         return
   957: }
   958:
   959: // Look up the localFileInodes to check if a file with given name exists.
(dlv) p core
*github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Core nil
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:943 (PC: 0x193863a)
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
   937:                 core, err = getLookupResult()
   938:
   939:                 if err != nil {
   940:                         return
   941:                 }
   942:
=> 943:                 if core == nil {
   944:                         err = fuse.ENOENT
   945:                         return
   946:                 }
   947:
   948:                 // Attempt to create the inode. Return if successful.
   949:                 child = fs.lookUpOrCreateInodeIfNotStale(*core)
   950:                 if child != nil {
   951:                         return
   952:                 }
   953:         }
   954:
   955:         err = fmt.Errorf("cannot find %q in %q with %v tries", childName, parent.Name(), maxTries)
   956:         return
   957: }
   958:
   959: // Look up the localFileInodes to check if a file with given name exists.
   960: // Return inode if it exists, else return nil.
   961: // LOCKS_EXCLUDED(fs.mu)
   962: // LOCKS_EXCLUDED(parent)
   963: // UNLOCK_FUNCTION(fs.mu)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:944 (PC: 0x19386f5)
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
   937:                 core, err = getLookupResult()
   938:
   939:                 if err != nil {
   940:                         return
   941:                 }
   942:
   943:                 if core == nil {
=> 944:                         err = fuse.ENOENT
   945:                         return
   946:                 }
   947:
   948:                 // Attempt to create the inode. Return if successful.
   949:                 child = fs.lookUpOrCreateInodeIfNotStale(*core)
   950:                 if child != nil {
   951:                         return
   952:                 }
   953:         }
   954:
   955:         err = fmt.Errorf("cannot find %q in %q with %v tries", childName, parent.Name(), maxTries)
   956:         return
   957: }
   958:
   959: // Look up the localFileInodes to check if a file with given name exists.
   960: // Return inode if it exists, else return nil.
   961: // LOCKS_EXCLUDED(fs.mu)
   962: // LOCKS_EXCLUDED(parent)
   963: // UNLOCK_FUNCTION(fs.mu)
   964: // LOCK_FUNCTION(child)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:945 (PC: 0x193870d)
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
   937:                 core, err = getLookupResult()
   938:
   939:                 if err != nil {
   940:                         return
   941:                 }
   942:
   943:                 if core == nil {
   944:                         err = fuse.ENOENT
=> 945:                         return
   946:                 }
   947:
   948:                 // Attempt to create the inode. Return if successful.
   949:                 child = fs.lookUpOrCreateInodeIfNotStale(*core)
   950:                 if child != nil {
   951:                         return
   952:                 }
   953:         }
   954:
   955:         err = fmt.Errorf("cannot find %q in %q with %v tries", childName, parent.Name(), maxTries)
   956:         return
   957: }
   958:
   959: // Look up the localFileInodes to check if a file with given name exists.
   960: // Return inode if it exists, else return nil.
   961: // LOCKS_EXCLUDED(fs.mu)
   962: // LOCKS_EXCLUDED(parent)
   963: // UNLOCK_FUNCTION(fs.mu)
   964: // LOCK_FUNCTION(child)
   965: func (fs *fileSystem) lookUpLocalFileInode(parent inode.DirInode, childName string) (child inode.Inode) {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1330 (PC: 0x193b69f)
Values returned:
        child: github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Inode nil
        err: (unreadable invalid interface type)

  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
=>1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
  1345:
  1346:         return
  1347: }
  1348:
  1349: // LOCKS_EXCLUDED(fs.mu)
  1350: func (fs *fileSystem) GetInodeAttributes(
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1331 (PC: 0x193b740)
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
=>1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
  1345:
  1346:         return
  1347: }
  1348:
  1349: // LOCKS_EXCLUDED(fs.mu)
  1350: func (fs *fileSystem) GetInodeAttributes(
  1351:         ctx context.Context,
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1332 (PC: 0x193b747)
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
=>1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
  1345:
  1346:         return
  1347: }
  1348:
  1349: // LOCKS_EXCLUDED(fs.mu)
  1350: func (fs *fileSystem) GetInodeAttributes(
  1351:         ctx context.Context,
  1352:         op *fuseops.GetInodeAttributesOp) (err error) {
(dlv) p err
(unreadable invalid interface type)
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/wrappers.(*errorMapping).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/wrappers/error_mapping.go:126 (PC: 0x192a606)
Values returned:
        err: (unreadable invalid interface type)

   106: func (em *errorMapping) Destroy() {
   107:         defer em.handlePanic()
   108:
   109:         em.wrapped.Destroy()
   110: }
   111:
   112: func (em *errorMapping) StatFS(
   113:         ctx context.Context,
   114:         op *fuseops.StatFSOp) error {
   115:         defer em.handlePanic()
   116:
   117:         err := em.wrapped.StatFS(ctx, op)
   118:         return em.mapError("StatFS", err)
   119: }
   120:
   121: func (em *errorMapping) LookUpInode(
   122:         ctx context.Context,
   123:         op *fuseops.LookUpInodeOp) error {
   124:         defer em.handlePanic()
   125:
=> 126:         err := em.wrapped.LookUpInode(ctx, op)
   127:         return em.mapError("LookUpInode", err)
   128: }
   129:
   130: func (em *errorMapping) GetInodeAttributes(
   131:         ctx context.Context,
   132:         op *fuseops.GetInodeAttributesOp) error {
   133:         defer em.handlePanic()
   134:
   135:         err := em.wrapped.GetInodeAttributes(ctx, op)
   136:         return em.mapError("GetInodeAttributes", err)
   137: }
   138:
   139: func (em *errorMapping) SetInodeAttributes(
   140:         ctx context.Context,
   141:         op *fuseops.SetInodeAttributesOp) error {
   142:         defer em.handlePanic()
   143:
   144:         err := em.wrapped.SetInodeAttributes(ctx, op)
   145:         return em.mapError("SetInodeAttributes", err)
   146: }
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/wrappers.(*monitoring).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/wrappers/monitoring.go:156 (PC: 0x192f20b)
Values returned:
        ~r0: (unreadable invalid interface type)

   136:         wrapped fuseutil.FileSystem
   137: }
   138:
   139: func (fs *monitoring) Destroy() {
   140:         fs.wrapped.Destroy()
   141: }
   142:
   143: func (fs *monitoring) StatFS(
   144:         ctx context.Context,
   145:         op *fuseops.StatFSOp) error {
   146:         startTime := time.Now()
   147:         err := fs.wrapped.StatFS(ctx, op)
   148:         recordOp(ctx, "StatFS", startTime, err)
   149:         return err
   150: }
   151:
   152: func (fs *monitoring) LookUpInode(
   153:         ctx context.Context,
   154:         op *fuseops.LookUpInodeOp) error {
   155:         startTime := time.Now()
=> 156:         err := fs.wrapped.LookUpInode(ctx, op)
   157:         recordOp(ctx, "LookUpInode", startTime, err)
   158:         return err
   159: }
   160:
   161: func (fs *monitoring) GetInodeAttributes(
   162:         ctx context.Context,
   163:         op *fuseops.GetInodeAttributesOp) error {
   164:         startTime := time.Now()
   165:         err := fs.wrapped.GetInodeAttributes(ctx, op)
   166:         recordOp(ctx, "GetInodeAttributes", startTime, err)
   167:         return err
   168: }
   169:
   170: func (fs *monitoring) SetInodeAttributes(
   171:         ctx context.Context,
   172:         op *fuseops.SetInodeAttributesOp) error {
   173:         startTime := time.Now()
   174:         err := fs.wrapped.SetInodeAttributes(ctx, op)
   175:         recordOp(ctx, "SetInodeAttributes", startTime, err)
   176:         return err
(dlv) so
> github.com/jacobsa/fuse/fuseutil.(*fileSystemServer).handleOp() /usr/local/google/home/gargnitin/go/pkg/mod/github.com/jacobsa/fuse@v0.0.0-20231003132804-d0f3daf365c3/fuseutil/file_system.go:144 (PC: 0x19121a4)
Values returned:
        ~r0: (unreadable invalid interface type)

   124:                 }
   125:         }
   126: }
   127:
   128: func (s *fileSystemServer) handleOp(
   129:         c *fuse.Connection,
   130:         ctx context.Context,
   131:         op interface{}) {
   132:         defer s.opsInFlight.Done()
   133:
   134:         // Dispatch to the appropriate method.
   135:         var err error
   136:         switch typed := op.(type) {
   137:         default:
   138:                 err = fuse.ENOSYS
   139:
   140:         case *fuseops.StatFSOp:
   141:                 err = s.fs.StatFS(ctx, typed)
   142:
   143:         case *fuseops.LookUpInodeOp:
=> 144:                 err = s.fs.LookUpInode(ctx, typed)
   145:
   146:         case *fuseops.GetInodeAttributesOp:
   147:                 err = s.fs.GetInodeAttributes(ctx, typed)
   148:
   149:         case *fuseops.SetInodeAttributesOp:
   150:                 err = s.fs.SetInodeAttributes(ctx, typed)
   151:
   152:         case *fuseops.ForgetInodeOp:
   153:                 err = s.fs.ForgetInode(ctx, typed)
   154:
   155:         case *fuseops.BatchForgetOp:
   156:                 err = s.fs.BatchForget(ctx, typed)
   157:                 if err == fuse.ENOSYS {
   158:                         // Handle as a series of single-inode forget operations
   159:                         for _, entry := range typed.Entries {
   160:                                 err = s.fs.ForgetInode(ctx, &fuseops.ForgetInodeOp{
   161:                                         Inode:     entry.Inode,
   162:                                         N:         entry.N,
   163:                                         OpContext: typed.OpContext,
   164:                                 })
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 (hits goroutine(419):1 total:2) (PC: 0x193b496)
        breakpoint hit during stepout
[c] continue [s] stop here and cancel stepout, [f] finish stepout skipping all breakpoints? f
continuing...
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func1() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:446 (hits goroutine(433):1 total:1) (PC: 0x19187f7)
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func3() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454 (hits goroutine(434):1 total:2) (PC: 0x1918477)
> runtime.goexit() /usr/lib/google-golang/src/runtime/asm_amd64.s:1696 (PC: 0x4817c1)
Warning: debugging optimized function
Values returned:

  1676:
  1677: TEXT runtime·return0(SB), NOSPLIT, $0
  1678:         MOVL    $0, AX
  1679:         RET
  1680:
  1681:
  1682: // Called from cgo wrappers, this function returns g->m->curg.stack.hi.
  1683: // Must obey the gcc calling convention.
  1684: TEXT _cgo_topofstack(SB),NOSPLIT,$0
  1685:         get_tls(CX)
  1686:         MOVQ    g(CX), AX
  1687:         MOVQ    g_m(AX), AX
  1688:         MOVQ    m_curg(AX), AX
  1689:         MOVQ    (g_stack+stack_hi)(AX), AX
  1690:         RET
  1691:
  1692: // The top-most function running on a goroutine
  1693: // returns to goexit+PCQuantum.
  1694: TEXT runtime·goexit(SB),NOSPLIT|TOPFRAME|NOFRAME,$0-0
  1695:         BYTE    $0x90   // NOP
=>1696:         CALL    runtime·goexit1(SB)     // does not return
  1697:         // traceback from goexit1 must hit code range of goexit
  1698:         BYTE    $0x90   // NOP
  1699:
  1700: // This is called from .init_array and follows the platform, not Go, ABI.
  1701: TEXT runtime·addmoduledata(SB),NOSPLIT,$0-0
  1702:         PUSHQ   R15 // The access to global variables below implicitly uses R15, which is callee-save
  1703:         MOVQ    runtime·lastmoduledatap(SB), AX
  1704:         MOVQ    DI, moduledata_next(AX)
  1705:         MOVQ    DI, runtime·lastmoduledatap(SB)
  1706:         POPQ    R15
  1707:         RET
  1708:
  1709: // Initialize special registers then jump to sigpanic.
  1710: // This function is injected from the signal handler for panicking
  1711: // signals. It is quite painful to set X15 in the signal context,
  1712: // so we do it here.
  1713: TEXT ·sigpanic0(SB),NOSPLIT,$0-0
  1714:         get_tls(R14)
  1715:         MOVQ    g(R14), R14
  1716: #ifndef GOOS_plan9
(dlv) bp
Breakpoint runtime-fatal-throw (enabled) at 0x446804,0x446724,0x45f40e for (multiple functions)() <multiple locations>:0 (0)
Breakpoint unrecovered-panic (enabled) at 0x446cc4 for runtime.fatalpanic() /usr/lib/google-golang/src/runtime/panic.go:1219 (0)
        print runtime.curg._panic.arg
Breakpoint 1 (enabled) at 0x193b496 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 (2)
Breakpoint 2 (enabled) at 0x19187f7 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func1() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:446 (1)
Breakpoint 4 (enabled) at 0x1918637 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func2() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:450 (0)
Breakpoint 6 (enabled) at 0x1918477 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func3() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454 (2)
Breakpoint 8 (enabled) at 0x1918202 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:488 (1)
Breakpoint 9 (enabled) at 0x191824a for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:494 (1)
(dlv) q
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ sudo umount $mountpath ; ./creationSituation.sh 1 debug
+ echo Number of args: 2
Number of args: 2
+ debug=0
+ run=1
+ '[' 2 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 2 -gt 1 ']'
+ debug=1
+ '[' 1 -ne 0 ']'
+ echo 'Debugging ...'
Debugging ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 1 = 0 ']'
+ dlv debug --check-go-version=false /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/. -- --config-file=config.yml --foreground --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
WARNING: undefined behavior - Go version go0.0 is too old for this version of Delve (minimum supported version 1.19)
Type 'help' for list of commands.
(dlv) r
Process restarted with PID 4045723
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314
Breakpoint 1 set at 0x193b496 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148
Breakpoint 2 set at 0x19451d6 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2126
Breakpoint 3 set at 0x1944ed3 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2126
(dlv) config source-list-line-count 20
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:446
Breakpoint 4 set at 0x19187f7 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func1() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:446
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:450
Breakpoint 5 set at 0x1918637 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func2() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:450
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454
Breakpoint 6 set at 0x1918477 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func3() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:488
Breakpoint 7 set at 0x1918202 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:488
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:488 at 1918202
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284
Breakpoint 9 set at 0x18c248a for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286
Breakpoint 10 set at 0x18c2559 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290
Breakpoint 11 set at 0x18c266b for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293
Breakpoint 12 set at 0x18c2734 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262
Breakpoint 13 set at 0x18c21a8 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262
(dlv) bp
Breakpoint runtime-fatal-throw (enabled) at 0x446724,0x446804,0x45f40e for (multiple functions)() <multiple locations>:0 (0)
Breakpoint unrecovered-panic (enabled) at 0x446cc4 for runtime.fatalpanic() /usr/lib/google-golang/src/runtime/panic.go:1219 (0)
        print runtime.curg._panic.arg
Breakpoint 1 (enabled) at 0x193b496 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 (0)
Breakpoint 2 (enabled) at 0x19451d6 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148 (0)
Breakpoint 3 (enabled) at 0x1944ed3 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2126 (0)
Breakpoint 4 (enabled) at 0x19187f7 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func1() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:446 (0)
Breakpoint 5 (enabled) at 0x1918637 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func2() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:450 (0)
Breakpoint 6 (enabled) at 0x1918477 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func3() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454 (0)
Breakpoint 7 (enabled) at 0x1918202 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:488 (0)
Breakpoint 9 (enabled) at 0x18c248a for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284 (0)
Breakpoint 10 (enabled) at 0x18c2559 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286 (0)
Breakpoint 11 (enabled) at 0x18c266b for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290 (0)
Breakpoint 12 (enabled) at 0x18c2734 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293 (0)
Breakpoint 13 (enabled) at 0x18c21a8 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262 (0)
(dlv) c
{"timestamp":{"seconds":1714848051,"nanos":559982583},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262 (hits goroutine(1):1 total:1) (PC: 0x18c21a8)
   242:         // Default Projection value in jacobsa/gcloud library is 0 that maps to 1 in Go Client API interface, and that is for "full".
   243:         default:
   244:                 convertedProjection = storage.Projection(1)
   245:         }
   246:         return convertedProjection
   247: }
   248:
   249: func (b *bucketHandle) ListObjects(ctx context.Context, req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   250:         // Converting *ListObjectsRequest to type *storage.Query as expected by the Go Storage Client.
   251:         query := &storage.Query{
   252:                 Delimiter:                req.Delimiter,
   253:                 Prefix:                   req.Prefix,
   254:                 Projection:               getProjectionValue(req.ProjectionVal),
   255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
   256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
=> 262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
(dlv) q
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ sudo umount $mountpath ; ./creationSituation.sh 1 debug
umount: /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4: not mounted.
+ echo Number of args: 2
Number of args: 2
+ debug=0
+ run=1
+ '[' 2 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 2 -gt 1 ']'
+ debug=1
+ '[' 1 -ne 0 ']'
+ echo 'Debugging ...'
Debugging ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 1 = 0 ']'
+ dlv debug --check-go-version=false /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/. -- --config-file=config.yml --foreground --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
WARNING: undefined behavior - Go version go0.0 is too old for this version of Delve (minimum supported version 1.19)
Type 'help' for list of commands.
(dlv) r
Process restarted with PID 4049103
(dlv) c
{"timestamp":{"seconds":1714848071,"nanos":629150285},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x4835c3)
Warning: debugging optimized function
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262
Breakpoint 1 set at 0x18c21a8 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262 at 18c21a8
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262 at 18c21a8
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262 at 18c21a8
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284
Breakpoint 5 set at 0x18c248a for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284 at 18c248a
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286
Breakpoint 7 set at 0x18c2559 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286 at 18c2559
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290
Breakpoint 9 set at 0x18c266b for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290 at 18c266b
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293^C
(dlv) q
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ sudo umount $mountpath ; ./creationSituation.sh 1 debug
+ echo Number of args: 2
Number of args: 2
+ debug=0
+ run=1
+ '[' 2 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 2 -gt 1 ']'
+ debug=1
+ '[' 1 -ne 0 ']'
+ echo 'Debugging ...'
Debugging ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 1 = 0 ']'
+ dlv debug --check-go-version=false /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/. -- --config-file=config.yml --foreground --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
WARNING: undefined behavior - Go version go0.0 is too old for this version of Delve (minimum supported version 1.19)
Type 'help' for list of commands.
(dlv) bp
Breakpoint runtime-fatal-throw (enabled) at 0x45f40e,0x446724,0x446804 for (multiple functions)() <multiple locations>:0 (0)
Breakpoint unrecovered-panic (enabled) at 0x446cc4 for runtime.fatalpanic() /usr/lib/google-golang/src/runtime/panic.go:1219 (0)
        print runtime.curg._panic.arg
(dlv) r
Process restarted with PID 4050282
(dlv) c
{"timestamp":{"seconds":1714848128,"nanos":798505718},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x4835c3)
Warning: debugging optimized function
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262
Breakpoint 1 set at 0x18c21a8 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262 at 18c21a8
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262 at 18c21a8
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262 at 18c21a8
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284
Breakpoint 5 set at 0x18c248a for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284 at 18c248a
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286
Breakpoint 7 set at 0x18c2559 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286 at 18c2559
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290
Breakpoint 9 set at 0x18c266b for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290 at 18c266b
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293bp
Command failed: Malformed breakpoint location "/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293bp" at 113: line offset negative or not a number
(dlv) bp
Breakpoint runtime-fatal-throw (enabled) at 0x45f40e,0x446724,0x446804 for (multiple functions)() <multiple locations>:0 (0)
Breakpoint unrecovered-panic (enabled) at 0x446cc4 for runtime.fatalpanic() /usr/lib/google-golang/src/runtime/panic.go:1219 (0)
        print runtime.curg._panic.arg
Breakpoint 1 (enabled) at 0x18c21a8 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262 (0)
Breakpoint 5 (enabled) at 0x18c248a for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284 (0)
Breakpoint 7 (enabled) at 0x18c2559 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286 (0)
Breakpoint 9 (enabled) at 0x18c266b for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290 (0)
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:29
Command failed: could not find statement at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:29, please use a line with a statement
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293
Breakpoint 11 set at 0x18c2734 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode
Breakpoint 12 set at 0x193b496 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 at 193b496
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir
Breakpoint 14 set at 0x19451d6 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148 at 19451d6
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir
Breakpoint 16 set at 0x1944ed3 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2126
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:446
Breakpoint 17 set at 0x19187f7 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func1() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:446
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:446 at 19187f7
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:450
Breakpoint 19 set at 0x1918637 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func2() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:450
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:450 at 1918637
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454
Breakpoint 21 set at 0x1918477 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func3() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454 at 1918477
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:488
Breakpoint 23 set at 0x1918202 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:488
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 (hits goroutine(353):1 total:1) (PC: 0x193b496)
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
=>1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1317 (PC: 0x193b4c6)
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
=>1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1325 (PC: 0x193b5d2)
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
=>1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1326 (PC: 0x193b5ef)
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
=>1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1327 (PC: 0x193b621)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
=>1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1330 (PC: 0x193b63e)
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
=>1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
(dlv) s
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:911 (PC: 0x19383d6)
   906: // Return the child locked, incrementing its lookup count.
   907: //
   908: // LOCKS_EXCLUDED(fs.mu)
   909: // LOCKS_EXCLUDED(parent)
   910: // LOCK_FUNCTION(child)
=> 911: func (fs *fileSystem) lookUpOrCreateChildInode(
   912:         ctx context.Context,
   913:         parent inode.DirInode,
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
   916:         child = fs.lookUpLocalFileInode(parent, childName)
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:916 (PC: 0x1938421)
   911: func (fs *fileSystem) lookUpOrCreateChildInode(
   912:         ctx context.Context,
   913:         parent inode.DirInode,
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
=> 916:         child = fs.lookUpLocalFileInode(parent, childName)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:917 (PC: 0x1938458)
   912:         ctx context.Context,
   913:         parent inode.DirInode,
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
   916:         child = fs.lookUpLocalFileInode(parent, childName)
=> 917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
(dlv) p child
github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Inode nil
(dlv) q
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ sudo umount $mountpath ; ./creationSituation.sh 1 debug
+ echo Number of args: 2
Number of args: 2
+ debug=0
+ run=1
+ '[' 2 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 2 -gt 1 ']'
+ debug=1
+ '[' 1 -ne 0 ']'
+ echo 'Debugging ...'
Debugging ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 1 = 0 ']'
+ dlv debug --check-go-version=false /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/. -- --config-file=config.yml --foreground --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
WARNING: undefined behavior - Go version go0.0 is too old for this version of Delve (minimum supported version 1.19)
Type 'help' for list of commands.
(dlv) r
Process restarted with PID 4052977
(dlv) c
{"timestamp":{"seconds":1714848281,"nanos":117344760},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x4835c3)
Warning: debugging optimized function
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262
Breakpoint 1 set at 0x18c21a8 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262 at 18c21a8
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284
Breakpoint 3 set at 0x18c248a for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284 at 18c248a
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286
Breakpoint 5 set at 0x18c2559 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286 at 18c2559
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290
Breakpoint 7 set at 0x18c266b for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290 at 18c266b
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293
Breakpoint 9 set at 0x18c2734 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293 at 18c2734
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode
Breakpoint 11 set at 0x193b496 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 at 193b496
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir
Breakpoint 13 set at 0x19451d6 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148 at 19451d6
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir
Breakpoint 15 set at 0x1944ed3 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2126
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2126 at 1944ed3
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:446
Breakpoint 17 set at 0x19187f7 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func1() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:446
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:446 at 19187f7
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:450
Breakpoint 19 set at 0x1918637 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func2() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:450
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:450 at 1918637
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454
Breakpoint 21 set at 0x1918477 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func3() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454 at 1918477
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:488
Breakpoint 23 set at 0x1918202 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:488
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:488 at 1918202
(dlv) config source-list-line-count 20
(dlv) bp
Breakpoint runtime-fatal-throw (enabled) at 0x446724,0x446804,0x45f40e for (multiple functions)() <multiple locations>:0 (0)
Breakpoint unrecovered-panic (enabled) at 0x446cc4 for runtime.fatalpanic() /usr/lib/google-golang/src/runtime/panic.go:1219 (0)
        print runtime.curg._panic.arg
Breakpoint 1 (enabled) at 0x18c21a8 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262 (0)
Breakpoint 3 (enabled) at 0x18c248a for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:284 (0)
Breakpoint 5 (enabled) at 0x18c2559 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:286 (0)
Breakpoint 7 (enabled) at 0x18c266b for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290 (0)
Breakpoint 9 (enabled) at 0x18c2734 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:293 (0)
Breakpoint 11 (enabled) at 0x193b496 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 (0)
Breakpoint 13 (enabled) at 0x19451d6 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148 (0)
Breakpoint 15 (enabled) at 0x1944ed3 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2126 (0)
Breakpoint 17 (enabled) at 0x19187f7 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func1() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:446 (0)
Breakpoint 19 (enabled) at 0x1918637 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func2() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:450 (0)
Breakpoint 21 (enabled) at 0x1918477 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func3() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454 (0)
Breakpoint 23 (enabled) at 0x1918202 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:488 (0)
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 (hits goroutine(373):1 total:1) (PC: 0x193b496)
  1294:         // Simulate a large amount of free space so that the Finder doesn't refuse to
  1295:         // copy in files. (See issue #125.) Use 2^17 as the block size because that
  1296:         // is the largest that OS X will pass on.
  1297:         op.BlockSize = 1 << 17
  1298:         op.Blocks = 1 << 33
  1299:         op.BlocksFree = op.Blocks
  1300:         op.BlocksAvailable = op.Blocks
  1301:
  1302:         // Similarly with inodes.
  1303:         op.Inodes = 1 << 50
  1304:         op.InodesFree = op.Inodes
  1305:
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
=>1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1317 (PC: 0x193b4c6)
  1297:         op.BlockSize = 1 << 17
  1298:         op.Blocks = 1 << 33
  1299:         op.BlocksFree = op.Blocks
  1300:         op.BlocksAvailable = op.Blocks
  1301:
  1302:         // Similarly with inodes.
  1303:         op.Inodes = 1 << 50
  1304:         op.InodesFree = op.Inodes
  1305:
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
=>1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1325 (PC: 0x193b5d2)
  1305:
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
=>1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
  1345:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1326 (PC: 0x193b5ef)
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
=>1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
  1345:
  1346:         return
(dlv) s
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).dirInodeOrDie() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1217 (PC: 0x193a7d3)
  1197:         return
  1198: }
  1199:
  1200: // inodeOrDie returns the inode with the given ID, panicking with a helpful
  1201: // error message if it doesn't exist.
  1202: //
  1203: // LOCKS_REQUIRED(fs.mu)
  1204: func (fs *fileSystem) inodeOrDie(id fuseops.InodeID) (in inode.Inode) {
  1205:         in = fs.inodes[id]
  1206:         if in == nil {
  1207:                 panic(fmt.Sprintf("inode %d doesn't exist", id))
  1208:         }
  1209:
  1210:         return
  1211: }
  1212:
  1213: // dirInodeOrDie returns the directory inode with the given ID, panicking with
  1214: // a helpful error message if it doesn't exist or is the wrong type.
  1215: //
  1216: // LOCKS_REQUIRED(fs.mu)
=>1217: func (fs *fileSystem) dirInodeOrDie(id fuseops.InodeID) (in inode.DirInode) {
  1218:         tmp := fs.inodes[id]
  1219:         in, ok := tmp.(inode.DirInode)
  1220:         if !ok {
  1221:                 panic(fmt.Sprintf("inode %d is %T, wanted inode.DirInode", id, tmp))
  1222:         }
  1223:
  1224:         return
  1225: }
  1226:
  1227: // fileInodeOrDie returns the file inode with the given ID, panicking with a
  1228: // helpful error message if it doesn't exist or is the wrong type.
  1229: //
  1230: // LOCKS_REQUIRED(fs.mu)
  1231: func (fs *fileSystem) fileInodeOrDie(id fuseops.InodeID) (in *inode.FileInode) {
  1232:         tmp := fs.inodes[id]
  1233:         in, ok := tmp.(*inode.FileInode)
  1234:         if !ok {
  1235:                 panic(fmt.Sprintf("inode %d is %T, wanted *inode.FileInode", id, tmp))
  1236:         }
  1237:
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).dirInodeOrDie() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1218 (PC: 0x193a7f0)
  1198: }
  1199:
  1200: // inodeOrDie returns the inode with the given ID, panicking with a helpful
  1201: // error message if it doesn't exist.
  1202: //
  1203: // LOCKS_REQUIRED(fs.mu)
  1204: func (fs *fileSystem) inodeOrDie(id fuseops.InodeID) (in inode.Inode) {
  1205:         in = fs.inodes[id]
  1206:         if in == nil {
  1207:                 panic(fmt.Sprintf("inode %d doesn't exist", id))
  1208:         }
  1209:
  1210:         return
  1211: }
  1212:
  1213: // dirInodeOrDie returns the directory inode with the given ID, panicking with
  1214: // a helpful error message if it doesn't exist or is the wrong type.
  1215: //
  1216: // LOCKS_REQUIRED(fs.mu)
  1217: func (fs *fileSystem) dirInodeOrDie(id fuseops.InodeID) (in inode.DirInode) {
=>1218:         tmp := fs.inodes[id]
  1219:         in, ok := tmp.(inode.DirInode)
  1220:         if !ok {
  1221:                 panic(fmt.Sprintf("inode %d is %T, wanted inode.DirInode", id, tmp))
  1222:         }
  1223:
  1224:         return
  1225: }
  1226:
  1227: // fileInodeOrDie returns the file inode with the given ID, panicking with a
  1228: // helpful error message if it doesn't exist or is the wrong type.
  1229: //
  1230: // LOCKS_REQUIRED(fs.mu)
  1231: func (fs *fileSystem) fileInodeOrDie(id fuseops.InodeID) (in *inode.FileInode) {
  1232:         tmp := fs.inodes[id]
  1233:         in, ok := tmp.(*inode.FileInode)
  1234:         if !ok {
  1235:                 panic(fmt.Sprintf("inode %d is %T, wanted *inode.FileInode", id, tmp))
  1236:         }
  1237:
  1238:         return
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1326 (PC: 0x193b611)
Values returned:
        in: (unreadable invalid interface type)

  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
=>1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
  1345:
  1346:         return
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1327 (PC: 0x193b621)
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
=>1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
  1345:
  1346:         return
  1347: }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1330 (PC: 0x193b63e)
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
=>1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
  1345:
  1346:         return
  1347: }
  1348:
  1349: // LOCKS_EXCLUDED(fs.mu)
  1350: func (fs *fileSystem) GetInodeAttributes(
(dlv) s
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:911 (PC: 0x19383d6)
   891:                 // Replace it with a newly-mintend inode and then go around, acquiring its
   892:                 // lock in accordance with our lock ordering rules.
   893:                 existingInode.Unlock()
   894:
   895:                 in = fs.mintInode(ic)
   896:                 fs.generationBackedInodes[in.Name()] = in.(inode.GenerationBackedInode)
   897:
   898:                 continue
   899:         }
   900: }
   901:
   902: // Look up the child with the given name within the parent, then return an
   903: // existing inode for that child or create a new one if necessary. Return
   904: // ENOENT if the child doesn't exist.
   905: //
   906: // Return the child locked, incrementing its lookup count.
   907: //
   908: // LOCKS_EXCLUDED(fs.mu)
   909: // LOCKS_EXCLUDED(parent)
   910: // LOCK_FUNCTION(child)
=> 911: func (fs *fileSystem) lookUpOrCreateChildInode(
   912:         ctx context.Context,
   913:         parent inode.DirInode,
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
   916:         child = fs.lookUpLocalFileInode(parent, childName)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:916 (PC: 0x1938421)
   896:                 fs.generationBackedInodes[in.Name()] = in.(inode.GenerationBackedInode)
   897:
   898:                 continue
   899:         }
   900: }
   901:
   902: // Look up the child with the given name within the parent, then return an
   903: // existing inode for that child or create a new one if necessary. Return
   904: // ENOENT if the child doesn't exist.
   905: //
   906: // Return the child locked, incrementing its lookup count.
   907: //
   908: // LOCKS_EXCLUDED(fs.mu)
   909: // LOCKS_EXCLUDED(parent)
   910: // LOCK_FUNCTION(child)
   911: func (fs *fileSystem) lookUpOrCreateChildInode(
   912:         ctx context.Context,
   913:         parent inode.DirInode,
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
=> 916:         child = fs.lookUpLocalFileInode(parent, childName)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
(dlv) s
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpLocalFileInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:965 (PC: 0x1938c56)
   945:                         return
   946:                 }
   947:
   948:                 // Attempt to create the inode. Return if successful.
   949:                 child = fs.lookUpOrCreateInodeIfNotStale(*core)
   950:                 if child != nil {
   951:                         return
   952:                 }
   953:         }
   954:
   955:         err = fmt.Errorf("cannot find %q in %q with %v tries", childName, parent.Name(), maxTries)
   956:         return
   957: }
   958:
   959: // Look up the localFileInodes to check if a file with given name exists.
   960: // Return inode if it exists, else return nil.
   961: // LOCKS_EXCLUDED(fs.mu)
   962: // LOCKS_EXCLUDED(parent)
   963: // UNLOCK_FUNCTION(fs.mu)
   964: // LOCK_FUNCTION(child)
=> 965: func (fs *fileSystem) lookUpLocalFileInode(parent inode.DirInode, childName string) (child inode.Inode) {
   966:         defer func() {
   967:                 if child != nil {
   968:                         child.IncrementLookupCount()
   969:                 }
   970:                 fs.mu.Unlock()
   971:         }()
   972:
   973:         // Trim the suffix assigned to fix conflicting names.
   974:         childName = strings.TrimSuffix(childName, inode.ConflictingFileNameSuffix)
   975:         fileName := inode.NewFileName(parent.Name(), childName)
   976:
   977:         fs.mu.Lock()
   978:         var maxTriesToLookupInode = 3
   979:         for n := 0; n < maxTriesToLookupInode; n++ {
   980:                 child = fs.localFileInodes[fileName]
   981:
   982:                 if child == nil {
   983:                         return
   984:                 }
   985:
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpLocalFileInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:966 (PC: 0x1938c8e)
   946:                 }
   947:
   948:                 // Attempt to create the inode. Return if successful.
   949:                 child = fs.lookUpOrCreateInodeIfNotStale(*core)
   950:                 if child != nil {
   951:                         return
   952:                 }
   953:         }
   954:
   955:         err = fmt.Errorf("cannot find %q in %q with %v tries", childName, parent.Name(), maxTries)
   956:         return
   957: }
   958:
   959: // Look up the localFileInodes to check if a file with given name exists.
   960: // Return inode if it exists, else return nil.
   961: // LOCKS_EXCLUDED(fs.mu)
   962: // LOCKS_EXCLUDED(parent)
   963: // UNLOCK_FUNCTION(fs.mu)
   964: // LOCK_FUNCTION(child)
   965: func (fs *fileSystem) lookUpLocalFileInode(parent inode.DirInode, childName string) (child inode.Inode) {
=> 966:         defer func() {
   967:                 if child != nil {
   968:                         child.IncrementLookupCount()
   969:                 }
   970:                 fs.mu.Unlock()
   971:         }()
   972:
   973:         // Trim the suffix assigned to fix conflicting names.
   974:         childName = strings.TrimSuffix(childName, inode.ConflictingFileNameSuffix)
   975:         fileName := inode.NewFileName(parent.Name(), childName)
   976:
   977:         fs.mu.Lock()
   978:         var maxTriesToLookupInode = 3
   979:         for n := 0; n < maxTriesToLookupInode; n++ {
   980:                 child = fs.localFileInodes[fileName]
   981:
   982:                 if child == nil {
   983:                         return
   984:                 }
   985:
   986:                 // If the inode already exists, we need to follow the lock ordering rules
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpLocalFileInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:974 (PC: 0x1938d3a)
   954:
   955:         err = fmt.Errorf("cannot find %q in %q with %v tries", childName, parent.Name(), maxTries)
   956:         return
   957: }
   958:
   959: // Look up the localFileInodes to check if a file with given name exists.
   960: // Return inode if it exists, else return nil.
   961: // LOCKS_EXCLUDED(fs.mu)
   962: // LOCKS_EXCLUDED(parent)
   963: // UNLOCK_FUNCTION(fs.mu)
   964: // LOCK_FUNCTION(child)
   965: func (fs *fileSystem) lookUpLocalFileInode(parent inode.DirInode, childName string) (child inode.Inode) {
   966:         defer func() {
   967:                 if child != nil {
   968:                         child.IncrementLookupCount()
   969:                 }
   970:                 fs.mu.Unlock()
   971:         }()
   972:
   973:         // Trim the suffix assigned to fix conflicting names.
=> 974:         childName = strings.TrimSuffix(childName, inode.ConflictingFileNameSuffix)
   975:         fileName := inode.NewFileName(parent.Name(), childName)
   976:
   977:         fs.mu.Lock()
   978:         var maxTriesToLookupInode = 3
   979:         for n := 0; n < maxTriesToLookupInode; n++ {
   980:                 child = fs.localFileInodes[fileName]
   981:
   982:                 if child == nil {
   983:                         return
   984:                 }
   985:
   986:                 // If the inode already exists, we need to follow the lock ordering rules
   987:                 // to get the lock. First get inode lock and then fs lock.
   988:                 fs.mu.Unlock()
   989:                 child.Lock()
   990:                 // Acquiring fs lock early to use common defer function even though it is
   991:                 // not required to check if local file inode has been unlinked.
   992:                 // Filesystem lock will be held till we increment lookUpCount to avoid
   993:                 // deletion of inode from fs.inodes/fs.localFileInodes map by other flows.
   994:                 fs.mu.Lock()
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpLocalFileInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:975 (PC: 0x1938d6b)
   955:         err = fmt.Errorf("cannot find %q in %q with %v tries", childName, parent.Name(), maxTries)
   956:         return
   957: }
   958:
   959: // Look up the localFileInodes to check if a file with given name exists.
   960: // Return inode if it exists, else return nil.
   961: // LOCKS_EXCLUDED(fs.mu)
   962: // LOCKS_EXCLUDED(parent)
   963: // UNLOCK_FUNCTION(fs.mu)
   964: // LOCK_FUNCTION(child)
   965: func (fs *fileSystem) lookUpLocalFileInode(parent inode.DirInode, childName string) (child inode.Inode) {
   966:         defer func() {
   967:                 if child != nil {
   968:                         child.IncrementLookupCount()
   969:                 }
   970:                 fs.mu.Unlock()
   971:         }()
   972:
   973:         // Trim the suffix assigned to fix conflicting names.
   974:         childName = strings.TrimSuffix(childName, inode.ConflictingFileNameSuffix)
=> 975:         fileName := inode.NewFileName(parent.Name(), childName)
   976:
   977:         fs.mu.Lock()
   978:         var maxTriesToLookupInode = 3
   979:         for n := 0; n < maxTriesToLookupInode; n++ {
   980:                 child = fs.localFileInodes[fileName]
   981:
   982:                 if child == nil {
   983:                         return
   984:                 }
   985:
   986:                 // If the inode already exists, we need to follow the lock ordering rules
   987:                 // to get the lock. First get inode lock and then fs lock.
   988:                 fs.mu.Unlock()
   989:                 child.Lock()
   990:                 // Acquiring fs lock early to use common defer function even though it is
   991:                 // not required to check if local file inode has been unlinked.
   992:                 // Filesystem lock will be held till we increment lookUpCount to avoid
   993:                 // deletion of inode from fs.inodes/fs.localFileInodes map by other flows.
   994:                 fs.mu.Lock()
   995:                 // Check if local file inode has been unlinked?
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpLocalFileInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:977 (PC: 0x1938dd8)
   957: }
   958:
   959: // Look up the localFileInodes to check if a file with given name exists.
   960: // Return inode if it exists, else return nil.
   961: // LOCKS_EXCLUDED(fs.mu)
   962: // LOCKS_EXCLUDED(parent)
   963: // UNLOCK_FUNCTION(fs.mu)
   964: // LOCK_FUNCTION(child)
   965: func (fs *fileSystem) lookUpLocalFileInode(parent inode.DirInode, childName string) (child inode.Inode) {
   966:         defer func() {
   967:                 if child != nil {
   968:                         child.IncrementLookupCount()
   969:                 }
   970:                 fs.mu.Unlock()
   971:         }()
   972:
   973:         // Trim the suffix assigned to fix conflicting names.
   974:         childName = strings.TrimSuffix(childName, inode.ConflictingFileNameSuffix)
   975:         fileName := inode.NewFileName(parent.Name(), childName)
   976:
=> 977:         fs.mu.Lock()
   978:         var maxTriesToLookupInode = 3
   979:         for n := 0; n < maxTriesToLookupInode; n++ {
   980:                 child = fs.localFileInodes[fileName]
   981:
   982:                 if child == nil {
   983:                         return
   984:                 }
   985:
   986:                 // If the inode already exists, we need to follow the lock ordering rules
   987:                 // to get the lock. First get inode lock and then fs lock.
   988:                 fs.mu.Unlock()
   989:                 child.Lock()
   990:                 // Acquiring fs lock early to use common defer function even though it is
   991:                 // not required to check if local file inode has been unlinked.
   992:                 // Filesystem lock will be held till we increment lookUpCount to avoid
   993:                 // deletion of inode from fs.inodes/fs.localFileInodes map by other flows.
   994:                 fs.mu.Lock()
   995:                 // Check if local file inode has been unlinked?
   996:                 fileInode, ok := child.(*inode.FileInode)
   997:                 if ok && fileInode.IsUnlinked() {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpLocalFileInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:978 (PC: 0x1938df5)
   958:
   959: // Look up the localFileInodes to check if a file with given name exists.
   960: // Return inode if it exists, else return nil.
   961: // LOCKS_EXCLUDED(fs.mu)
   962: // LOCKS_EXCLUDED(parent)
   963: // UNLOCK_FUNCTION(fs.mu)
   964: // LOCK_FUNCTION(child)
   965: func (fs *fileSystem) lookUpLocalFileInode(parent inode.DirInode, childName string) (child inode.Inode) {
   966:         defer func() {
   967:                 if child != nil {
   968:                         child.IncrementLookupCount()
   969:                 }
   970:                 fs.mu.Unlock()
   971:         }()
   972:
   973:         // Trim the suffix assigned to fix conflicting names.
   974:         childName = strings.TrimSuffix(childName, inode.ConflictingFileNameSuffix)
   975:         fileName := inode.NewFileName(parent.Name(), childName)
   976:
   977:         fs.mu.Lock()
=> 978:         var maxTriesToLookupInode = 3
   979:         for n := 0; n < maxTriesToLookupInode; n++ {
   980:                 child = fs.localFileInodes[fileName]
   981:
   982:                 if child == nil {
   983:                         return
   984:                 }
   985:
   986:                 // If the inode already exists, we need to follow the lock ordering rules
   987:                 // to get the lock. First get inode lock and then fs lock.
   988:                 fs.mu.Unlock()
   989:                 child.Lock()
   990:                 // Acquiring fs lock early to use common defer function even though it is
   991:                 // not required to check if local file inode has been unlinked.
   992:                 // Filesystem lock will be held till we increment lookUpCount to avoid
   993:                 // deletion of inode from fs.inodes/fs.localFileInodes map by other flows.
   994:                 fs.mu.Lock()
   995:                 // Check if local file inode has been unlinked?
   996:                 fileInode, ok := child.(*inode.FileInode)
   997:                 if ok && fileInode.IsUnlinked() {
   998:                         child.Unlock()
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpLocalFileInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:979 (PC: 0x1938dfe)
   959: // Look up the localFileInodes to check if a file with given name exists.
   960: // Return inode if it exists, else return nil.
   961: // LOCKS_EXCLUDED(fs.mu)
   962: // LOCKS_EXCLUDED(parent)
   963: // UNLOCK_FUNCTION(fs.mu)
   964: // LOCK_FUNCTION(child)
   965: func (fs *fileSystem) lookUpLocalFileInode(parent inode.DirInode, childName string) (child inode.Inode) {
   966:         defer func() {
   967:                 if child != nil {
   968:                         child.IncrementLookupCount()
   969:                 }
   970:                 fs.mu.Unlock()
   971:         }()
   972:
   973:         // Trim the suffix assigned to fix conflicting names.
   974:         childName = strings.TrimSuffix(childName, inode.ConflictingFileNameSuffix)
   975:         fileName := inode.NewFileName(parent.Name(), childName)
   976:
   977:         fs.mu.Lock()
   978:         var maxTriesToLookupInode = 3
=> 979:         for n := 0; n < maxTriesToLookupInode; n++ {
   980:                 child = fs.localFileInodes[fileName]
   981:
   982:                 if child == nil {
   983:                         return
   984:                 }
   985:
   986:                 // If the inode already exists, we need to follow the lock ordering rules
   987:                 // to get the lock. First get inode lock and then fs lock.
   988:                 fs.mu.Unlock()
   989:                 child.Lock()
   990:                 // Acquiring fs lock early to use common defer function even though it is
   991:                 // not required to check if local file inode has been unlinked.
   992:                 // Filesystem lock will be held till we increment lookUpCount to avoid
   993:                 // deletion of inode from fs.inodes/fs.localFileInodes map by other flows.
   994:                 fs.mu.Lock()
   995:                 // Check if local file inode has been unlinked?
   996:                 fileInode, ok := child.(*inode.FileInode)
   997:                 if ok && fileInode.IsUnlinked() {
   998:                         child.Unlock()
   999:                         child = nil
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpLocalFileInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:980 (PC: 0x1938e38)
   960: // Return inode if it exists, else return nil.
   961: // LOCKS_EXCLUDED(fs.mu)
   962: // LOCKS_EXCLUDED(parent)
   963: // UNLOCK_FUNCTION(fs.mu)
   964: // LOCK_FUNCTION(child)
   965: func (fs *fileSystem) lookUpLocalFileInode(parent inode.DirInode, childName string) (child inode.Inode) {
   966:         defer func() {
   967:                 if child != nil {
   968:                         child.IncrementLookupCount()
   969:                 }
   970:                 fs.mu.Unlock()
   971:         }()
   972:
   973:         // Trim the suffix assigned to fix conflicting names.
   974:         childName = strings.TrimSuffix(childName, inode.ConflictingFileNameSuffix)
   975:         fileName := inode.NewFileName(parent.Name(), childName)
   976:
   977:         fs.mu.Lock()
   978:         var maxTriesToLookupInode = 3
   979:         for n := 0; n < maxTriesToLookupInode; n++ {
=> 980:                 child = fs.localFileInodes[fileName]
   981:
   982:                 if child == nil {
   983:                         return
   984:                 }
   985:
   986:                 // If the inode already exists, we need to follow the lock ordering rules
   987:                 // to get the lock. First get inode lock and then fs lock.
   988:                 fs.mu.Unlock()
   989:                 child.Lock()
   990:                 // Acquiring fs lock early to use common defer function even though it is
   991:                 // not required to check if local file inode has been unlinked.
   992:                 // Filesystem lock will be held till we increment lookUpCount to avoid
   993:                 // deletion of inode from fs.inodes/fs.localFileInodes map by other flows.
   994:                 fs.mu.Lock()
   995:                 // Check if local file inode has been unlinked?
   996:                 fileInode, ok := child.(*inode.FileInode)
   997:                 if ok && fileInode.IsUnlinked() {
   998:                         child.Unlock()
   999:                         child = nil
  1000:                         return
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpLocalFileInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:982 (PC: 0x1938ec0)
   962: // LOCKS_EXCLUDED(parent)
   963: // UNLOCK_FUNCTION(fs.mu)
   964: // LOCK_FUNCTION(child)
   965: func (fs *fileSystem) lookUpLocalFileInode(parent inode.DirInode, childName string) (child inode.Inode) {
   966:         defer func() {
   967:                 if child != nil {
   968:                         child.IncrementLookupCount()
   969:                 }
   970:                 fs.mu.Unlock()
   971:         }()
   972:
   973:         // Trim the suffix assigned to fix conflicting names.
   974:         childName = strings.TrimSuffix(childName, inode.ConflictingFileNameSuffix)
   975:         fileName := inode.NewFileName(parent.Name(), childName)
   976:
   977:         fs.mu.Lock()
   978:         var maxTriesToLookupInode = 3
   979:         for n := 0; n < maxTriesToLookupInode; n++ {
   980:                 child = fs.localFileInodes[fileName]
   981:
=> 982:                 if child == nil {
   983:                         return
   984:                 }
   985:
   986:                 // If the inode already exists, we need to follow the lock ordering rules
   987:                 // to get the lock. First get inode lock and then fs lock.
   988:                 fs.mu.Unlock()
   989:                 child.Lock()
   990:                 // Acquiring fs lock early to use common defer function even though it is
   991:                 // not required to check if local file inode has been unlinked.
   992:                 // Filesystem lock will be held till we increment lookUpCount to avoid
   993:                 // deletion of inode from fs.inodes/fs.localFileInodes map by other flows.
   994:                 fs.mu.Lock()
   995:                 // Check if local file inode has been unlinked?
   996:                 fileInode, ok := child.(*inode.FileInode)
   997:                 if ok && fileInode.IsUnlinked() {
   998:                         child.Unlock()
   999:                         child = nil
  1000:                         return
  1001:                 }
  1002:                 // Once we get fs lock, validate if the inode is still valid. If not
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpLocalFileInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:983 (PC: 0x19390e7)
   963: // UNLOCK_FUNCTION(fs.mu)
   964: // LOCK_FUNCTION(child)
   965: func (fs *fileSystem) lookUpLocalFileInode(parent inode.DirInode, childName string) (child inode.Inode) {
   966:         defer func() {
   967:                 if child != nil {
   968:                         child.IncrementLookupCount()
   969:                 }
   970:                 fs.mu.Unlock()
   971:         }()
   972:
   973:         // Trim the suffix assigned to fix conflicting names.
   974:         childName = strings.TrimSuffix(childName, inode.ConflictingFileNameSuffix)
   975:         fileName := inode.NewFileName(parent.Name(), childName)
   976:
   977:         fs.mu.Lock()
   978:         var maxTriesToLookupInode = 3
   979:         for n := 0; n < maxTriesToLookupInode; n++ {
   980:                 child = fs.localFileInodes[fileName]
   981:
   982:                 if child == nil {
=> 983:                         return
   984:                 }
   985:
   986:                 // If the inode already exists, we need to follow the lock ordering rules
   987:                 // to get the lock. First get inode lock and then fs lock.
   988:                 fs.mu.Unlock()
   989:                 child.Lock()
   990:                 // Acquiring fs lock early to use common defer function even though it is
   991:                 // not required to check if local file inode has been unlinked.
   992:                 // Filesystem lock will be held till we increment lookUpCount to avoid
   993:                 // deletion of inode from fs.inodes/fs.localFileInodes map by other flows.
   994:                 fs.mu.Lock()
   995:                 // Check if local file inode has been unlinked?
   996:                 fileInode, ok := child.(*inode.FileInode)
   997:                 if ok && fileInode.IsUnlinked() {
   998:                         child.Unlock()
   999:                         child = nil
  1000:                         return
  1001:                 }
  1002:                 // Once we get fs lock, validate if the inode is still valid. If not
  1003:                 // try to fetch it again. Eg: If the inode is deleted by other thread after
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:916 (PC: 0x193844e)
Values returned:
        child: github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Inode nil

   896:                 fs.generationBackedInodes[in.Name()] = in.(inode.GenerationBackedInode)
   897:
   898:                 continue
   899:         }
   900: }
   901:
   902: // Look up the child with the given name within the parent, then return an
   903: // existing inode for that child or create a new one if necessary. Return
   904: // ENOENT if the child doesn't exist.
   905: //
   906: // Return the child locked, incrementing its lookup count.
   907: //
   908: // LOCKS_EXCLUDED(fs.mu)
   909: // LOCKS_EXCLUDED(parent)
   910: // LOCK_FUNCTION(child)
   911: func (fs *fileSystem) lookUpOrCreateChildInode(
   912:         ctx context.Context,
   913:         parent inode.DirInode,
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
=> 916:         child = fs.lookUpLocalFileInode(parent, childName)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:917 (PC: 0x1938458)
   897:
   898:                 continue
   899:         }
   900: }
   901:
   902: // Look up the child with the given name within the parent, then return an
   903: // existing inode for that child or create a new one if necessary. Return
   904: // ENOENT if the child doesn't exist.
   905: //
   906: // Return the child locked, incrementing its lookup count.
   907: //
   908: // LOCKS_EXCLUDED(fs.mu)
   909: // LOCKS_EXCLUDED(parent)
   910: // LOCK_FUNCTION(child)
   911: func (fs *fileSystem) lookUpOrCreateChildInode(
   912:         ctx context.Context,
   913:         parent inode.DirInode,
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
   916:         child = fs.lookUpLocalFileInode(parent, childName)
=> 917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
   937:                 core, err = getLookupResult()
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:926 (PC: 0x1938472)
   906: // Return the child locked, incrementing its lookup count.
   907: //
   908: // LOCKS_EXCLUDED(fs.mu)
   909: // LOCKS_EXCLUDED(parent)
   910: // LOCK_FUNCTION(child)
   911: func (fs *fileSystem) lookUpOrCreateChildInode(
   912:         ctx context.Context,
   913:         parent inode.DirInode,
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
   916:         child = fs.lookUpLocalFileInode(parent, childName)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
=> 926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
   937:                 core, err = getLookupResult()
   938:
   939:                 if err != nil {
   940:                         return
   941:                 }
   942:
   943:                 if core == nil {
   944:                         err = fuse.ENOENT
   945:                         return
   946:                 }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:934 (PC: 0x1938574)
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
   916:         child = fs.lookUpLocalFileInode(parent, childName)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
=> 934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
   937:                 core, err = getLookupResult()
   938:
   939:                 if err != nil {
   940:                         return
   941:                 }
   942:
   943:                 if core == nil {
   944:                         err = fuse.ENOENT
   945:                         return
   946:                 }
   947:
   948:                 // Attempt to create the inode. Return if successful.
   949:                 child = fs.lookUpOrCreateInodeIfNotStale(*core)
   950:                 if child != nil {
   951:                         return
   952:                 }
   953:         }
   954:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:936 (PC: 0x193858c)
   916:         child = fs.lookUpLocalFileInode(parent, childName)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
=> 936:                 var core *inode.Core
   937:                 core, err = getLookupResult()
   938:
   939:                 if err != nil {
   940:                         return
   941:                 }
   942:
   943:                 if core == nil {
   944:                         err = fuse.ENOENT
   945:                         return
   946:                 }
   947:
   948:                 // Attempt to create the inode. Return if successful.
   949:                 child = fs.lookUpOrCreateInodeIfNotStale(*core)
   950:                 if child != nil {
   951:                         return
   952:                 }
   953:         }
   954:
   955:         err = fmt.Errorf("cannot find %q in %q with %v tries", childName, parent.Name(), maxTries)
   956:         return
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:937 (PC: 0x1938595)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
=> 937:                 core, err = getLookupResult()
   938:
   939:                 if err != nil {
   940:                         return
   941:                 }
   942:
   943:                 if core == nil {
   944:                         err = fuse.ENOENT
   945:                         return
   946:                 }
   947:
   948:                 // Attempt to create the inode. Return if successful.
   949:                 child = fs.lookUpOrCreateInodeIfNotStale(*core)
   950:                 if child != nil {
   951:                         return
   952:                 }
   953:         }
   954:
   955:         err = fmt.Errorf("cannot find %q in %q with %v tries", childName, parent.Name(), maxTries)
   956:         return
   957: }
(dlv) s
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode.func1() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:926 (PC: 0x19389b6)
   906: // Return the child locked, incrementing its lookup count.
   907: //
   908: // LOCKS_EXCLUDED(fs.mu)
   909: // LOCKS_EXCLUDED(parent)
   910: // LOCK_FUNCTION(child)
   911: func (fs *fileSystem) lookUpOrCreateChildInode(
   912:         ctx context.Context,
   913:         parent inode.DirInode,
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
   916:         child = fs.lookUpLocalFileInode(parent, childName)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
=> 926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
   937:                 core, err = getLookupResult()
   938:
   939:                 if err != nil {
   940:                         return
   941:                 }
   942:
   943:                 if core == nil {
   944:                         err = fuse.ENOENT
   945:                         return
   946:                 }
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode.func1() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:927 (PC: 0x1938a0e)
   907: //
   908: // LOCKS_EXCLUDED(fs.mu)
   909: // LOCKS_EXCLUDED(parent)
   910: // LOCK_FUNCTION(child)
   911: func (fs *fileSystem) lookUpOrCreateChildInode(
   912:         ctx context.Context,
   913:         parent inode.DirInode,
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
   916:         child = fs.lookUpLocalFileInode(parent, childName)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
=> 927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
   937:                 core, err = getLookupResult()
   938:
   939:                 if err != nil {
   940:                         return
   941:                 }
   942:
   943:                 if core == nil {
   944:                         err = fuse.ENOENT
   945:                         return
   946:                 }
   947:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode.func1() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:928 (PC: 0x1938a23)
   908: // LOCKS_EXCLUDED(fs.mu)
   909: // LOCKS_EXCLUDED(parent)
   910: // LOCK_FUNCTION(child)
   911: func (fs *fileSystem) lookUpOrCreateChildInode(
   912:         ctx context.Context,
   913:         parent inode.DirInode,
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
   916:         child = fs.lookUpLocalFileInode(parent, childName)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
=> 928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
   937:                 core, err = getLookupResult()
   938:
   939:                 if err != nil {
   940:                         return
   941:                 }
   942:
   943:                 if core == nil {
   944:                         err = fuse.ENOENT
   945:                         return
   946:                 }
   947:
   948:                 // Attempt to create the inode. Return if successful.
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode.func1() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:929 (PC: 0x1938aca)
   909: // LOCKS_EXCLUDED(parent)
   910: // LOCK_FUNCTION(child)
   911: func (fs *fileSystem) lookUpOrCreateChildInode(
   912:         ctx context.Context,
   913:         parent inode.DirInode,
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
   916:         child = fs.lookUpLocalFileInode(parent, childName)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
=> 929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
   937:                 core, err = getLookupResult()
   938:
   939:                 if err != nil {
   940:                         return
   941:                 }
   942:
   943:                 if core == nil {
   944:                         err = fuse.ENOENT
   945:                         return
   946:                 }
   947:
   948:                 // Attempt to create the inode. Return if successful.
   949:                 child = fs.lookUpOrCreateInodeIfNotStale(*core)
(dlv) s
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:437 (PC: 0x19179f6)
   417:         // Set up basic attributes.
   418:         attrs = d.attrs
   419:         attrs.Nlink = 1
   420:
   421:         return
   422: }
   423:
   424: func (d *dirInode) Bucket() *gcsx.SyncerBucket {
   425:         return d.bucket
   426: }
   427:
   428: // A suffix that can be used to unambiguously tag a file system name.
   429: // (Unambiguous because U+000A is not allowed in GCS object names.) This is
   430: // used to refer to the file/symlink in a (file/symlink, directory) pair with
   431: // conflicting object names.
   432: //
   433: // See also the notes on DirInode.LookUpChild.
   434: const ConflictingFileNameSuffix = "\n"
   435:
   436: // LOCKS_REQUIRED(d)
=> 437: func (d *dirInode) LookUpChild(ctx context.Context, name string) (*Core, error) {
   438:         // Is this a conflict marker name?
   439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:439 (PC: 0x1917a34)
   419:         attrs.Nlink = 1
   420:
   421:         return
   422: }
   423:
   424: func (d *dirInode) Bucket() *gcsx.SyncerBucket {
   425:         return d.bucket
   426: }
   427:
   428: // A suffix that can be used to unambiguously tag a file system name.
   429: // (Unambiguous because U+000A is not allowed in GCS object names.) This is
   430: // used to refer to the file/symlink in a (file/symlink, directory) pair with
   431: // conflicting object names.
   432: //
   433: // See also the notes on DirInode.LookUpChild.
   434: const ConflictingFileNameSuffix = "\n"
   435:
   436: // LOCKS_REQUIRED(d)
   437: func (d *dirInode) LookUpChild(ctx context.Context, name string) (*Core, error) {
   438:         // Is this a conflict marker name?
=> 439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:443 (PC: 0x1917b24)
   423:
   424: func (d *dirInode) Bucket() *gcsx.SyncerBucket {
   425:         return d.bucket
   426: }
   427:
   428: // A suffix that can be used to unambiguously tag a file system name.
   429: // (Unambiguous because U+000A is not allowed in GCS object names.) This is
   430: // used to refer to the file/symlink in a (file/symlink, directory) pair with
   431: // conflicting object names.
   432: //
   433: // See also the notes on DirInode.LookUpChild.
   434: const ConflictingFileNameSuffix = "\n"
   435:
   436: // LOCKS_REQUIRED(d)
   437: func (d *dirInode) LookUpChild(ctx context.Context, name string) (*Core, error) {
   438:         // Is this a conflict marker name?
   439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
=> 443:         var fileResult *Core
   444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:444 (PC: 0x1917b5a)
   424: func (d *dirInode) Bucket() *gcsx.SyncerBucket {
   425:         return d.bucket
   426: }
   427:
   428: // A suffix that can be used to unambiguously tag a file system name.
   429: // (Unambiguous because U+000A is not allowed in GCS object names.) This is
   430: // used to refer to the file/symlink in a (file/symlink, directory) pair with
   431: // conflicting object names.
   432: //
   433: // See also the notes on DirInode.LookUpChild.
   434: const ConflictingFileNameSuffix = "\n"
   435:
   436: // LOCKS_REQUIRED(d)
   437: func (d *dirInode) LookUpChild(ctx context.Context, name string) (*Core, error) {
   438:         // Is this a conflict marker name?
   439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
=> 444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:445 (PC: 0x1917b91)
   425:         return d.bucket
   426: }
   427:
   428: // A suffix that can be used to unambiguously tag a file system name.
   429: // (Unambiguous because U+000A is not allowed in GCS object names.) This is
   430: // used to refer to the file/symlink in a (file/symlink, directory) pair with
   431: // conflicting object names.
   432: //
   433: // See also the notes on DirInode.LookUpChild.
   434: const ConflictingFileNameSuffix = "\n"
   435:
   436: // LOCKS_REQUIRED(d)
   437: func (d *dirInode) LookUpChild(ctx context.Context, name string) (*Core, error) {
   438:         // Is this a conflict marker name?
   439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
=> 445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:449 (PC: 0x1917c6d)
   429: // (Unambiguous because U+000A is not allowed in GCS object names.) This is
   430: // used to refer to the file/symlink in a (file/symlink, directory) pair with
   431: // conflicting object names.
   432: //
   433: // See also the notes on DirInode.LookUpChild.
   434: const ConflictingFileNameSuffix = "\n"
   435:
   436: // LOCKS_REQUIRED(d)
   437: func (d *dirInode) LookUpChild(ctx context.Context, name string) (*Core, error) {
   438:         // Is this a conflict marker name?
   439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
=> 449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:453 (PC: 0x1917d48)
   433: // See also the notes on DirInode.LookUpChild.
   434: const ConflictingFileNameSuffix = "\n"
   435:
   436: // LOCKS_REQUIRED(d)
   437: func (d *dirInode) LookUpChild(ctx context.Context, name string) (*Core, error) {
   438:         // Is this a conflict marker name?
   439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
=> 453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:458 (PC: 0x1917e25)
   438:         // Is this a conflict marker name?
   439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
=> 458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
   476:                 if d.implicitDirs {
   477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:460 (PC: 0x1917e42)
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
=> 460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
   476:                 if d.implicitDirs {
   477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
   479:                         b.Add(lookUpExplicitDir)
   480:                 }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:461 (PC: 0x1917ec8)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
=> 461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
   476:                 if d.implicitDirs {
   477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
   479:                         b.Add(lookUpExplicitDir)
   480:                 }
   481:         }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:470 (PC: 0x1917ed1)
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
=> 470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
   476:                 if d.implicitDirs {
   477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
   479:                         b.Add(lookUpExplicitDir)
   480:                 }
   481:         }
   482:
   483:         if err := b.Join(); err != nil {
   484:                 return nil, err
   485:         }
   486:
   487:         var result *Core
   488:         if dirResult != nil {
   489:                 result = dirResult
   490:         } else if fileResult != nil {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:474 (PC: 0x1917ed8)
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
=> 474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
   476:                 if d.implicitDirs {
   477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
   479:                         b.Add(lookUpExplicitDir)
   480:                 }
   481:         }
   482:
   483:         if err := b.Join(); err != nil {
   484:                 return nil, err
   485:         }
   486:
   487:         var result *Core
   488:         if dirResult != nil {
   489:                 result = dirResult
   490:         } else if fileResult != nil {
   491:                 result = fileResult
   492:         }
   493:
   494:         if result != nil {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:475 (PC: 0x1917ee2)
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
=> 475:                 b.Add(lookUpFile)
   476:                 if d.implicitDirs {
   477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
   479:                         b.Add(lookUpExplicitDir)
   480:                 }
   481:         }
   482:
   483:         if err := b.Join(); err != nil {
   484:                 return nil, err
   485:         }
   486:
   487:         var result *Core
   488:         if dirResult != nil {
   489:                 result = dirResult
   490:         } else if fileResult != nil {
   491:                 result = fileResult
   492:         }
   493:
   494:         if result != nil {
   495:                 d.cache.Insert(d.cacheClock.Now(), name, result.Type())
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func1() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:446 (hits goroutine(303):1 total:1) (PC: 0x19187f7)
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:476 (PC: 0x1917ef7)
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
=> 476:                 if d.implicitDirs {
   477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
   479:                         b.Add(lookUpExplicitDir)
   480:                 }
   481:         }
   482:
   483:         if err := b.Join(); err != nil {
   484:                 return nil, err
   485:         }
   486:
   487:         var result *Core
   488:         if dirResult != nil {
   489:                 result = dirResult
   490:         } else if fileResult != nil {
   491:                 result = fileResult
   492:         }
   493:
   494:         if result != nil {
   495:                 d.cache.Insert(d.cacheClock.Now(), name, result.Type())
   496:         } else if d.enableNonexistentTypeCache && cachedType == metadata.UnknownType {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:477 (PC: 0x1917f09)
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
   476:                 if d.implicitDirs {
=> 477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
   479:                         b.Add(lookUpExplicitDir)
   480:                 }
   481:         }
   482:
   483:         if err := b.Join(); err != nil {
   484:                 return nil, err
   485:         }
   486:
   487:         var result *Core
   488:         if dirResult != nil {
   489:                 result = dirResult
   490:         } else if fileResult != nil {
   491:                 result = fileResult
   492:         }
   493:
   494:         if result != nil {
   495:                 d.cache.Insert(d.cacheClock.Now(), name, result.Type())
   496:         } else if d.enableNonexistentTypeCache && cachedType == metadata.UnknownType {
   497:                 d.cache.Insert(d.cacheClock.Now(), name, metadata.NonexistentType)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func3() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454 (hits goroutine(304):1 total:1) (PC: 0x1918477)
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:476 (PC: 0x1917f34)
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
=> 476:                 if d.implicitDirs {
   477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
   479:                         b.Add(lookUpExplicitDir)
   480:                 }
   481:         }
   482:
   483:         if err := b.Join(); err != nil {
   484:                 return nil, err
   485:         }
   486:
   487:         var result *Core
   488:         if dirResult != nil {
   489:                 result = dirResult
   490:         } else if fileResult != nil {
   491:                 result = fileResult
   492:         }
   493:
   494:         if result != nil {
   495:                 d.cache.Insert(d.cacheClock.Now(), name, result.Type())
   496:         } else if d.enableNonexistentTypeCache && cachedType == metadata.UnknownType {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262 (hits goroutine(304):1 total:1) (PC: 0x18c21a8)
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:483 (PC: 0x19181a4)
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
   476:                 if d.implicitDirs {
   477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
   479:                         b.Add(lookUpExplicitDir)
   480:                 }
   481:         }
   482:
=> 483:         if err := b.Join(); err != nil {
   484:                 return nil, err
   485:         }
   486:
   487:         var result *Core
   488:         if dirResult != nil {
   489:                 result = dirResult
   490:         } else if fileResult != nil {
   491:                 result = fileResult
   492:         }
   493:
   494:         if result != nil {
   495:                 d.cache.Insert(d.cacheClock.Now(), name, result.Type())
   496:         } else if d.enableNonexistentTypeCache && cachedType == metadata.UnknownType {
   497:                 d.cache.Insert(d.cacheClock.Now(), name, metadata.NonexistentType)
   498:         }
   499:
   500:         return result, nil
   501: }
   502:
   503: // LOCKS_REQUIRED(d)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290 (hits goroutine(304):1 total:1) (PC: 0x18c266b)
        breakpoint hit during next
[c] continue [s] stop here and cancel next, [f] finish next skipping all breakpoints? c
continuing...
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:487 (PC: 0x19181f9)
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
   476:                 if d.implicitDirs {
   477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
   479:                         b.Add(lookUpExplicitDir)
   480:                 }
   481:         }
   482:
   483:         if err := b.Join(); err != nil {
   484:                 return nil, err
   485:         }
   486:
=> 487:         var result *Core
   488:         if dirResult != nil {
   489:                 result = dirResult
   490:         } else if fileResult != nil {
   491:                 result = fileResult
   492:         }
   493:
   494:         if result != nil {
   495:                 d.cache.Insert(d.cacheClock.Now(), name, result.Type())
   496:         } else if d.enableNonexistentTypeCache && cachedType == metadata.UnknownType {
   497:                 d.cache.Insert(d.cacheClock.Now(), name, metadata.NonexistentType)
   498:         }
   499:
   500:         return result, nil
   501: }
   502:
   503: // LOCKS_REQUIRED(d)
   504: func (d *dirInode) ReadDescendants(ctx context.Context, limit int) (map[Name]*Core, error) {
   505:         var tok string
   506:         descendants := make(map[Name]*Core)
   507:         for {
(dlv) p result
Command failed: could not find symbol value for result
(dlv) p dirResult
*github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Core nil
(dlv) p fileResult
*github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Core nil
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:488 (hits goroutine(373):1 total:1) (PC: 0x1918202)
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
   476:                 if d.implicitDirs {
   477:                         b.Add(lookUpImplicitOrExplicitDir)
   478:                 } else {
   479:                         b.Add(lookUpExplicitDir)
   480:                 }
   481:         }
   482:
   483:         if err := b.Join(); err != nil {
   484:                 return nil, err
   485:         }
   486:
   487:         var result *Core
=> 488:         if dirResult != nil {
   489:                 result = dirResult
   490:         } else if fileResult != nil {
   491:                 result = fileResult
   492:         }
   493:
   494:         if result != nil {
   495:                 d.cache.Insert(d.cacheClock.Now(), name, result.Type())
   496:         } else if d.enableNonexistentTypeCache && cachedType == metadata.UnknownType {
   497:                 d.cache.Insert(d.cacheClock.Now(), name, metadata.NonexistentType)
   498:         }
   499:
   500:         return result, nil
   501: }
   502:
   503: // LOCKS_REQUIRED(d)
   504: func (d *dirInode) ReadDescendants(ctx context.Context, limit int) (map[Name]*Core, error) {
   505:         var tok string
   506:         descendants := make(map[Name]*Core)
   507:         for {
   508:                 listing, err := d.bucket.ListObjects(ctx, &gcs.ListObjectsRequest{
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 (hits goroutine(344):1 total:2) (PC: 0x193b496)
  1294:         // Simulate a large amount of free space so that the Finder doesn't refuse to
  1295:         // copy in files. (See issue #125.) Use 2^17 as the block size because that
  1296:         // is the largest that OS X will pass on.
  1297:         op.BlockSize = 1 << 17
  1298:         op.Blocks = 1 << 33
  1299:         op.BlocksFree = op.Blocks
  1300:         op.BlocksAvailable = op.Blocks
  1301:
  1302:         // Similarly with inodes.
  1303:         op.Inodes = 1 << 50
  1304:         op.InodesFree = op.Inodes
  1305:
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
=>1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func1() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:446 (hits goroutine(80):1 total:2) (PC: 0x19187f7)
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func3() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454 (hits goroutine(401):1 total:2) (PC: 0x1918477)
   434: const ConflictingFileNameSuffix = "\n"
   435:
   436: // LOCKS_REQUIRED(d)
   437: func (d *dirInode) LookUpChild(ctx context.Context, name string) (*Core, error) {
   438:         // Is this a conflict marker name?
   439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
=> 454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
(dlv) s
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).Bucket() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:424 (PC: 0x19179a4)
   404:         destroy = d.lc.Dec(n)
   405:         return
   406: }
   407:
   408: // LOCKS_REQUIRED(d)
   409: func (d *dirInode) Destroy() (err error) {
   410:         // Nothing interesting to do.
   411:         return
   412: }
   413:
   414: // LOCKS_REQUIRED(d)
   415: func (d *dirInode) Attributes(
   416:         ctx context.Context) (attrs fuseops.InodeAttributes, err error) {
   417:         // Set up basic attributes.
   418:         attrs = d.attrs
   419:         attrs.Nlink = 1
   420:
   421:         return
   422: }
   423:
=> 424: func (d *dirInode) Bucket() *gcsx.SyncerBucket {
   425:         return d.bucket
   426: }
   427:
   428: // A suffix that can be used to unambiguously tag a file system name.
   429: // (Unambiguous because U+000A is not allowed in GCS object names.) This is
   430: // used to refer to the file/symlink in a (file/symlink, directory) pair with
   431: // conflicting object names.
   432: //
   433: // See also the notes on DirInode.LookUpChild.
   434: const ConflictingFileNameSuffix = "\n"
   435:
   436: // LOCKS_REQUIRED(d)
   437: func (d *dirInode) LookUpChild(ctx context.Context, name string) (*Core, error) {
   438:         // Is this a conflict marker name?
   439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func3() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454 (PC: 0x1918485)
Values returned:
        ~r0: ("*github.com/googlecloudplatform/gcsfuse/v2/internal/gcsx.SyncerBucket")(0xc000d80100)
*github.com/googlecloudplatform/gcsfuse/v2/internal/gcsx.SyncerBucket {
                Bucket: (unreadable invalid interface type),
                Syncer: (unreadable invalid interface type),}

   434: const ConflictingFileNameSuffix = "\n"
   435:
   436: // LOCKS_REQUIRED(d)
   437: func (d *dirInode) LookUpChild(ctx context.Context, name string) (*Core, error) {
   438:         // Is this a conflict marker name?
   439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
=> 454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
(dlv) s
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).Name() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:393 (PC: 0x19177e4)
   373:
   374:         return
   375: }
   376:
   377: ////////////////////////////////////////////////////////////////////////
   378: // Public interface
   379: ////////////////////////////////////////////////////////////////////////
   380:
   381: func (d *dirInode) Lock() {
   382:         d.mu.Lock()
   383: }
   384:
   385: func (d *dirInode) Unlock() {
   386:         d.mu.Unlock()
   387: }
   388:
   389: func (d *dirInode) ID() fuseops.InodeID {
   390:         return d.id
   391: }
   392:
=> 393: func (d *dirInode) Name() Name {
   394:         return d.name
   395: }
   396:
   397: // LOCKS_REQUIRED(d)
   398: func (d *dirInode) IncrementLookupCount() {
   399:         d.lc.Inc()
   400: }
   401:
   402: // LOCKS_REQUIRED(d)
   403: func (d *dirInode) DecrementLookupCount(n uint64) (destroy bool) {
   404:         destroy = d.lc.Dec(n)
   405:         return
   406: }
   407:
   408: // LOCKS_REQUIRED(d)
   409: func (d *dirInode) Destroy() (err error) {
   410:         // Nothing interesting to do.
   411:         return
   412: }
   413:
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func3() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454 (PC: 0x1918497)
Values returned:
        ~r0: github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Name {bucketName: "", objectName: ""}

   434: const ConflictingFileNameSuffix = "\n"
   435:
   436: // LOCKS_REQUIRED(d)
   437: func (d *dirInode) LookUpChild(ctx context.Context, name string) (*Core, error) {
   438:         // Is this a conflict marker name?
   439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
=> 454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
(dlv) s
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.NewDirName() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/name.go:42 (PC: 0x19218b3)
    22: // Name is the inode's name that can be interpreted in 2 ways:
    23: //
    24: //      (1) LocalName: the name of the inode in the local file system.
    25: //      (2) GcsObjectName: the name of its gcs object backed by the inode.
    26: type Name struct {
    27:         // The value of bucketName can be:
    28:         // - "", when single gcs bucket is explicitly mounted for the file system.
    29:         // - the name of the gcs bucket, when potentially multiple buckets are
    30:         //   mounted as subdirectories of the root of the file system.
    31:         bucketName string
    32:         // The gcs object's name in its bucket.
    33:         objectName string
    34: }
    35:
    36: // NewRootName creates a Name for the root directory of a gcs bucket
    37: func NewRootName(bucketName string) Name {
    38:         return Name{bucketName, ""}
    39: }
    40:
    41: // NewDirName creates a new inode name for a directory.
=>  42: func NewDirName(parentName Name, dirName string) Name {
    43:         if parentName.IsFile() || dirName == "" {
    44:                 panic(fmt.Sprintf(
    45:                         "Inode '%s' cannot have child subdirectory '%s'",
    46:                         parentName,
    47:                         dirName))
    48:         }
    49:         if dirName[len(dirName)-1] != '/' {
    50:                 dirName = dirName + "/"
    51:         }
    52:         return Name{parentName.bucketName, parentName.objectName + dirName}
    53: }
    54:
    55: // NewFileName creates a new inode name for a file.
    56: func NewFileName(parentName Name, fileName string) Name {
    57:         if parentName.IsFile() || fileName == "" {
    58:                 panic(fmt.Sprintf(
    59:                         "Inode '%s' cannot have child file '%s'",
    60:                         parentName,
    61:                         fileName))
    62:         }
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func3() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454 (PC: 0x19184c6)
Values returned:
        ~r0: github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Name {bucketName: "", objectName: "a/"}

   434: const ConflictingFileNameSuffix = "\n"
   435:
   436: // LOCKS_REQUIRED(d)
   437: func (d *dirInode) LookUpChild(ctx context.Context, name string) (*Core, error) {
   438:         // Is this a conflict marker name?
   439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
=> 454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
(dlv) s
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.findDirInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:326 (PC: 0x1916c96)
   306:         // Suppress "not found" errors.
   307:         var gcsErr *gcs.NotFoundError
   308:         if errors.As(err, &gcsErr) {
   309:                 return nil, nil
   310:         }
   311:
   312:         // Annotate others.
   313:         if err != nil {
   314:                 return nil, fmt.Errorf("StatObject: %w", err)
   315:         }
   316:
   317:         return &Core{
   318:                 Bucket:    bucket,
   319:                 FullName:  name,
   320:                 MinObject: m,
   321:         }, nil
   322: }
   323:
   324: // findDirInode finds the dir inode core where the directory is either explicit
   325: // or implicit. Returns nil if no such directory exists.
=> 326: func findDirInode(ctx context.Context, bucket *gcsx.SyncerBucket, name Name) (*Core, error) {
   327:         if !name.IsDir() {
   328:                 return nil, fmt.Errorf("%q is not directory", name)
   329:         }
   330:
   331:         req := &gcs.ListObjectsRequest{
   332:                 Prefix:     name.GcsObjectName(),
   333:                 MaxResults: 1,
   334:         }
   335:         listing, err := bucket.ListObjects(ctx, req)
   336:         if err != nil {
   337:                 return nil, fmt.Errorf("list objects: %w", err)
   338:         }
   339:
   340:         if len(listing.Objects) == 0 {
   341:                 return nil, nil
   342:         }
   343:
   344:         result := &Core{
   345:                 Bucket:   bucket,
   346:                 FullName: name,
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.findDirInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:327 (PC: 0x1916ce4)
   307:         var gcsErr *gcs.NotFoundError
   308:         if errors.As(err, &gcsErr) {
   309:                 return nil, nil
   310:         }
   311:
   312:         // Annotate others.
   313:         if err != nil {
   314:                 return nil, fmt.Errorf("StatObject: %w", err)
   315:         }
   316:
   317:         return &Core{
   318:                 Bucket:    bucket,
   319:                 FullName:  name,
   320:                 MinObject: m,
   321:         }, nil
   322: }
   323:
   324: // findDirInode finds the dir inode core where the directory is either explicit
   325: // or implicit. Returns nil if no such directory exists.
   326: func findDirInode(ctx context.Context, bucket *gcsx.SyncerBucket, name Name) (*Core, error) {
=> 327:         if !name.IsDir() {
   328:                 return nil, fmt.Errorf("%q is not directory", name)
   329:         }
   330:
   331:         req := &gcs.ListObjectsRequest{
   332:                 Prefix:     name.GcsObjectName(),
   333:                 MaxResults: 1,
   334:         }
   335:         listing, err := bucket.ListObjects(ctx, req)
   336:         if err != nil {
   337:                 return nil, fmt.Errorf("list objects: %w", err)
   338:         }
   339:
   340:         if len(listing.Objects) == 0 {
   341:                 return nil, nil
   342:         }
   343:
   344:         result := &Core{
   345:                 Bucket:   bucket,
   346:                 FullName: name,
   347:         }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.findDirInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:332 (PC: 0x1916d16)
   312:         // Annotate others.
   313:         if err != nil {
   314:                 return nil, fmt.Errorf("StatObject: %w", err)
   315:         }
   316:
   317:         return &Core{
   318:                 Bucket:    bucket,
   319:                 FullName:  name,
   320:                 MinObject: m,
   321:         }, nil
   322: }
   323:
   324: // findDirInode finds the dir inode core where the directory is either explicit
   325: // or implicit. Returns nil if no such directory exists.
   326: func findDirInode(ctx context.Context, bucket *gcsx.SyncerBucket, name Name) (*Core, error) {
   327:         if !name.IsDir() {
   328:                 return nil, fmt.Errorf("%q is not directory", name)
   329:         }
   330:
   331:         req := &gcs.ListObjectsRequest{
=> 332:                 Prefix:     name.GcsObjectName(),
   333:                 MaxResults: 1,
   334:         }
   335:         listing, err := bucket.ListObjects(ctx, req)
   336:         if err != nil {
   337:                 return nil, fmt.Errorf("list objects: %w", err)
   338:         }
   339:
   340:         if len(listing.Objects) == 0 {
   341:                 return nil, nil
   342:         }
   343:
   344:         result := &Core{
   345:                 Bucket:   bucket,
   346:                 FullName: name,
   347:         }
   348:         if o := listing.Objects[0]; o.Name == name.GcsObjectName() {
   349:                 result.MinObject = storageutil.ConvertObjToMinObject(o)
   350:         }
   351:         return result, nil
   352: }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.findDirInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:331 (PC: 0x1916d4b)
   311:
   312:         // Annotate others.
   313:         if err != nil {
   314:                 return nil, fmt.Errorf("StatObject: %w", err)
   315:         }
   316:
   317:         return &Core{
   318:                 Bucket:    bucket,
   319:                 FullName:  name,
   320:                 MinObject: m,
   321:         }, nil
   322: }
   323:
   324: // findDirInode finds the dir inode core where the directory is either explicit
   325: // or implicit. Returns nil if no such directory exists.
   326: func findDirInode(ctx context.Context, bucket *gcsx.SyncerBucket, name Name) (*Core, error) {
   327:         if !name.IsDir() {
   328:                 return nil, fmt.Errorf("%q is not directory", name)
   329:         }
   330:
=> 331:         req := &gcs.ListObjectsRequest{
   332:                 Prefix:     name.GcsObjectName(),
   333:                 MaxResults: 1,
   334:         }
   335:         listing, err := bucket.ListObjects(ctx, req)
   336:         if err != nil {
   337:                 return nil, fmt.Errorf("list objects: %w", err)
   338:         }
   339:
   340:         if len(listing.Objects) == 0 {
   341:                 return nil, nil
   342:         }
   343:
   344:         result := &Core{
   345:                 Bucket:   bucket,
   346:                 FullName: name,
   347:         }
   348:         if o := listing.Objects[0]; o.Name == name.GcsObjectName() {
   349:                 result.MinObject = storageutil.ConvertObjToMinObject(o)
   350:         }
   351:         return result, nil
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.findDirInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:332 (PC: 0x1916db1)
   312:         // Annotate others.
   313:         if err != nil {
   314:                 return nil, fmt.Errorf("StatObject: %w", err)
   315:         }
   316:
   317:         return &Core{
   318:                 Bucket:    bucket,
   319:                 FullName:  name,
   320:                 MinObject: m,
   321:         }, nil
   322: }
   323:
   324: // findDirInode finds the dir inode core where the directory is either explicit
   325: // or implicit. Returns nil if no such directory exists.
   326: func findDirInode(ctx context.Context, bucket *gcsx.SyncerBucket, name Name) (*Core, error) {
   327:         if !name.IsDir() {
   328:                 return nil, fmt.Errorf("%q is not directory", name)
   329:         }
   330:
   331:         req := &gcs.ListObjectsRequest{
=> 332:                 Prefix:     name.GcsObjectName(),
   333:                 MaxResults: 1,
   334:         }
   335:         listing, err := bucket.ListObjects(ctx, req)
   336:         if err != nil {
   337:                 return nil, fmt.Errorf("list objects: %w", err)
   338:         }
   339:
   340:         if len(listing.Objects) == 0 {
   341:                 return nil, nil
   342:         }
   343:
   344:         result := &Core{
   345:                 Bucket:   bucket,
   346:                 FullName: name,
   347:         }
   348:         if o := listing.Objects[0]; o.Name == name.GcsObjectName() {
   349:                 result.MinObject = storageutil.ConvertObjToMinObject(o)
   350:         }
   351:         return result, nil
   352: }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.findDirInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:331 (PC: 0x1916de6)
   311:
   312:         // Annotate others.
   313:         if err != nil {
   314:                 return nil, fmt.Errorf("StatObject: %w", err)
   315:         }
   316:
   317:         return &Core{
   318:                 Bucket:    bucket,
   319:                 FullName:  name,
   320:                 MinObject: m,
   321:         }, nil
   322: }
   323:
   324: // findDirInode finds the dir inode core where the directory is either explicit
   325: // or implicit. Returns nil if no such directory exists.
   326: func findDirInode(ctx context.Context, bucket *gcsx.SyncerBucket, name Name) (*Core, error) {
   327:         if !name.IsDir() {
   328:                 return nil, fmt.Errorf("%q is not directory", name)
   329:         }
   330:
=> 331:         req := &gcs.ListObjectsRequest{
   332:                 Prefix:     name.GcsObjectName(),
   333:                 MaxResults: 1,
   334:         }
   335:         listing, err := bucket.ListObjects(ctx, req)
   336:         if err != nil {
   337:                 return nil, fmt.Errorf("list objects: %w", err)
   338:         }
   339:
   340:         if len(listing.Objects) == 0 {
   341:                 return nil, nil
   342:         }
   343:
   344:         result := &Core{
   345:                 Bucket:   bucket,
   346:                 FullName: name,
   347:         }
   348:         if o := listing.Objects[0]; o.Name == name.GcsObjectName() {
   349:                 result.MinObject = storageutil.ConvertObjToMinObject(o)
   350:         }
   351:         return result, nil
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.findDirInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:333 (PC: 0x1916df0)
   313:         if err != nil {
   314:                 return nil, fmt.Errorf("StatObject: %w", err)
   315:         }
   316:
   317:         return &Core{
   318:                 Bucket:    bucket,
   319:                 FullName:  name,
   320:                 MinObject: m,
   321:         }, nil
   322: }
   323:
   324: // findDirInode finds the dir inode core where the directory is either explicit
   325: // or implicit. Returns nil if no such directory exists.
   326: func findDirInode(ctx context.Context, bucket *gcsx.SyncerBucket, name Name) (*Core, error) {
   327:         if !name.IsDir() {
   328:                 return nil, fmt.Errorf("%q is not directory", name)
   329:         }
   330:
   331:         req := &gcs.ListObjectsRequest{
   332:                 Prefix:     name.GcsObjectName(),
=> 333:                 MaxResults: 1,
   334:         }
   335:         listing, err := bucket.ListObjects(ctx, req)
   336:         if err != nil {
   337:                 return nil, fmt.Errorf("list objects: %w", err)
   338:         }
   339:
   340:         if len(listing.Objects) == 0 {
   341:                 return nil, nil
   342:         }
   343:
   344:         result := &Core{
   345:                 Bucket:   bucket,
   346:                 FullName: name,
   347:         }
   348:         if o := listing.Objects[0]; o.Name == name.GcsObjectName() {
   349:                 result.MinObject = storageutil.ConvertObjToMinObject(o)
   350:         }
   351:         return result, nil
   352: }
   353:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.findDirInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:331 (PC: 0x1916df8)
   311:
   312:         // Annotate others.
   313:         if err != nil {
   314:                 return nil, fmt.Errorf("StatObject: %w", err)
   315:         }
   316:
   317:         return &Core{
   318:                 Bucket:    bucket,
   319:                 FullName:  name,
   320:                 MinObject: m,
   321:         }, nil
   322: }
   323:
   324: // findDirInode finds the dir inode core where the directory is either explicit
   325: // or implicit. Returns nil if no such directory exists.
   326: func findDirInode(ctx context.Context, bucket *gcsx.SyncerBucket, name Name) (*Core, error) {
   327:         if !name.IsDir() {
   328:                 return nil, fmt.Errorf("%q is not directory", name)
   329:         }
   330:
=> 331:         req := &gcs.ListObjectsRequest{
   332:                 Prefix:     name.GcsObjectName(),
   333:                 MaxResults: 1,
   334:         }
   335:         listing, err := bucket.ListObjects(ctx, req)
   336:         if err != nil {
   337:                 return nil, fmt.Errorf("list objects: %w", err)
   338:         }
   339:
   340:         if len(listing.Objects) == 0 {
   341:                 return nil, nil
   342:         }
   343:
   344:         result := &Core{
   345:                 Bucket:   bucket,
   346:                 FullName: name,
   347:         }
   348:         if o := listing.Objects[0]; o.Name == name.GcsObjectName() {
   349:                 result.MinObject = storageutil.ConvertObjToMinObject(o)
   350:         }
   351:         return result, nil
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.findDirInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:335 (PC: 0x1916e05)
   315:         }
   316:
   317:         return &Core{
   318:                 Bucket:    bucket,
   319:                 FullName:  name,
   320:                 MinObject: m,
   321:         }, nil
   322: }
   323:
   324: // findDirInode finds the dir inode core where the directory is either explicit
   325: // or implicit. Returns nil if no such directory exists.
   326: func findDirInode(ctx context.Context, bucket *gcsx.SyncerBucket, name Name) (*Core, error) {
   327:         if !name.IsDir() {
   328:                 return nil, fmt.Errorf("%q is not directory", name)
   329:         }
   330:
   331:         req := &gcs.ListObjectsRequest{
   332:                 Prefix:     name.GcsObjectName(),
   333:                 MaxResults: 1,
   334:         }
=> 335:         listing, err := bucket.ListObjects(ctx, req)
   336:         if err != nil {
   337:                 return nil, fmt.Errorf("list objects: %w", err)
   338:         }
   339:
   340:         if len(listing.Objects) == 0 {
   341:                 return nil, nil
   342:         }
   343:
   344:         result := &Core{
   345:                 Bucket:   bucket,
   346:                 FullName: name,
   347:         }
   348:         if o := listing.Objects[0]; o.Name == name.GcsObjectName() {
   349:                 result.MinObject = storageutil.ConvertObjToMinObject(o)
   350:         }
   351:         return result, nil
   352: }
   353:
   354: // Fail if the name already exists. Pass on errors directly.
   355: func (d *dirInode) createNewObject(
(dlv) p req 
("*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.ListObjectsRequest")(0xc000c90460)
*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.ListObjectsRequest {Prefix: "a/", Delimiter: "", IncludeTrailingDelimiter: false, IncludeFoldersAsPrefixes: false, ContinuationToken: "", MaxResults: 1, ProjectionVal: Full (0)}
(dlv) s
> github.com/googlecloudplatform/gcsfuse/v2/internal/gcsx.(*contentTypeBucket).ListObjects() <autogenerated>:1 (PC: 0x190d240)
(dlv) s
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*debugBucket).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/debug_bucket.go:199 (PC: 0x18c6716)
   179:         id, desc, start := b.startRequest(
   180:                 "ComposeObjects(%q)",
   181:                 req.DstName)
   182:
   183:         defer b.finishRequest(id, desc, start, &err)
   184:
   185:         o, err = b.wrapped.ComposeObjects(ctx, req)
   186:         return
   187: }
   188:
   189: func (b *debugBucket) StatObject(
   190:         ctx context.Context,
   191:         req *gcs.StatObjectRequest) (m *gcs.MinObject, e *gcs.ExtendedObjectAttributes, err error) {
   192:         id, desc, start := b.startRequest("StatObject(%q)", req.Name)
   193:         defer b.finishRequest(id, desc, start, &err)
   194:
   195:         m, e, err = b.wrapped.StatObject(ctx, req)
   196:         return
   197: }
   198:
=> 199: func (b *debugBucket) ListObjects(
   200:         ctx context.Context,
   201:         req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   202:         id, desc, start := b.startRequest("ListObjects(%q)", req.Prefix)
   203:         defer b.finishRequest(id, desc, start, &err)
   204:
   205:         listing, err = b.wrapped.ListObjects(ctx, req)
   206:         return
   207: }
   208:
   209: func (b *debugBucket) UpdateObject(
   210:         ctx context.Context,
   211:         req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   212:         id, desc, start := b.startRequest("UpdateObject(%q)", req.Name)
   213:         defer b.finishRequest(id, desc, start, &err)
   214:
   215:         o, err = b.wrapped.UpdateObject(ctx, req)
   216:         return
   217: }
   218:
   219: func (b *debugBucket) DeleteObject(
(dlv) n 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*debugBucket).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/debug_bucket.go:202 (PC: 0x18c6752)
   182:
   183:         defer b.finishRequest(id, desc, start, &err)
   184:
   185:         o, err = b.wrapped.ComposeObjects(ctx, req)
   186:         return
   187: }
   188:
   189: func (b *debugBucket) StatObject(
   190:         ctx context.Context,
   191:         req *gcs.StatObjectRequest) (m *gcs.MinObject, e *gcs.ExtendedObjectAttributes, err error) {
   192:         id, desc, start := b.startRequest("StatObject(%q)", req.Name)
   193:         defer b.finishRequest(id, desc, start, &err)
   194:
   195:         m, e, err = b.wrapped.StatObject(ctx, req)
   196:         return
   197: }
   198:
   199: func (b *debugBucket) ListObjects(
   200:         ctx context.Context,
   201:         req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
=> 202:         id, desc, start := b.startRequest("ListObjects(%q)", req.Prefix)
   203:         defer b.finishRequest(id, desc, start, &err)
   204:
   205:         listing, err = b.wrapped.ListObjects(ctx, req)
   206:         return
   207: }
   208:
   209: func (b *debugBucket) UpdateObject(
   210:         ctx context.Context,
   211:         req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   212:         id, desc, start := b.startRequest("UpdateObject(%q)", req.Name)
   213:         defer b.finishRequest(id, desc, start, &err)
   214:
   215:         o, err = b.wrapped.UpdateObject(ctx, req)
   216:         return
   217: }
   218:
   219: func (b *debugBucket) DeleteObject(
   220:         ctx context.Context,
   221:         req *gcs.DeleteObjectRequest) (err error) {
   222:         id, desc, start := b.startRequest("DeleteObject(%q)", req.Name)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*debugBucket).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/debug_bucket.go:203 (PC: 0x18c691c)
   183:         defer b.finishRequest(id, desc, start, &err)
   184:
   185:         o, err = b.wrapped.ComposeObjects(ctx, req)
   186:         return
   187: }
   188:
   189: func (b *debugBucket) StatObject(
   190:         ctx context.Context,
   191:         req *gcs.StatObjectRequest) (m *gcs.MinObject, e *gcs.ExtendedObjectAttributes, err error) {
   192:         id, desc, start := b.startRequest("StatObject(%q)", req.Name)
   193:         defer b.finishRequest(id, desc, start, &err)
   194:
   195:         m, e, err = b.wrapped.StatObject(ctx, req)
   196:         return
   197: }
   198:
   199: func (b *debugBucket) ListObjects(
   200:         ctx context.Context,
   201:         req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   202:         id, desc, start := b.startRequest("ListObjects(%q)", req.Prefix)
=> 203:         defer b.finishRequest(id, desc, start, &err)
   204:
   205:         listing, err = b.wrapped.ListObjects(ctx, req)
   206:         return
   207: }
   208:
   209: func (b *debugBucket) UpdateObject(
   210:         ctx context.Context,
   211:         req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   212:         id, desc, start := b.startRequest("UpdateObject(%q)", req.Name)
   213:         defer b.finishRequest(id, desc, start, &err)
   214:
   215:         o, err = b.wrapped.UpdateObject(ctx, req)
   216:         return
   217: }
   218:
   219: func (b *debugBucket) DeleteObject(
   220:         ctx context.Context,
   221:         req *gcs.DeleteObjectRequest) (err error) {
   222:         id, desc, start := b.startRequest("DeleteObject(%q)", req.Name)
   223:         defer b.finishRequest(id, desc, start, &err)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*debugBucket).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/debug_bucket.go:205 (PC: 0x18c6af7)
   185:         o, err = b.wrapped.ComposeObjects(ctx, req)
   186:         return
   187: }
   188:
   189: func (b *debugBucket) StatObject(
   190:         ctx context.Context,
   191:         req *gcs.StatObjectRequest) (m *gcs.MinObject, e *gcs.ExtendedObjectAttributes, err error) {
   192:         id, desc, start := b.startRequest("StatObject(%q)", req.Name)
   193:         defer b.finishRequest(id, desc, start, &err)
   194:
   195:         m, e, err = b.wrapped.StatObject(ctx, req)
   196:         return
   197: }
   198:
   199: func (b *debugBucket) ListObjects(
   200:         ctx context.Context,
   201:         req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   202:         id, desc, start := b.startRequest("ListObjects(%q)", req.Prefix)
   203:         defer b.finishRequest(id, desc, start, &err)
   204:
=> 205:         listing, err = b.wrapped.ListObjects(ctx, req)
   206:         return
   207: }
   208:
   209: func (b *debugBucket) UpdateObject(
   210:         ctx context.Context,
   211:         req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   212:         id, desc, start := b.startRequest("UpdateObject(%q)", req.Name)
   213:         defer b.finishRequest(id, desc, start, &err)
   214:
   215:         o, err = b.wrapped.UpdateObject(ctx, req)
   216:         return
   217: }
   218:
   219: func (b *debugBucket) DeleteObject(
   220:         ctx context.Context,
   221:         req *gcs.DeleteObjectRequest) (err error) {
   222:         id, desc, start := b.startRequest("DeleteObject(%q)", req.Name)
   223:         defer b.finishRequest(id, desc, start, &err)
   224:
   225:         err = b.wrapped.DeleteObject(ctx, req)
(dlv) s
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:249 (PC: 0x18c1fb6)
   229:         return
   230: }
   231:
   232: func getProjectionValue(req gcs.Projection) storage.Projection {
   233:         // Explicitly converting Projection Value because the ProjectionVal interface of jacobsa/gcloud and Go Client API are not coupled correctly.
   234:         var convertedProjection storage.Projection // Stores the Projection Value according to the Go Client API Interface.
   235:         switch int(req) {
   236:         // Projection Value 0 in jacobsa/gcloud maps to Projection Value 1 in Go Client API, that is for "full".
   237:         case 0:
   238:                 convertedProjection = storage.Projection(1)
   239:         // Projection Value 1 in jacobsa/gcloud maps to Projection Value 2 in Go Client API, that is for "noAcl".
   240:         case 1:
   241:                 convertedProjection = storage.Projection(2)
   242:         // Default Projection value in jacobsa/gcloud library is 0 that maps to 1 in Go Client API interface, and that is for "full".
   243:         default:
   244:                 convertedProjection = storage.Projection(1)
   245:         }
   246:         return convertedProjection
   247: }
   248:
=> 249: func (b *bucketHandle) ListObjects(ctx context.Context, req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   250:         // Converting *ListObjectsRequest to type *storage.Query as expected by the Go Storage Client.
   251:         query := &storage.Query{
   252:                 Delimiter:                req.Delimiter,
   253:                 Prefix:                   req.Prefix,
   254:                 Projection:               getProjectionValue(req.ProjectionVal),
   255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
   256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:254 (PC: 0x18c1fef)
   234:         var convertedProjection storage.Projection // Stores the Projection Value according to the Go Client API Interface.
   235:         switch int(req) {
   236:         // Projection Value 0 in jacobsa/gcloud maps to Projection Value 1 in Go Client API, that is for "full".
   237:         case 0:
   238:                 convertedProjection = storage.Projection(1)
   239:         // Projection Value 1 in jacobsa/gcloud maps to Projection Value 2 in Go Client API, that is for "noAcl".
   240:         case 1:
   241:                 convertedProjection = storage.Projection(2)
   242:         // Default Projection value in jacobsa/gcloud library is 0 that maps to 1 in Go Client API interface, and that is for "full".
   243:         default:
   244:                 convertedProjection = storage.Projection(1)
   245:         }
   246:         return convertedProjection
   247: }
   248:
   249: func (b *bucketHandle) ListObjects(ctx context.Context, req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   250:         // Converting *ListObjectsRequest to type *storage.Query as expected by the Go Storage Client.
   251:         query := &storage.Query{
   252:                 Delimiter:                req.Delimiter,
   253:                 Prefix:                   req.Prefix,
=> 254:                 Projection:               getProjectionValue(req.ProjectionVal),
   255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
   256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:251 (PC: 0x18c200c)
   231:
   232: func getProjectionValue(req gcs.Projection) storage.Projection {
   233:         // Explicitly converting Projection Value because the ProjectionVal interface of jacobsa/gcloud and Go Client API are not coupled correctly.
   234:         var convertedProjection storage.Projection // Stores the Projection Value according to the Go Client API Interface.
   235:         switch int(req) {
   236:         // Projection Value 0 in jacobsa/gcloud maps to Projection Value 1 in Go Client API, that is for "full".
   237:         case 0:
   238:                 convertedProjection = storage.Projection(1)
   239:         // Projection Value 1 in jacobsa/gcloud maps to Projection Value 2 in Go Client API, that is for "noAcl".
   240:         case 1:
   241:                 convertedProjection = storage.Projection(2)
   242:         // Default Projection value in jacobsa/gcloud library is 0 that maps to 1 in Go Client API interface, and that is for "full".
   243:         default:
   244:                 convertedProjection = storage.Projection(1)
   245:         }
   246:         return convertedProjection
   247: }
   248:
   249: func (b *bucketHandle) ListObjects(ctx context.Context, req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   250:         // Converting *ListObjectsRequest to type *storage.Query as expected by the Go Storage Client.
=> 251:         query := &storage.Query{
   252:                 Delimiter:                req.Delimiter,
   253:                 Prefix:                   req.Prefix,
   254:                 Projection:               getProjectionValue(req.ProjectionVal),
   255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
   256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:252 (PC: 0x18c207d)
   232: func getProjectionValue(req gcs.Projection) storage.Projection {
   233:         // Explicitly converting Projection Value because the ProjectionVal interface of jacobsa/gcloud and Go Client API are not coupled correctly.
   234:         var convertedProjection storage.Projection // Stores the Projection Value according to the Go Client API Interface.
   235:         switch int(req) {
   236:         // Projection Value 0 in jacobsa/gcloud maps to Projection Value 1 in Go Client API, that is for "full".
   237:         case 0:
   238:                 convertedProjection = storage.Projection(1)
   239:         // Projection Value 1 in jacobsa/gcloud maps to Projection Value 2 in Go Client API, that is for "noAcl".
   240:         case 1:
   241:                 convertedProjection = storage.Projection(2)
   242:         // Default Projection value in jacobsa/gcloud library is 0 that maps to 1 in Go Client API interface, and that is for "full".
   243:         default:
   244:                 convertedProjection = storage.Projection(1)
   245:         }
   246:         return convertedProjection
   247: }
   248:
   249: func (b *bucketHandle) ListObjects(ctx context.Context, req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   250:         // Converting *ListObjectsRequest to type *storage.Query as expected by the Go Storage Client.
   251:         query := &storage.Query{
=> 252:                 Delimiter:                req.Delimiter,
   253:                 Prefix:                   req.Prefix,
   254:                 Projection:               getProjectionValue(req.ProjectionVal),
   255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
   256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:251 (PC: 0x18c20b6)
   231:
   232: func getProjectionValue(req gcs.Projection) storage.Projection {
   233:         // Explicitly converting Projection Value because the ProjectionVal interface of jacobsa/gcloud and Go Client API are not coupled correctly.
   234:         var convertedProjection storage.Projection // Stores the Projection Value according to the Go Client API Interface.
   235:         switch int(req) {
   236:         // Projection Value 0 in jacobsa/gcloud maps to Projection Value 1 in Go Client API, that is for "full".
   237:         case 0:
   238:                 convertedProjection = storage.Projection(1)
   239:         // Projection Value 1 in jacobsa/gcloud maps to Projection Value 2 in Go Client API, that is for "noAcl".
   240:         case 1:
   241:                 convertedProjection = storage.Projection(2)
   242:         // Default Projection value in jacobsa/gcloud library is 0 that maps to 1 in Go Client API interface, and that is for "full".
   243:         default:
   244:                 convertedProjection = storage.Projection(1)
   245:         }
   246:         return convertedProjection
   247: }
   248:
   249: func (b *bucketHandle) ListObjects(ctx context.Context, req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   250:         // Converting *ListObjectsRequest to type *storage.Query as expected by the Go Storage Client.
=> 251:         query := &storage.Query{
   252:                 Delimiter:                req.Delimiter,
   253:                 Prefix:                   req.Prefix,
   254:                 Projection:               getProjectionValue(req.ProjectionVal),
   255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
   256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:253 (PC: 0x18c20c0)
   233:         // Explicitly converting Projection Value because the ProjectionVal interface of jacobsa/gcloud and Go Client API are not coupled correctly.
   234:         var convertedProjection storage.Projection // Stores the Projection Value according to the Go Client API Interface.
   235:         switch int(req) {
   236:         // Projection Value 0 in jacobsa/gcloud maps to Projection Value 1 in Go Client API, that is for "full".
   237:         case 0:
   238:                 convertedProjection = storage.Projection(1)
   239:         // Projection Value 1 in jacobsa/gcloud maps to Projection Value 2 in Go Client API, that is for "noAcl".
   240:         case 1:
   241:                 convertedProjection = storage.Projection(2)
   242:         // Default Projection value in jacobsa/gcloud library is 0 that maps to 1 in Go Client API interface, and that is for "full".
   243:         default:
   244:                 convertedProjection = storage.Projection(1)
   245:         }
   246:         return convertedProjection
   247: }
   248:
   249: func (b *bucketHandle) ListObjects(ctx context.Context, req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   250:         // Converting *ListObjectsRequest to type *storage.Query as expected by the Go Storage Client.
   251:         query := &storage.Query{
   252:                 Delimiter:                req.Delimiter,
=> 253:                 Prefix:                   req.Prefix,
   254:                 Projection:               getProjectionValue(req.ProjectionVal),
   255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
   256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:251 (PC: 0x18c20fa)
   231:
   232: func getProjectionValue(req gcs.Projection) storage.Projection {
   233:         // Explicitly converting Projection Value because the ProjectionVal interface of jacobsa/gcloud and Go Client API are not coupled correctly.
   234:         var convertedProjection storage.Projection // Stores the Projection Value according to the Go Client API Interface.
   235:         switch int(req) {
   236:         // Projection Value 0 in jacobsa/gcloud maps to Projection Value 1 in Go Client API, that is for "full".
   237:         case 0:
   238:                 convertedProjection = storage.Projection(1)
   239:         // Projection Value 1 in jacobsa/gcloud maps to Projection Value 2 in Go Client API, that is for "noAcl".
   240:         case 1:
   241:                 convertedProjection = storage.Projection(2)
   242:         // Default Projection value in jacobsa/gcloud library is 0 that maps to 1 in Go Client API interface, and that is for "full".
   243:         default:
   244:                 convertedProjection = storage.Projection(1)
   245:         }
   246:         return convertedProjection
   247: }
   248:
   249: func (b *bucketHandle) ListObjects(ctx context.Context, req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   250:         // Converting *ListObjectsRequest to type *storage.Query as expected by the Go Storage Client.
=> 251:         query := &storage.Query{
   252:                 Delimiter:                req.Delimiter,
   253:                 Prefix:                   req.Prefix,
   254:                 Projection:               getProjectionValue(req.ProjectionVal),
   255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
   256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:254 (PC: 0x18c2104)
   234:         var convertedProjection storage.Projection // Stores the Projection Value according to the Go Client API Interface.
   235:         switch int(req) {
   236:         // Projection Value 0 in jacobsa/gcloud maps to Projection Value 1 in Go Client API, that is for "full".
   237:         case 0:
   238:                 convertedProjection = storage.Projection(1)
   239:         // Projection Value 1 in jacobsa/gcloud maps to Projection Value 2 in Go Client API, that is for "noAcl".
   240:         case 1:
   241:                 convertedProjection = storage.Projection(2)
   242:         // Default Projection value in jacobsa/gcloud library is 0 that maps to 1 in Go Client API interface, and that is for "full".
   243:         default:
   244:                 convertedProjection = storage.Projection(1)
   245:         }
   246:         return convertedProjection
   247: }
   248:
   249: func (b *bucketHandle) ListObjects(ctx context.Context, req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   250:         // Converting *ListObjectsRequest to type *storage.Query as expected by the Go Storage Client.
   251:         query := &storage.Query{
   252:                 Delimiter:                req.Delimiter,
   253:                 Prefix:                   req.Prefix,
=> 254:                 Projection:               getProjectionValue(req.ProjectionVal),
   255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
   256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:251 (PC: 0x18c210d)
   231:
   232: func getProjectionValue(req gcs.Projection) storage.Projection {
   233:         // Explicitly converting Projection Value because the ProjectionVal interface of jacobsa/gcloud and Go Client API are not coupled correctly.
   234:         var convertedProjection storage.Projection // Stores the Projection Value according to the Go Client API Interface.
   235:         switch int(req) {
   236:         // Projection Value 0 in jacobsa/gcloud maps to Projection Value 1 in Go Client API, that is for "full".
   237:         case 0:
   238:                 convertedProjection = storage.Projection(1)
   239:         // Projection Value 1 in jacobsa/gcloud maps to Projection Value 2 in Go Client API, that is for "noAcl".
   240:         case 1:
   241:                 convertedProjection = storage.Projection(2)
   242:         // Default Projection value in jacobsa/gcloud library is 0 that maps to 1 in Go Client API interface, and that is for "full".
   243:         default:
   244:                 convertedProjection = storage.Projection(1)
   245:         }
   246:         return convertedProjection
   247: }
   248:
   249: func (b *bucketHandle) ListObjects(ctx context.Context, req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   250:         // Converting *ListObjectsRequest to type *storage.Query as expected by the Go Storage Client.
=> 251:         query := &storage.Query{
   252:                 Delimiter:                req.Delimiter,
   253:                 Prefix:                   req.Prefix,
   254:                 Projection:               getProjectionValue(req.ProjectionVal),
   255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
   256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:255 (PC: 0x18c2117)
   235:         switch int(req) {
   236:         // Projection Value 0 in jacobsa/gcloud maps to Projection Value 1 in Go Client API, that is for "full".
   237:         case 0:
   238:                 convertedProjection = storage.Projection(1)
   239:         // Projection Value 1 in jacobsa/gcloud maps to Projection Value 2 in Go Client API, that is for "noAcl".
   240:         case 1:
   241:                 convertedProjection = storage.Projection(2)
   242:         // Default Projection value in jacobsa/gcloud library is 0 that maps to 1 in Go Client API interface, and that is for "full".
   243:         default:
   244:                 convertedProjection = storage.Projection(1)
   245:         }
   246:         return convertedProjection
   247: }
   248:
   249: func (b *bucketHandle) ListObjects(ctx context.Context, req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   250:         // Converting *ListObjectsRequest to type *storage.Query as expected by the Go Storage Client.
   251:         query := &storage.Query{
   252:                 Delimiter:                req.Delimiter,
   253:                 Prefix:                   req.Prefix,
   254:                 Projection:               getProjectionValue(req.ProjectionVal),
=> 255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
   256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("error in iterating through objects: %w", err)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:251 (PC: 0x18c2129)
   231:
   232: func getProjectionValue(req gcs.Projection) storage.Projection {
   233:         // Explicitly converting Projection Value because the ProjectionVal interface of jacobsa/gcloud and Go Client API are not coupled correctly.
   234:         var convertedProjection storage.Projection // Stores the Projection Value according to the Go Client API Interface.
   235:         switch int(req) {
   236:         // Projection Value 0 in jacobsa/gcloud maps to Projection Value 1 in Go Client API, that is for "full".
   237:         case 0:
   238:                 convertedProjection = storage.Projection(1)
   239:         // Projection Value 1 in jacobsa/gcloud maps to Projection Value 2 in Go Client API, that is for "noAcl".
   240:         case 1:
   241:                 convertedProjection = storage.Projection(2)
   242:         // Default Projection value in jacobsa/gcloud library is 0 that maps to 1 in Go Client API interface, and that is for "full".
   243:         default:
   244:                 convertedProjection = storage.Projection(1)
   245:         }
   246:         return convertedProjection
   247: }
   248:
   249: func (b *bucketHandle) ListObjects(ctx context.Context, req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   250:         // Converting *ListObjectsRequest to type *storage.Query as expected by the Go Storage Client.
=> 251:         query := &storage.Query{
   252:                 Delimiter:                req.Delimiter,
   253:                 Prefix:                   req.Prefix,
   254:                 Projection:               getProjectionValue(req.ProjectionVal),
   255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
   256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:256 (PC: 0x18c2133)
   236:         // Projection Value 0 in jacobsa/gcloud maps to Projection Value 1 in Go Client API, that is for "full".
   237:         case 0:
   238:                 convertedProjection = storage.Projection(1)
   239:         // Projection Value 1 in jacobsa/gcloud maps to Projection Value 2 in Go Client API, that is for "noAcl".
   240:         case 1:
   241:                 convertedProjection = storage.Projection(2)
   242:         // Default Projection value in jacobsa/gcloud library is 0 that maps to 1 in Go Client API interface, and that is for "full".
   243:         default:
   244:                 convertedProjection = storage.Projection(1)
   245:         }
   246:         return convertedProjection
   247: }
   248:
   249: func (b *bucketHandle) ListObjects(ctx context.Context, req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   250:         // Converting *ListObjectsRequest to type *storage.Query as expected by the Go Storage Client.
   251:         query := &storage.Query{
   252:                 Delimiter:                req.Delimiter,
   253:                 Prefix:                   req.Prefix,
   254:                 Projection:               getProjectionValue(req.ProjectionVal),
   255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
=> 256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("error in iterating through objects: %w", err)
   276:                         return
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:251 (PC: 0x18c2148)
   231:
   232: func getProjectionValue(req gcs.Projection) storage.Projection {
   233:         // Explicitly converting Projection Value because the ProjectionVal interface of jacobsa/gcloud and Go Client API are not coupled correctly.
   234:         var convertedProjection storage.Projection // Stores the Projection Value according to the Go Client API Interface.
   235:         switch int(req) {
   236:         // Projection Value 0 in jacobsa/gcloud maps to Projection Value 1 in Go Client API, that is for "full".
   237:         case 0:
   238:                 convertedProjection = storage.Projection(1)
   239:         // Projection Value 1 in jacobsa/gcloud maps to Projection Value 2 in Go Client API, that is for "noAcl".
   240:         case 1:
   241:                 convertedProjection = storage.Projection(2)
   242:         // Default Projection value in jacobsa/gcloud library is 0 that maps to 1 in Go Client API interface, and that is for "full".
   243:         default:
   244:                 convertedProjection = storage.Projection(1)
   245:         }
   246:         return convertedProjection
   247: }
   248:
   249: func (b *bucketHandle) ListObjects(ctx context.Context, req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   250:         // Converting *ListObjectsRequest to type *storage.Query as expected by the Go Storage Client.
=> 251:         query := &storage.Query{
   252:                 Delimiter:                req.Delimiter,
   253:                 Prefix:                   req.Prefix,
   254:                 Projection:               getProjectionValue(req.ProjectionVal),
   255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
   256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:259 (PC: 0x18c2155)
   239:         // Projection Value 1 in jacobsa/gcloud maps to Projection Value 2 in Go Client API, that is for "noAcl".
   240:         case 1:
   241:                 convertedProjection = storage.Projection(2)
   242:         // Default Projection value in jacobsa/gcloud library is 0 that maps to 1 in Go Client API interface, and that is for "full".
   243:         default:
   244:                 convertedProjection = storage.Projection(1)
   245:         }
   246:         return convertedProjection
   247: }
   248:
   249: func (b *bucketHandle) ListObjects(ctx context.Context, req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   250:         // Converting *ListObjectsRequest to type *storage.Query as expected by the Go Storage Client.
   251:         query := &storage.Query{
   252:                 Delimiter:                req.Delimiter,
   253:                 Prefix:                   req.Prefix,
   254:                 Projection:               getProjectionValue(req.ProjectionVal),
   255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
   256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
=> 259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:260 (PC: 0x18c218a)
   240:         case 1:
   241:                 convertedProjection = storage.Projection(2)
   242:         // Default Projection value in jacobsa/gcloud library is 0 that maps to 1 in Go Client API interface, and that is for "full".
   243:         default:
   244:                 convertedProjection = storage.Projection(1)
   245:         }
   246:         return convertedProjection
   247: }
   248:
   249: func (b *bucketHandle) ListObjects(ctx context.Context, req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   250:         // Converting *ListObjectsRequest to type *storage.Query as expected by the Go Storage Client.
   251:         query := &storage.Query{
   252:                 Delimiter:                req.Delimiter,
   253:                 Prefix:                   req.Prefix,
   254:                 Projection:               getProjectionValue(req.ProjectionVal),
   255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
   256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
=> 260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:261 (PC: 0x18c2194)
   241:                 convertedProjection = storage.Projection(2)
   242:         // Default Projection value in jacobsa/gcloud library is 0 that maps to 1 in Go Client API interface, and that is for "full".
   243:         default:
   244:                 convertedProjection = storage.Projection(1)
   245:         }
   246:         return convertedProjection
   247: }
   248:
   249: func (b *bucketHandle) ListObjects(ctx context.Context, req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   250:         // Converting *ListObjectsRequest to type *storage.Query as expected by the Go Storage Client.
   251:         query := &storage.Query{
   252:                 Delimiter:                req.Delimiter,
   253:                 Prefix:                   req.Prefix,
   254:                 Projection:               getProjectionValue(req.ProjectionVal),
   255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
   256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
=> 261:         pi.MaxSize = req.MaxResults
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262 (hits goroutine(401):1 total:2) (PC: 0x18c21a8)
   242:         // Default Projection value in jacobsa/gcloud library is 0 that maps to 1 in Go Client API interface, and that is for "full".
   243:         default:
   244:                 convertedProjection = storage.Projection(1)
   245:         }
   246:         return convertedProjection
   247: }
   248:
   249: func (b *bucketHandle) ListObjects(ctx context.Context, req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   250:         // Converting *ListObjectsRequest to type *storage.Query as expected by the Go Storage Client.
   251:         query := &storage.Query{
   252:                 Delimiter:                req.Delimiter,
   253:                 Prefix:                   req.Prefix,
   254:                 Projection:               getProjectionValue(req.ProjectionVal),
   255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
   256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
=> 262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
(dlv) p query
("*cloud.google.com/go/storage.Query")(0xc000310090)
*cloud.google.com/go/storage.Query {
        Delimiter: "",
        Prefix: "a/",
        Versions: false,
        attrSelection: []string len: 0, cap: 0, nil,
        StartOffset: "",
        EndOffset: "",
        Projection: ProjectionFull (1),
        IncludeTrailingDelimiter: false,
        MatchGlob: "",
        IncludeFoldersAsPrefixes: false,}
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:263 (PC: 0x18c21e6)
   243:         default:
   244:                 convertedProjection = storage.Projection(1)
   245:         }
   246:         return convertedProjection
   247: }
   248:
   249: func (b *bucketHandle) ListObjects(ctx context.Context, req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   250:         // Converting *ListObjectsRequest to type *storage.Query as expected by the Go Storage Client.
   251:         query := &storage.Query{
   252:                 Delimiter:                req.Delimiter,
   253:                 Prefix:                   req.Prefix,
   254:                 Projection:               getProjectionValue(req.ProjectionVal),
   255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
   256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
   262:         pi.Token = req.ContinuationToken
=> 263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:266 (PC: 0x18c223b)
   246:         return convertedProjection
   247: }
   248:
   249: func (b *bucketHandle) ListObjects(ctx context.Context, req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   250:         // Converting *ListObjectsRequest to type *storage.Query as expected by the Go Storage Client.
   251:         query := &storage.Query{
   252:                 Delimiter:                req.Delimiter,
   253:                 Prefix:                   req.Prefix,
   254:                 Projection:               getProjectionValue(req.ProjectionVal),
   255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
   256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
=> 266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 logger.Warnf("Ignoring unsupported directory-name: \"%s\"", attrs.Prefix)
   285:                         } else {
   286:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:267 (PC: 0x18c223d)
   247: }
   248:
   249: func (b *bucketHandle) ListObjects(ctx context.Context, req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   250:         // Converting *ListObjectsRequest to type *storage.Query as expected by the Go Storage Client.
   251:         query := &storage.Query{
   252:                 Delimiter:                req.Delimiter,
   253:                 Prefix:                   req.Prefix,
   254:                 Projection:               getProjectionValue(req.ProjectionVal),
   255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
   256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
=> 267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 logger.Warnf("Ignoring unsupported directory-name: \"%s\"", attrs.Prefix)
   285:                         } else {
   286:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   287:                         }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:269 (PC: 0x18c224b)
   249: func (b *bucketHandle) ListObjects(ctx context.Context, req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   250:         // Converting *ListObjectsRequest to type *storage.Query as expected by the Go Storage Client.
   251:         query := &storage.Query{
   252:                 Delimiter:                req.Delimiter,
   253:                 Prefix:                   req.Prefix,
   254:                 Projection:               getProjectionValue(req.ProjectionVal),
   255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
   256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
=> 269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 logger.Warnf("Ignoring unsupported directory-name: \"%s\"", attrs.Prefix)
   285:                         } else {
   286:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   287:                         }
   288:                 } else {
   289:                         if util.IsUnsupportedObjectName(attrs.Name) {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:270 (PC: 0x18c22e2)
   250:         // Converting *ListObjectsRequest to type *storage.Query as expected by the Go Storage Client.
   251:         query := &storage.Query{
   252:                 Delimiter:                req.Delimiter,
   253:                 Prefix:                   req.Prefix,
   254:                 Projection:               getProjectionValue(req.ProjectionVal),
   255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
   256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
=> 270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 logger.Warnf("Ignoring unsupported directory-name: \"%s\"", attrs.Prefix)
   285:                         } else {
   286:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   287:                         }
   288:                 } else {
   289:                         if util.IsUnsupportedObjectName(attrs.Name) {
   290:                                 logger.Warnf("Ignoring unsupported object-name: \"%s\"", attrs.Name)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:274 (PC: 0x18c2311)
   254:                 Projection:               getProjectionValue(req.ProjectionVal),
   255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
   256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
=> 274:                 if err != nil {
   275:                         err = fmt.Errorf("error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 logger.Warnf("Ignoring unsupported directory-name: \"%s\"", attrs.Prefix)
   285:                         } else {
   286:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   287:                         }
   288:                 } else {
   289:                         if util.IsUnsupportedObjectName(attrs.Name) {
   290:                                 logger.Warnf("Ignoring unsupported object-name: \"%s\"", attrs.Name)
   291:                         } else {
   292:                                 // Converting attrs to *Object type.
   293:                                 currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   294:                                 list.Objects = append(list.Objects, currObject)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:282 (PC: 0x18c2437)
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
=> 282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 logger.Warnf("Ignoring unsupported directory-name: \"%s\"", attrs.Prefix)
   285:                         } else {
   286:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   287:                         }
   288:                 } else {
   289:                         if util.IsUnsupportedObjectName(attrs.Name) {
   290:                                 logger.Warnf("Ignoring unsupported object-name: \"%s\"", attrs.Name)
   291:                         } else {
   292:                                 // Converting attrs to *Object type.
   293:                                 currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   294:                                 list.Objects = append(list.Objects, currObject)
   295:                         }
   296:                 }
   297:
   298:                 // itr.next returns all the objects present in the bucket. Hence adding a
   299:                 // check to break after iterating over the current page. pi.Remaining()
   300:                 // function returns number of items (items + prefixes) remaining in current
   301:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   302:                 // after first itr.Next() call and becomes 0 when iteration is done.
(dlv) p attrs.Prefix
""
(dlv) p req
("*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.ListObjectsRequest")(0xc000c90460)
*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.ListObjectsRequest {Prefix: "a/", Delimiter: "", IncludeTrailingDelimiter: false, IncludeFoldersAsPrefixes: false, ContinuationToken: "", MaxResults: 1, ProjectionVal: Full (0)}
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:289 (PC: 0x18c2637)
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 logger.Warnf("Ignoring unsupported directory-name: \"%s\"", attrs.Prefix)
   285:                         } else {
   286:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   287:                         }
   288:                 } else {
=> 289:                         if util.IsUnsupportedObjectName(attrs.Name) {
   290:                                 logger.Warnf("Ignoring unsupported object-name: \"%s\"", attrs.Name)
   291:                         } else {
   292:                                 // Converting attrs to *Object type.
   293:                                 currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   294:                                 list.Objects = append(list.Objects, currObject)
   295:                         }
   296:                 }
   297:
   298:                 // itr.next returns all the objects present in the bucket. Hence adding a
   299:                 // check to break after iterating over the current page. pi.Remaining()
   300:                 // function returns number of items (items + prefixes) remaining in current
   301:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   302:                 // after first itr.Next() call and becomes 0 when iteration is done.
   303:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   304:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   305:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   306:                         break
   307:                 }
   308:         }
   309:
(dlv) p attrs.Name  
"a/../8"
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:290 (hits goroutine(401):1 total:2) (PC: 0x18c266b)
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 logger.Warnf("Ignoring unsupported directory-name: \"%s\"", attrs.Prefix)
   285:                         } else {
   286:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   287:                         }
   288:                 } else {
   289:                         if util.IsUnsupportedObjectName(attrs.Name) {
=> 290:                                 logger.Warnf("Ignoring unsupported object-name: \"%s\"", attrs.Name)
   291:                         } else {
   292:                                 // Converting attrs to *Object type.
   293:                                 currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   294:                                 list.Objects = append(list.Objects, currObject)
   295:                         }
   296:                 }
   297:
   298:                 // itr.next returns all the objects present in the bucket. Hence adding a
   299:                 // check to break after iterating over the current page. pi.Remaining()
   300:                 // function returns number of items (items + prefixes) remaining in current
   301:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   302:                 // after first itr.Next() call and becomes 0 when iteration is done.
   303:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   304:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   305:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   306:                         break
   307:                 }
   308:         }
   309:
   310:         list.ContinuationToken = itr.PageInfo().Token
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:305 (PC: 0x18c27ee)
   285:                         } else {
   286:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   287:                         }
   288:                 } else {
   289:                         if util.IsUnsupportedObjectName(attrs.Name) {
   290:                                 logger.Warnf("Ignoring unsupported object-name: \"%s\"", attrs.Name)
   291:                         } else {
   292:                                 // Converting attrs to *Object type.
   293:                                 currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   294:                                 list.Objects = append(list.Objects, currObject)
   295:                         }
   296:                 }
   297:
   298:                 // itr.next returns all the objects present in the bucket. Hence adding a
   299:                 // check to break after iterating over the current page. pi.Remaining()
   300:                 // function returns number of items (items + prefixes) remaining in current
   301:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   302:                 // after first itr.Next() call and becomes 0 when iteration is done.
   303:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   304:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
=> 305:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   306:                         break
   307:                 }
   308:         }
   309:
   310:         list.ContinuationToken = itr.PageInfo().Token
   311:         listing = &list
   312:         return
   313: }
   314:
   315: func (b *bucketHandle) UpdateObject(ctx context.Context, req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   316:         obj := b.bucket.Object(req.Name)
   317:
   318:         if req.Generation != 0 {
   319:                 obj = obj.Generation(req.Generation)
   320:         }
   321:
   322:         if req.MetaGenerationPrecondition != nil {
   323:                 obj = obj.If(storage.Conditions{MetagenerationMatch: *req.MetaGenerationPrecondition})
   324:         }
   325:
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306 (PC: 0x18c282d)
   286:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   287:                         }
   288:                 } else {
   289:                         if util.IsUnsupportedObjectName(attrs.Name) {
   290:                                 logger.Warnf("Ignoring unsupported object-name: \"%s\"", attrs.Name)
   291:                         } else {
   292:                                 // Converting attrs to *Object type.
   293:                                 currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   294:                                 list.Objects = append(list.Objects, currObject)
   295:                         }
   296:                 }
   297:
   298:                 // itr.next returns all the objects present in the bucket. Hence adding a
   299:                 // check to break after iterating over the current page. pi.Remaining()
   300:                 // function returns number of items (items + prefixes) remaining in current
   301:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   302:                 // after first itr.Next() call and becomes 0 when iteration is done.
   303:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   304:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   305:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
=> 306:                         break
   307:                 }
   308:         }
   309:
   310:         list.ContinuationToken = itr.PageInfo().Token
   311:         listing = &list
   312:         return
   313: }
   314:
   315: func (b *bucketHandle) UpdateObject(ctx context.Context, req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   316:         obj := b.bucket.Object(req.Name)
   317:
   318:         if req.Generation != 0 {
   319:                 obj = obj.Generation(req.Generation)
   320:         }
   321:
   322:         if req.MetaGenerationPrecondition != nil {
   323:                 obj = obj.If(storage.Conditions{MetagenerationMatch: *req.MetaGenerationPrecondition})
   324:         }
   325:
   326:         updateQuery := storage.ObjectAttrsToUpdate{}
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:310 (PC: 0x18c282f)
   290:                                 logger.Warnf("Ignoring unsupported object-name: \"%s\"", attrs.Name)
   291:                         } else {
   292:                                 // Converting attrs to *Object type.
   293:                                 currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   294:                                 list.Objects = append(list.Objects, currObject)
   295:                         }
   296:                 }
   297:
   298:                 // itr.next returns all the objects present in the bucket. Hence adding a
   299:                 // check to break after iterating over the current page. pi.Remaining()
   300:                 // function returns number of items (items + prefixes) remaining in current
   301:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   302:                 // after first itr.Next() call and becomes 0 when iteration is done.
   303:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   304:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   305:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   306:                         break
   307:                 }
   308:         }
   309:
=> 310:         list.ContinuationToken = itr.PageInfo().Token
   311:         listing = &list
   312:         return
   313: }
   314:
   315: func (b *bucketHandle) UpdateObject(ctx context.Context, req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   316:         obj := b.bucket.Object(req.Name)
   317:
   318:         if req.Generation != 0 {
   319:                 obj = obj.Generation(req.Generation)
   320:         }
   321:
   322:         if req.MetaGenerationPrecondition != nil {
   323:                 obj = obj.If(storage.Conditions{MetagenerationMatch: *req.MetaGenerationPrecondition})
   324:         }
   325:
   326:         updateQuery := storage.ObjectAttrsToUpdate{}
   327:
   328:         if req.ContentType != nil {
   329:                 updateQuery.ContentType = *req.ContentType
   330:         }
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:262 (hits goroutine(433):1 total:3) (PC: 0x18c21a8)
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*debugBucket).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/debug_bucket.go:205 (PC: 0x18c6b3d)
Values returned:
        listing: ("*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing")(0xc00012a000)
*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing {
                Objects: []*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object len: 0, cap: 0, nil,
                CollapsedRuns: []string len: 0, cap: 0, nil,
                ContinuationToken: "CgZhLy4uLzg=",}
        err: error nil

   185:         o, err = b.wrapped.ComposeObjects(ctx, req)
   186:         return
   187: }
   188:
   189: func (b *debugBucket) StatObject(
   190:         ctx context.Context,
   191:         req *gcs.StatObjectRequest) (m *gcs.MinObject, e *gcs.ExtendedObjectAttributes, err error) {
   192:         id, desc, start := b.startRequest("StatObject(%q)", req.Name)
   193:         defer b.finishRequest(id, desc, start, &err)
   194:
   195:         m, e, err = b.wrapped.StatObject(ctx, req)
   196:         return
   197: }
   198:
   199: func (b *debugBucket) ListObjects(
   200:         ctx context.Context,
   201:         req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   202:         id, desc, start := b.startRequest("ListObjects(%q)", req.Prefix)
   203:         defer b.finishRequest(id, desc, start, &err)
   204:
=> 205:         listing, err = b.wrapped.ListObjects(ctx, req)
   206:         return
   207: }
   208:
   209: func (b *debugBucket) UpdateObject(
   210:         ctx context.Context,
   211:         req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   212:         id, desc, start := b.startRequest("UpdateObject(%q)", req.Name)
   213:         defer b.finishRequest(id, desc, start, &err)
   214:
   215:         o, err = b.wrapped.UpdateObject(ctx, req)
   216:         return
   217: }
   218:
   219: func (b *debugBucket) DeleteObject(
   220:         ctx context.Context,
   221:         req *gcs.DeleteObjectRequest) (err error) {
   222:         id, desc, start := b.startRequest("DeleteObject(%q)", req.Name)
   223:         defer b.finishRequest(id, desc, start, &err)
   224:
   225:         err = b.wrapped.DeleteObject(ctx, req)
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.findDirInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:335 (PC: 0x1916e48)
Values returned:
        ~r0: ("*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing")(0xc00012a000)
*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing {
                Objects: []*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object len: 0, cap: 0, nil,
                CollapsedRuns: []string len: 0, cap: 0, nil,
                ContinuationToken: "CgZhLy4uLzg=",}
        ~r1: error nil

   315:         }
   316:
   317:         return &Core{
   318:                 Bucket:    bucket,
   319:                 FullName:  name,
   320:                 MinObject: m,
   321:         }, nil
   322: }
   323:
   324: // findDirInode finds the dir inode core where the directory is either explicit
   325: // or implicit. Returns nil if no such directory exists.
   326: func findDirInode(ctx context.Context, bucket *gcsx.SyncerBucket, name Name) (*Core, error) {
   327:         if !name.IsDir() {
   328:                 return nil, fmt.Errorf("%q is not directory", name)
   329:         }
   330:
   331:         req := &gcs.ListObjectsRequest{
   332:                 Prefix:     name.GcsObjectName(),
   333:                 MaxResults: 1,
   334:         }
=> 335:         listing, err := bucket.ListObjects(ctx, req)
   336:         if err != nil {
   337:                 return nil, fmt.Errorf("list objects: %w", err)
   338:         }
   339:
   340:         if len(listing.Objects) == 0 {
   341:                 return nil, nil
   342:         }
   343:
   344:         result := &Core{
   345:                 Bucket:   bucket,
   346:                 FullName: name,
   347:         }
   348:         if o := listing.Objects[0]; o.Name == name.GcsObjectName() {
   349:                 result.MinObject = storageutil.ConvertObjToMinObject(o)
   350:         }
   351:         return result, nil
   352: }
   353:
   354: // Fail if the name already exists. Pass on errors directly.
   355: func (d *dirInode) createNewObject(
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.findDirInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:336 (PC: 0x1916eb7)
   316:
   317:         return &Core{
   318:                 Bucket:    bucket,
   319:                 FullName:  name,
   320:                 MinObject: m,
   321:         }, nil
   322: }
   323:
   324: // findDirInode finds the dir inode core where the directory is either explicit
   325: // or implicit. Returns nil if no such directory exists.
   326: func findDirInode(ctx context.Context, bucket *gcsx.SyncerBucket, name Name) (*Core, error) {
   327:         if !name.IsDir() {
   328:                 return nil, fmt.Errorf("%q is not directory", name)
   329:         }
   330:
   331:         req := &gcs.ListObjectsRequest{
   332:                 Prefix:     name.GcsObjectName(),
   333:                 MaxResults: 1,
   334:         }
   335:         listing, err := bucket.ListObjects(ctx, req)
=> 336:         if err != nil {
   337:                 return nil, fmt.Errorf("list objects: %w", err)
   338:         }
   339:
   340:         if len(listing.Objects) == 0 {
   341:                 return nil, nil
   342:         }
   343:
   344:         result := &Core{
   345:                 Bucket:   bucket,
   346:                 FullName: name,
   347:         }
   348:         if o := listing.Objects[0]; o.Name == name.GcsObjectName() {
   349:                 result.MinObject = storageutil.ConvertObjToMinObject(o)
   350:         }
   351:         return result, nil
   352: }
   353:
   354: // Fail if the name already exists. Pass on errors directly.
   355: func (d *dirInode) createNewObject(
   356:         ctx context.Context,
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.findDirInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:340 (PC: 0x1916fec)
   320:                 MinObject: m,
   321:         }, nil
   322: }
   323:
   324: // findDirInode finds the dir inode core where the directory is either explicit
   325: // or implicit. Returns nil if no such directory exists.
   326: func findDirInode(ctx context.Context, bucket *gcsx.SyncerBucket, name Name) (*Core, error) {
   327:         if !name.IsDir() {
   328:                 return nil, fmt.Errorf("%q is not directory", name)
   329:         }
   330:
   331:         req := &gcs.ListObjectsRequest{
   332:                 Prefix:     name.GcsObjectName(),
   333:                 MaxResults: 1,
   334:         }
   335:         listing, err := bucket.ListObjects(ctx, req)
   336:         if err != nil {
   337:                 return nil, fmt.Errorf("list objects: %w", err)
   338:         }
   339:
=> 340:         if len(listing.Objects) == 0 {
   341:                 return nil, nil
   342:         }
   343:
   344:         result := &Core{
   345:                 Bucket:   bucket,
   346:                 FullName: name,
   347:         }
   348:         if o := listing.Objects[0]; o.Name == name.GcsObjectName() {
   349:                 result.MinObject = storageutil.ConvertObjToMinObject(o)
   350:         }
   351:         return result, nil
   352: }
   353:
   354: // Fail if the name already exists. Pass on errors directly.
   355: func (d *dirInode) createNewObject(
   356:         ctx context.Context,
   357:         name Name,
   358:         metadata map[string]string) (o *gcs.Object, err error) {
   359:         // Create an empty backing object for the child, failing if it already
   360:         // exists.
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.findDirInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:341 (PC: 0x1917007)
   321:         }, nil
   322: }
   323:
   324: // findDirInode finds the dir inode core where the directory is either explicit
   325: // or implicit. Returns nil if no such directory exists.
   326: func findDirInode(ctx context.Context, bucket *gcsx.SyncerBucket, name Name) (*Core, error) {
   327:         if !name.IsDir() {
   328:                 return nil, fmt.Errorf("%q is not directory", name)
   329:         }
   330:
   331:         req := &gcs.ListObjectsRequest{
   332:                 Prefix:     name.GcsObjectName(),
   333:                 MaxResults: 1,
   334:         }
   335:         listing, err := bucket.ListObjects(ctx, req)
   336:         if err != nil {
   337:                 return nil, fmt.Errorf("list objects: %w", err)
   338:         }
   339:
   340:         if len(listing.Objects) == 0 {
=> 341:                 return nil, nil
   342:         }
   343:
   344:         result := &Core{
   345:                 Bucket:   bucket,
   346:                 FullName: name,
   347:         }
   348:         if o := listing.Objects[0]; o.Name == name.GcsObjectName() {
   349:                 result.MinObject = storageutil.ConvertObjToMinObject(o)
   350:         }
   351:         return result, nil
   352: }
   353:
   354: // Fail if the name already exists. Pass on errors directly.
   355: func (d *dirInode) createNewObject(
   356:         ctx context.Context,
   357:         name Name,
   358:         metadata map[string]string) (o *gcs.Object, err error) {
   359:         // Create an empty backing object for the child, failing if it already
   360:         // exists.
   361:         var precond int64
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func3() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454 (PC: 0x191852c)
Values returned:
        ~r0: *github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Core nil
        ~r1: error nil

   434: const ConflictingFileNameSuffix = "\n"
   435:
   436: // LOCKS_REQUIRED(d)
   437: func (d *dirInode) LookUpChild(ctx context.Context, name string) (*Core, error) {
   438:         // Is this a conflict marker name?
   439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
=> 454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func3() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:455 (PC: 0x19185ae)
   435:
   436: // LOCKS_REQUIRED(d)
   437: func (d *dirInode) LookUpChild(ctx context.Context, name string) (*Core, error) {
   438:         // Is this a conflict marker name?
   439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
   454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
=> 455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
   475:                 b.Add(lookUpFile)
(dlv) 
> github.com/jacobsa/syncutil.(*Bundle).Add.func1() /usr/local/google/home/gargnitin/go/pkg/mod/github.com/jacobsa/syncutil@v0.0.0-20180201203307-228ac8e5a6c3/bundle.go:89 (PC: 0xed4c91)
Values returned:
        err: error nil

    69: type Bundle struct {
    70:         context context.Context
    71:         cancel  context.CancelFunc
    72:
    73:         waitGroup sync.WaitGroup
    74:
    75:         errorOnce  sync.Once
    76:         firstError error
    77: }
    78:
    79: // Add a new operation to the bundle. The operation will be invoked with a
    80: // context that will be cancelled if any other operation fails or has already
    81: // failed.
    82: func (b *Bundle) Add(f func(context.Context) error) {
    83:         b.waitGroup.Add(1)
    84:
    85:         // Run the function in the background.
    86:         go func() {
    87:                 defer b.waitGroup.Done()
    88:
=>  89:                 err := f(b.context)
    90:                 if err == nil {
    91:                         return
    92:                 }
    93:
    94:                 // On first error, cancel the context and save the error.
    95:                 b.errorOnce.Do(func() {
    96:                         b.firstError = err
    97:                         b.cancel()
    98:                 })
    99:         }()
   100: }
   101:
   102: // Wait for all previously-added operations to complete. Return nil if all
   103: // operations succeeded. Otherwise return the first error.
   104: //
   105: // Add must not be called concurrently with or after Join.
   106: func (b *Bundle) Join() error {
   107:         b.waitGroup.Wait()
   108:
   109:         // context.WithCancel requires that we arrange for this to be called
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:488 (hits goroutine(344):1 total:2) (PC: 0x1918202)
> runtime.goexit() /usr/lib/google-golang/src/runtime/asm_amd64.s:1696 (PC: 0x4817c1)
Warning: debugging optimized function
Values returned:

  1676:
  1677: TEXT runtime·return0(SB), NOSPLIT, $0
  1678:         MOVL    $0, AX
  1679:         RET
  1680:
  1681:
  1682: // Called from cgo wrappers, this function returns g->m->curg.stack.hi.
  1683: // Must obey the gcc calling convention.
  1684: TEXT _cgo_topofstack(SB),NOSPLIT,$0
  1685:         get_tls(CX)
  1686:         MOVQ    g(CX), AX
  1687:         MOVQ    g_m(AX), AX
  1688:         MOVQ    m_curg(AX), AX
  1689:         MOVQ    (g_stack+stack_hi)(AX), AX
  1690:         RET
  1691:
  1692: // The top-most function running on a goroutine
  1693: // returns to goexit+PCQuantum.
  1694: TEXT runtime·goexit(SB),NOSPLIT|TOPFRAME|NOFRAME,$0-0
  1695:         BYTE    $0x90   // NOP
=>1696:         CALL    runtime·goexit1(SB)     // does not return
  1697:         // traceback from goexit1 must hit code range of goexit
  1698:         BYTE    $0x90   // NOP
  1699:
  1700: // This is called from .init_array and follows the platform, not Go, ABI.
  1701: TEXT runtime·addmoduledata(SB),NOSPLIT,$0-0
  1702:         PUSHQ   R15 // The access to global variables below implicitly uses R15, which is callee-save
  1703:         MOVQ    runtime·lastmoduledatap(SB), AX
  1704:         MOVQ    DI, moduledata_next(AX)
  1705:         MOVQ    DI, runtime·lastmoduledatap(SB)
  1706:         POPQ    R15
  1707:         RET
  1708:
  1709: // Initialize special registers then jump to sigpanic.
  1710: // This function is injected from the signal handler for panicking
  1711: // signals. It is quite painful to set X15 in the signal context,
  1712: // so we do it here.
  1713: TEXT ·sigpanic0(SB),NOSPLIT,$0-0
  1714:         get_tls(R14)
  1715:         MOVQ    g(R14), R14
  1716: #ifndef GOOS_plan9
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:488 (hits goroutine(344):1 total:2) (PC: 0x1918202)
> runtime.goexit() /usr/lib/google-golang/src/runtime/asm_amd64.s:1696 (PC: 0x4817c1)
Warning: debugging optimized function
Command failed: nothing to stepout to
(dlv) c
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x4835c3)
Warning: debugging optimized function
   539: TEXT runtime·madvise(SB),NOSPLIT,$0
   540:         MOVQ    addr+0(FP), DI
   541:         MOVQ    n+8(FP), SI
   542:         MOVL    flags+16(FP), DX
   543:         MOVQ    $SYS_madvise, AX
   544:         SYSCALL
   545:         MOVL    AX, ret+24(FP)
   546:         RET
   547:
   548: // int64 futex(int32 *uaddr, int32 op, int32 val,
   549: //      struct timespec *timeout, int32 *uaddr2, int32 val2);
   550: TEXT runtime·futex(SB),NOSPLIT,$0
   551:         MOVQ    addr+0(FP), DI
   552:         MOVL    op+8(FP), SI
   553:         MOVL    val+12(FP), DX
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
   565:         MOVQ    stk+8(FP), SI
   566:         MOVQ    $0, DX
   567:         MOVQ    $0, R10
   568:         MOVQ    $0, R8
   569:         // Copy mp, gp, fn off parent stack for use by child.
   570:         // Careful: Linux system call clobbers CX and R11.
   571:         MOVQ    mp+16(FP), R13
   572:         MOVQ    gp+24(FP), R9
   573:         MOVQ    fn+32(FP), R12
   574:         CMPQ    R13, $0    // m
   575:         JEQ     nog1
   576:         CMPQ    R9, $0    // g
   577:         JEQ     nog1
   578:         LEAQ    m_tls(R13), R8
   579: #ifdef GOOS_android
(dlv) q
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ sudo umount $mountpath ; ./creationSituation.sh 1               
+ echo Number of args: 1
Number of args: 1
+ debug=0
+ run=1
+ '[' 1 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 1 -gt 1 ']'
+ '[' 0 -ne 0 ']'
+ echo 'Running ...'
Running ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 0 = 0 ']'
+ go run /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse --config-file=config.yml --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
{"timestamp":{"seconds":1714849125,"nanos":280879336},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
time="04/05/2024 06:58:45.281233" severity=INFO message="Start gcsfuse/unknown (Go version go1.23-20240317-RC00 cl/616607620 +0a6f05e30f X:fieldtrack,boringcrypto) for app \"\" using mount point: /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4\n"
time="04/05/2024 06:58:45.424765" severity=INFO message="File system has been successfully mounted."
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ sudo umount $mountpath ; ./creationSituation.sh 1
[sudo] password for gargnitin: 
+ echo Number of args: 1
Number of args: 1
+ debug=0
+ run=1
+ '[' 1 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 1 -gt 1 ']'
+ '[' 0 -ne 0 ']'
+ echo 'Running ...'
Running ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 0 = 0 ']'
+ go run /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse --config-file=config.yml --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
{"timestamp":{"seconds":1714850398,"nanos":263841584},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
time="04/05/2024 07:19:58.264122" severity=INFO message="Start gcsfuse/unknown (Go version go1.23-20240317-RC00 cl/616607620 +0a6f05e30f X:fieldtrack,boringcrypto) for app \"\" using mount point: /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4\n"
time="04/05/2024 07:19:58.399460" severity=INFO message="File system has been successfully mounted."
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ sudo umount $mountpath ; ./creationSituation.sh 1        
[sudo] password for gargnitin: 
+ echo Number of args: 1
Number of args: 1
+ debug=0
+ run=1
+ '[' 1 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 1 -gt 1 ']'
+ '[' 0 -ne 0 ']'
+ echo 'Running ...'
Running ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 0 = 0 ']'
+ go run /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse --config-file=config.yml --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
{"timestamp":{"seconds":1714853199,"nanos":878813597},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
time="04/05/2024 08:06:39.879180" severity=INFO message="Start gcsfuse/unknown (Go version go1.23-20240317-RC00 cl/616607620 +0a6f05e30f X:fieldtrack,boringcrypto) for app \"\" using mount point: /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4\n"
time="04/05/2024 08:06:40.027626" severity=INFO message="File system has been successfully mounted."
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ sudo umount $mountpath ; ./creationSituation.sh 1 debug
[sudo] password for gargnitin: 
+ echo Number of args: 2
Number of args: 2
+ debug=0
+ run=1
+ '[' 2 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 2 -gt 1 ']'
+ debug=1
+ '[' 1 -ne 0 ']'
+ echo 'Debugging ...'
Debugging ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 1 = 0 ']'
+ dlv debug --check-go-version=false /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/. -- --config-file=config.yml --foreground --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
WARNING: undefined behavior - Go version go0.0 is too old for this version of Delve (minimum supported version 1.19)
Type 'help' for list of commands.
(dlv) q       
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ sudo umount $mountpath ; ./creationSituation.sh 1      
[sudo] password for gargnitin: 
umount: /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4: not mounted.
+ echo Number of args: 1
Number of args: 1
+ debug=0
+ run=1
+ '[' 1 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 1 -gt 1 ']'
+ '[' 0 -ne 0 ']'
+ echo 'Running ...'
Running ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 0 = 0 ']'
+ go run /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse --config-file=config.yml --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
{"timestamp":{"seconds":1714912478,"nanos":63093904},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
time="05/05/2024 12:34:38.063446" severity=INFO message="Start gcsfuse/unknown (Go version go1.23-20240317-RC00 cl/616607620 +0a6f05e30f X:fieldtrack,boringcrypto) for app \"\" using mount point: /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4\n"
time="05/05/2024 12:34:38.240770" severity=INFO message="File system has been successfully mounted."
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ cho $bucket 
Command cho not found
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ 
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ echo $bucket                                     
gargnitin-test-empty-dirname-asia-se1
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ ./creationSituation.sh 1                                        
+ echo Number of args: 1
Number of args: 1
+ debug=0
+ run=1
+ '[' 1 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 1 -gt 1 ']'
+ '[' 0 -ne 0 ']'
+ echo 'Running ...'
Running ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 0 = 0 ']'
+ go run /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse --config-file=config.yml --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
go: downloading cloud.google.com/go/longrunning v0.5.5
{"timestamp":{"seconds":1715193011,"nanos":760577233},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
time="08/05/2024 06:30:11.761772" severity=INFO message="Start gcsfuse/unknown (Go version go1.23-20240419-RC02 cl/626470163 +7f76c00fc5 X:fieldtrack,boringcrypto) for app \"\" using mount point: /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4\n"
time="08/05/2024 06:30:11.928745" severity=INFO message="File system has been successfully mounted."
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ ./creationSituation.sh 1 
+ echo Number of args: 1
Number of args: 1
+ debug=0
+ run=1
+ '[' 1 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 1 -gt 1 ']'
+ '[' 0 -ne 0 ']'
+ echo 'Running ...'
Running ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 0 = 0 ']'
+ go run /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse --config-file=config.yml --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
{"timestamp":{"seconds":1715194389,"nanos":950680469},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
time="08/05/2024 06:53:09.951151" severity=INFO message="Start gcsfuse/unknown (Go version go1.23-20240419-RC02 cl/626470163 +7f76c00fc5 X:fieldtrack,boringcrypto) for app \"\" using mount point: /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4\n"
time="08/05/2024 06:53:10.099211" severity=INFO message="File system has been successfully mounted."
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ ./creationSituation.sh 1 
+ echo Number of args: 1
Number of args: 1
+ debug=0
+ run=1
+ '[' 1 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 1 -gt 1 ']'
+ '[' 0 -ne 0 ']'
+ echo 'Running ...'
Running ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 0 = 0 ']'
+ go run /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse --config-file=config.yml --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
{"timestamp":{"seconds":1715194489,"nanos":454549772},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
time="08/05/2024 06:54:49.455063" severity=INFO message="Start gcsfuse/unknown (Go version go1.23-20240419-RC02 cl/626470163 +7f76c00fc5 X:fieldtrack,boringcrypto) for app \"\" using mount point: /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4\n"
time="08/05/2024 06:54:49.597689" severity=INFO message="File system has been successfully mounted."
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ ./creationSituation.sh 1                                        
+ echo Number of args: 1
Number of args: 1
+ debug=0
+ run=1
+ '[' 1 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 1 -gt 1 ']'
+ '[' 0 -ne 0 ']'
+ echo 'Running ...'
Running ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 0 = 0 ']'
+ go run /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse --config-file=config.yml --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
{"timestamp":{"seconds":1715194549,"nanos":636803531},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
time="08/05/2024 06:55:49.638786" severity=INFO message="Start gcsfuse/unknown (Go version go1.23-20240419-RC02 cl/626470163 +7f76c00fc5 X:fieldtrack,boringcrypto) for app \"\" using mount point: /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4\n"
time="08/05/2024 06:55:49.773478" severity=INFO message="File system has been successfully mounted."
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ ./creationSituation.sh 1 debug
+ echo Number of args: 2
Number of args: 2
+ debug=0
+ run=1
+ '[' 2 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 2 -gt 1 ']'
+ debug=1
+ '[' 1 -ne 0 ']'
+ echo 'Debugging ...'
Debugging ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 1 = 0 ']'
+ dlv debug --check-go-version=false /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/. -- --config-file=config.yml --foreground --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
WARNING: undefined behavior - Go version go0.0 is too old for this version of Delve (minimum supported version 1.19)
Type 'help' for list of commands.
(dlv) config source-list-line-count 20
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:283
Breakpoint 1 set at 0x18ef190 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:283
(dlv) bp
Breakpoint runtime-fatal-throw (enabled) at 0x446404,0x4464e4,0x45f38e for (multiple functions)() <multiple locations>:0 (0)
Breakpoint unrecovered-panic (enabled) at 0x4469a4 for runtime.fatalpanic() /usr/lib/google-golang/src/runtime/panic.go:1219 (0)
        print runtime.curg._panic.arg
Breakpoint 1 (enabled) at 0x18ef190 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:283 (0)
(dlv) toggle 1
Breakpoint 1 toggled at 0x18ef190 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:283
(dlv) r
Process restarted with PID 1568959
(dlv) c
{"timestamp":{"seconds":1715194749,"nanos":867560790},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x483b03)
Warning: debugging optimized function
   539: TEXT runtime·madvise(SB),NOSPLIT,$0
   540:         MOVQ    addr+0(FP), DI
   541:         MOVQ    n+8(FP), SI
   542:         MOVL    flags+16(FP), DX
   543:         MOVQ    $SYS_madvise, AX
   544:         SYSCALL
   545:         MOVL    AX, ret+24(FP)
   546:         RET
   547:
   548: // int64 futex(int32 *uaddr, int32 op, int32 val,
   549: //      struct timespec *timeout, int32 *uaddr2, int32 val2);
   550: TEXT runtime·futex(SB),NOSPLIT,$0
   551:         MOVQ    addr+0(FP), DI
   552:         MOVL    op+8(FP), SI
   553:         MOVL    val+12(FP), DX
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
   565:         MOVQ    stk+8(FP), SI
   566:         MOVQ    $0, DX
   567:         MOVQ    $0, R10
   568:         MOVQ    $0, R8
   569:         // Copy mp, gp, fn off parent stack for use by child.
   570:         // Careful: Linux system call clobbers CX and R11.
   571:         MOVQ    mp+16(FP), R13
   572:         MOVQ    gp+24(FP), R9
   573:         MOVQ    fn+32(FP), R12
   574:         CMPQ    R13, $0    // m
   575:         JEQ     nog1
   576:         CMPQ    R9, $0    // g
   577:         JEQ     nog1
   578:         LEAQ    m_tls(R13), R8
   579: #ifdef GOOS_android
(dlv) toggle 1
Breakpoint 1 toggled at 0x0 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:283
(dlv) bp
Breakpoint runtime-fatal-throw (enabled) at 0x45f38e,0x446404,0x4464e4 for (multiple functions)() <multiple locations>:0 (0)
Breakpoint unrecovered-panic (enabled) at 0x4469a4 for runtime.fatalpanic() /usr/lib/google-golang/src/runtime/panic.go:1219 (0)
        print runtime.curg._panic.arg
Breakpoint 1 (enabled) at 0x18ef190 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:283 (0)
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:282
Breakpoint 2 set at 0x18ef177 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:282
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:282 (hits goroutine(338):1 total:1) (PC: 0x18ef177)
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("Error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
=> 282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 // Do not list unsupported directories such as '.', '..',
   285:                                 // '/', and '\0' as prefixes, which become implicit directories,
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
   292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
(dlv) p attrs.Prefix
""
(dlv) p len(attrs.Prefix)
0
(dlv) bp
Breakpoint runtime-fatal-throw (enabled) at 0x446404,0x4464e4,0x45f38e for (multiple functions)() <multiple locations>:0 (0)
Breakpoint unrecovered-panic (enabled) at 0x4469a4 for runtime.fatalpanic() /usr/lib/google-golang/src/runtime/panic.go:1219 (0)
        print runtime.curg._panic.arg
Breakpoint 1 (enabled) at 0x18ef190 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:283 (0)
Breakpoint 2 (enabled) at 0x18ef177 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:282 (1)
(dlv) toggle 1
Breakpoint 1 toggled at 0x18ef190 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:283
(dlv) toggle 2
Breakpoint 2 toggled at 0x18ef177 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:282
(dlv) c
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x483b03)
Warning: debugging optimized function
   539: TEXT runtime·madvise(SB),NOSPLIT,$0
   540:         MOVQ    addr+0(FP), DI
   541:         MOVQ    n+8(FP), SI
   542:         MOVL    flags+16(FP), DX
   543:         MOVQ    $SYS_madvise, AX
   544:         SYSCALL
   545:         MOVL    AX, ret+24(FP)
   546:         RET
   547:
   548: // int64 futex(int32 *uaddr, int32 op, int32 val,
   549: //      struct timespec *timeout, int32 *uaddr2, int32 val2);
   550: TEXT runtime·futex(SB),NOSPLIT,$0
   551:         MOVQ    addr+0(FP), DI
   552:         MOVL    op+8(FP), SI
   553:         MOVL    val+12(FP), DX
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
   565:         MOVQ    stk+8(FP), SI
   566:         MOVQ    $0, DX
   567:         MOVQ    $0, R10
   568:         MOVQ    $0, R8
   569:         // Copy mp, gp, fn off parent stack for use by child.
   570:         // Careful: Linux system call clobbers CX and R11.
   571:         MOVQ    mp+16(FP), R13
   572:         MOVQ    gp+24(FP), R9
   573:         MOVQ    fn+32(FP), R12
   574:         CMPQ    R13, $0    // m
   575:         JEQ     nog1
   576:         CMPQ    R9, $0    // g
   577:         JEQ     nog1
   578:         LEAQ    m_tls(R13), R8
   579: #ifdef GOOS_android
(dlv) c
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x483b03)
Warning: debugging optimized function
   539: TEXT runtime·madvise(SB),NOSPLIT,$0
   540:         MOVQ    addr+0(FP), DI
   541:         MOVQ    n+8(FP), SI
   542:         MOVL    flags+16(FP), DX
   543:         MOVQ    $SYS_madvise, AX
   544:         SYSCALL
   545:         MOVL    AX, ret+24(FP)
   546:         RET
   547:
   548: // int64 futex(int32 *uaddr, int32 op, int32 val,
   549: //      struct timespec *timeout, int32 *uaddr2, int32 val2);
   550: TEXT runtime·futex(SB),NOSPLIT,$0
   551:         MOVQ    addr+0(FP), DI
   552:         MOVL    op+8(FP), SI
   553:         MOVL    val+12(FP), DX
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
   565:         MOVQ    stk+8(FP), SI
   566:         MOVQ    $0, DX
   567:         MOVQ    $0, R10
   568:         MOVQ    $0, R8
   569:         // Copy mp, gp, fn off parent stack for use by child.
   570:         // Careful: Linux system call clobbers CX and R11.
   571:         MOVQ    mp+16(FP), R13
   572:         MOVQ    gp+24(FP), R9
   573:         MOVQ    fn+32(FP), R12
   574:         CMPQ    R13, $0    // m
   575:         JEQ     nog1
   576:         CMPQ    R9, $0    // g
   577:         JEQ     nog1
   578:         LEAQ    m_tls(R13), R8
   579: #ifdef GOOS_android
(dlv) q
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ fusermount -uz $mountpath ; ./creationSituation.sh 1 debug      
+ echo Number of args: 2
Number of args: 2
+ debug=0
+ run=1
+ '[' 2 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 2 -gt 1 ']'
+ debug=1
+ '[' 1 -ne 0 ']'
+ echo 'Debugging ...'
Debugging ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 1 = 0 ']'
+ dlv debug --check-go-version=false /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/. -- --config-file=config.yml --foreground --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
WARNING: undefined behavior - Go version go0.0 is too old for this version of Delve (minimum supported version 1.19)
Type 'help' for list of commands.
(dlv) config source-list-line-count 20
(dlv) r
Process restarted with PID 1571199
(dlv) c
{"timestamp":{"seconds":1715194977,"nanos":768042778},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x483b03)
Warning: debugging optimized function
   539: TEXT runtime·madvise(SB),NOSPLIT,$0
   540:         MOVQ    addr+0(FP), DI
   541:         MOVQ    n+8(FP), SI
   542:         MOVL    flags+16(FP), DX
   543:         MOVQ    $SYS_madvise, AX
   544:         SYSCALL
   545:         MOVL    AX, ret+24(FP)
   546:         RET
   547:
   548: // int64 futex(int32 *uaddr, int32 op, int32 val,
   549: //      struct timespec *timeout, int32 *uaddr2, int32 val2);
   550: TEXT runtime·futex(SB),NOSPLIT,$0
   551:         MOVQ    addr+0(FP), DI
   552:         MOVL    op+8(FP), SI
   553:         MOVL    val+12(FP), DX
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
   565:         MOVQ    stk+8(FP), SI
   566:         MOVQ    $0, DX
   567:         MOVQ    $0, R10
   568:         MOVQ    $0, R8
   569:         // Copy mp, gp, fn off parent stack for use by child.
   570:         // Careful: Linux system call clobbers CX and R11.
   571:         MOVQ    mp+16(FP), R13
   572:         MOVQ    gp+24(FP), R9
   573:         MOVQ    fn+32(FP), R12
   574:         CMPQ    R13, $0    // m
   575:         JEQ     nog1
   576:         CMPQ    R9, $0    // g
   577:         JEQ     nog1
   578:         LEAQ    m_tls(R13), R8
   579: #ifdef GOOS_android
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:292
Breakpoint 1 set at 0x18ef1ca for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:292
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:294
Breakpoint 2 set at 0x18ef299 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:294
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:302
Breakpoint 3 set at 0x18ef3ab for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:302
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306
Breakpoint 4 set at 0x18ef473 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306 (hits goroutine(373):1 total:1) (PC: 0x18ef473)
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
   292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
=> 306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
   323:         listing = &list
   324:         return
   325: }
   326:
(dlv) p attrs.Name
"14"
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306 (hits goroutine(373):2 total:2) (PC: 0x18ef473)
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
   292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
=> 306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
   323:         listing = &list
   324:         return
   325: }
   326:
(dlv) p attrs.Name
"walked/"
(dlv) c           
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:292 (hits goroutine(373):1 total:1) (PC: 0x18ef1ca)
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("Error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 // Do not list unsupported directories such as '.', '..',
   285:                                 // '/', and '\0' as prefixes, which become implicit directories,
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
=> 292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
(dlv) p attrs.Prefix
"../"
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:292 (hits goroutine(373):2 total:2) (PC: 0x18ef1ca)
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("Error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 // Do not list unsupported directories such as '.', '..',
   285:                                 // '/', and '\0' as prefixes, which become implicit directories,
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
=> 292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
(dlv) p attrs.Prefix
"./"
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:292 (hits goroutine(373):3 total:3) (PC: 0x18ef1ca)
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("Error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 // Do not list unsupported directories such as '.', '..',
   285:                                 // '/', and '\0' as prefixes, which become implicit directories,
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
=> 292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
(dlv) p attrs.Prefix
"/"
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:294 (hits goroutine(373):1 total:1) (PC: 0x18ef299)
   274:                 if err != nil {
   275:                         err = fmt.Errorf("Error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 // Do not list unsupported directories such as '.', '..',
   285:                                 // '/', and '\0' as prefixes, which become implicit directories,
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
   292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
=> 294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
(dlv) p attrs.Prefix
"a/"
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:294 (hits goroutine(373):2 total:2) (PC: 0x18ef299)
   274:                 if err != nil {
   275:                         err = fmt.Errorf("Error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 // Do not list unsupported directories such as '.', '..',
   285:                                 // '/', and '\0' as prefixes, which become implicit directories,
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
   292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
=> 294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
(dlv) p attrs.Prefix
"walked/"
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:302 (hits goroutine(224):1 total:1) (PC: 0x18ef3ab)
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 // Do not list unsupported directories such as '.', '..',
   285:                                 // '/', and '\0' as prefixes, which become implicit directories,
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
   292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
=> 302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
(dlv) p attrs.Prefix
""
(dlv) p attrs.Name  
"a/../8"
(dlv) bt
0  0x00000000018ef3ab in github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects
   at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:302
1  0x00000000018f387d in github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*debugBucket).ListObjects
   at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/debug_bucket.go:205
2  0x000000000193a868 in github.com/googlecloudplatform/gcsfuse/v2/internal/gcsx.(*contentTypeBucket).ListObjects
   at <autogenerated>:1
3  0x00000000019443e8 in github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.findDirInode
   at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:335
4  0x0000000001945acc in github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func3
   at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454
5  0x0000000000f5ea91 in github.com/jacobsa/syncutil.(*Bundle).Add.func1
   at /usr/local/google/home/gargnitin/go/pkg/mod/github.com/jacobsa/syncutil@v0.0.0-20180201203307-228ac8e5a6c3/bundle.go:89
6  0x0000000000481d01 in runtime.goexit
   at /usr/lib/google-golang/src/runtime/asm_amd64.s:1695
(dlv) l
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:302 (hits goroutine(224):1 total:1) (PC: 0x18ef3ab)
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 // Do not list unsupported directories such as '.', '..',
   285:                                 // '/', and '\0' as prefixes, which become implicit directories,
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
   292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
=> 302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
(dlv) b 322
Breakpoint 5 set at 0x18ef56d for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:322
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306 (hits goroutine(224):1 total:3) (PC: 0x18ef473)
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
   292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
=> 306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
   323:         listing = &list
   324:         return
   325: }
   326:
(dlv) p attrs.Name
"a/../8"
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:322 (hits goroutine(224):1 total:1) (PC: 0x18ef56d)
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
=> 322:         list.ContinuationToken = itr.PageInfo().Token
   323:         listing = &list
   324:         return
   325: }
   326:
   327: func (b *bucketHandle) UpdateObject(ctx context.Context, req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   328:         obj := b.bucket.Object(req.Name)
   329:
   330:         if req.Generation != 0 {
   331:                 obj = obj.Generation(req.Generation)
   332:         }
   333:
   334:         if req.MetaGenerationPrecondition != nil {
   335:                 obj = obj.If(storage.Conditions{MetagenerationMatch: *req.MetaGenerationPrecondition})
   336:         }
   337:
   338:         updateQuery := storage.ObjectAttrsToUpdate{}
   339:
   340:         if req.ContentType != nil {
   341:                 updateQuery.ContentType = *req.ContentType
   342:         }
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:323 (PC: 0x18ef5b8)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
=> 323:         listing = &list
   324:         return
   325: }
   326:
   327: func (b *bucketHandle) UpdateObject(ctx context.Context, req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   328:         obj := b.bucket.Object(req.Name)
   329:
   330:         if req.Generation != 0 {
   331:                 obj = obj.Generation(req.Generation)
   332:         }
   333:
   334:         if req.MetaGenerationPrecondition != nil {
   335:                 obj = obj.If(storage.Conditions{MetagenerationMatch: *req.MetaGenerationPrecondition})
   336:         }
   337:
   338:         updateQuery := storage.ObjectAttrsToUpdate{}
   339:
   340:         if req.ContentType != nil {
   341:                 updateQuery.ContentType = *req.ContentType
   342:         }
   343:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:324 (PC: 0x18ef5c5)
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
   323:         listing = &list
=> 324:         return
   325: }
   326:
   327: func (b *bucketHandle) UpdateObject(ctx context.Context, req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   328:         obj := b.bucket.Object(req.Name)
   329:
   330:         if req.Generation != 0 {
   331:                 obj = obj.Generation(req.Generation)
   332:         }
   333:
   334:         if req.MetaGenerationPrecondition != nil {
   335:                 obj = obj.If(storage.Conditions{MetagenerationMatch: *req.MetaGenerationPrecondition})
   336:         }
   337:
   338:         updateQuery := storage.ObjectAttrsToUpdate{}
   339:
   340:         if req.ContentType != nil {
   341:                 updateQuery.ContentType = *req.ContentType
   342:         }
   343:
   344:         if req.ContentEncoding != nil {
(dlv) p listing
("*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing")(0xc000ac40c0)
*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing {
        Objects: []*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object len: 1, cap: 1, [
                *(*"github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object")(0xc0001ba140),
        ],
        CollapsedRuns: []string len: 0, cap: 0, nil,
        ContinuationToken: "CgZhLy4uLzg=",}
(dlv) p Objects[0]
Command failed: could not find symbol value for Objects
(dlv) p list.Objects
[]*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object len: 1, cap: 1, [
        *{
                Name: "a/../8",
                ContentType: "text/plain",
                ContentLanguage: "",
                CacheControl: "",
                Owner: "",
                Size: 6,
                ContentEncoding: "",
                MD5: *[16]uint8 [177,148,106,201,36,146,210,52,124,98,53,180,210,97,17,132],
                CRC32C: *893245630,
                MediaLink: "https://storage.googleapis.com/download/storage/v1/b/gargnitin-t...+77 more",
                Metadata: map[string]string nil,
                Generation: 1714642897885179,
                MetaGeneration: 1,
                StorageClass: "STANDARD",
                Deleted: (*time.Time)(0xc0001ba1f0),
                Updated: (*time.Time)(0xc0001ba208),
                ComponentCount: 0,
                ContentDisposition: "",
                CustomTime: "0001-01-01T00:00:00Z",
                EventBasedHold: false,
                Acl: []*google.golang.org/api/storage/v1.ObjectAccessControl len: 0, cap: 0, nil,},
]
(dlv) q
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ fusermount -uz $mountpath ; ./creationSituation.sh 1 debug
+ echo Number of args: 2
Number of args: 2
+ debug=0
+ run=1
+ '[' 2 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 2 -gt 1 ']'
+ debug=1
+ '[' 1 -ne 0 ']'
+ echo 'Debugging ...'
Debugging ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 1 = 0 ']'
+ dlv debug --check-go-version=false /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/. -- --config-file=config.yml --foreground --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
WARNING: undefined behavior - Go version go0.0 is too old for this version of Delve (minimum supported version 1.19)
Type 'help' for list of commands.
(dlv) r
Process restarted with PID 1575640
(dlv) c
{"timestamp":{"seconds":1715195336,"nanos":277672884},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x483b03)
Warning: debugging optimized function
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
(dlv) config source-list-line-count 20
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:292
Breakpoint 1 set at 0x18ef1ca for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:292
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:294
Breakpoint 2 set at 0x18ef299 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:294
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:302
Breakpoint 3 set at 0x18ef3ab for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:302
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306
Breakpoint 4 set at 0x18ef473 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306 at 18ef473
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode
Breakpoint 6 set at 0x1968a36 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir
Breakpoint 7 set at 0x1972776 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir
Breakpoint 8 set at 0x1972473 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2126
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 (hits goroutine(338):1 total:1) (PC: 0x1968a36)
  1294:         // Simulate a large amount of free space so that the Finder doesn't refuse to
  1295:         // copy in files. (See issue #125.) Use 2^17 as the block size because that
  1296:         // is the largest that OS X will pass on.
  1297:         op.BlockSize = 1 << 17
  1298:         op.Blocks = 1 << 33
  1299:         op.BlocksFree = op.Blocks
  1300:         op.BlocksAvailable = op.Blocks
  1301:
  1302:         // Similarly with inodes.
  1303:         op.Inodes = 1 << 50
  1304:         op.InodesFree = op.Inodes
  1305:
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
=>1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
(dlv) p op
("*github.com/jacobsa/fuse/fuseops.LookUpInodeOp")(0xc0009fe960)
*github.com/jacobsa/fuse/fuseops.LookUpInodeOp {
        Parent: 1,
        Name: "walked",
        Entry: github.com/jacobsa/fuse/fuseops.ChildInodeEntry {
                Child: 0,
                Generation: 0,
                Attributes: (*"github.com/jacobsa/fuse/fuseops.InodeAttributes")(0xc0009fe988),
                AttributesExpiration: (*time.Time)(0xc0009fea08),
                EntryExpiration: (*time.Time)(0xc0009fea20),},
        OpContext: github.com/jacobsa/fuse/fuseops.OpContext {FuseID: 386, Pid: 1576076, Uid: 1012083},}
(dlv) bt
0  0x0000000001968a36 in github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode
   at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314
1  0x0000000001957ba6 in github.com/googlecloudplatform/gcsfuse/v2/internal/fs/wrappers.(*errorMapping).LookUpInode
   at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/wrappers/error_mapping.go:126
2  0x000000000195c7ab in github.com/googlecloudplatform/gcsfuse/v2/internal/fs/wrappers.(*monitoring).LookUpInode
   at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/wrappers/monitoring.go:156
3  0x000000000193f744 in github.com/jacobsa/fuse/fuseutil.(*fileSystemServer).handleOp
   at /usr/local/google/home/gargnitin/go/pkg/mod/github.com/jacobsa/fuse@v0.0.0-20231003132804-d0f3daf365c3/fuseutil/file_system.go:144
4  0x000000000193f466 in github.com/jacobsa/fuse/fuseutil.(*fileSystemServer).ServeOps.gowrap1
   at /usr/local/google/home/gargnitin/go/pkg/mod/github.com/jacobsa/fuse@v0.0.0-20231003132804-d0f3daf365c3/fuseutil/file_system.go:123
5  0x0000000000481d01 in runtime.goexit
   at /usr/lib/google-golang/src/runtime/asm_amd64.s:1695
(dlv) bp
Breakpoint runtime-fatal-throw (enabled) at 0x4464e4,0x446404,0x45f38e for (multiple functions)() <multiple locations>:0 (0)
Breakpoint unrecovered-panic (enabled) at 0x4469a4 for runtime.fatalpanic() /usr/lib/google-golang/src/runtime/panic.go:1219 (0)
        print runtime.curg._panic.arg
Breakpoint 1 (enabled) at 0x18ef1ca for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:292 (0)
Breakpoint 2 (enabled) at 0x18ef299 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:294 (0)
Breakpoint 3 (enabled) at 0x18ef3ab for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:302 (0)
Breakpoint 4 (enabled) at 0x18ef473 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306 (0)
Breakpoint 6 (enabled) at 0x1968a36 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 (1)
Breakpoint 7 (enabled) at 0x1972776 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148 (0)
Breakpoint 8 (enabled) at 0x1972473 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2126 (0)
(dlv) l 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 (hits goroutine(338):1 total:1) (PC: 0x1968a36)
  1294:         // Simulate a large amount of free space so that the Finder doesn't refuse to
  1295:         // copy in files. (See issue #125.) Use 2^17 as the block size because that
  1296:         // is the largest that OS X will pass on.
  1297:         op.BlockSize = 1 << 17
  1298:         op.Blocks = 1 << 33
  1299:         op.BlocksFree = op.Blocks
  1300:         op.BlocksAvailable = op.Blocks
  1301:
  1302:         // Similarly with inodes.
  1303:         op.Inodes = 1 << 50
  1304:         op.InodesFree = op.Inodes
  1305:
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
=>1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1317 (PC: 0x1968a66)
  1297:         op.BlockSize = 1 << 17
  1298:         op.Blocks = 1 << 33
  1299:         op.BlocksFree = op.Blocks
  1300:         op.BlocksAvailable = op.Blocks
  1301:
  1302:         // Similarly with inodes.
  1303:         op.Inodes = 1 << 50
  1304:         op.InodesFree = op.Inodes
  1305:
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
=>1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1325 (PC: 0x1968b72)
  1305:
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
=>1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
  1345:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1326 (PC: 0x1968b8f)
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
=>1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
  1345:
  1346:         return
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1327 (PC: 0x1968bc1)
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
=>1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
  1345:
  1346:         return
  1347: }
(dlv) b 1335
Breakpoint 9 set at 0x1968d05 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1335
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306 (hits goroutine(333):1 total:1) (PC: 0x18ef473)
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
   292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
=> 306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
   323:         listing = &list
   324:         return
   325: }
   326:
(dlv) p attrs.Name
"walked/"
(dlv) bp
Breakpoint runtime-fatal-throw (enabled) at 0x4464e4,0x446404,0x45f38e for (multiple functions)() <multiple locations>:0 (0)
Breakpoint unrecovered-panic (enabled) at 0x4469a4 for runtime.fatalpanic() /usr/lib/google-golang/src/runtime/panic.go:1219 (0)
        print runtime.curg._panic.arg
Breakpoint 1 (enabled) at 0x18ef1ca for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:292 (0)
Breakpoint 2 (enabled) at 0x18ef299 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:294 (0)
Breakpoint 3 (enabled) at 0x18ef3ab for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:302 (0)
Breakpoint 4 (enabled) at 0x18ef473 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306 (1)
Breakpoint 6 (enabled) at 0x1968a36 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 (1)
Breakpoint 7 (enabled) at 0x1972776 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148 (0)
Breakpoint 8 (enabled) at 0x1972473 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2126 (0)
Breakpoint 9 (enabled) at 0x1968d05 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1335 (0)
(dlv) b 324
Breakpoint 10 set at 0x18ef5c5 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:324
(dlv) l;
Command failed: command not available
(dlv) l
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306 (hits goroutine(333):1 total:1) (PC: 0x18ef473)
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
   292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
=> 306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
   323:         listing = &list
   324:         return
   325: }
   326:
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:324 (hits goroutine(333):1 total:1) (PC: 0x18ef5c5)
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
   323:         listing = &list
=> 324:         return
   325: }
   326:
   327: func (b *bucketHandle) UpdateObject(ctx context.Context, req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   328:         obj := b.bucket.Object(req.Name)
   329:
   330:         if req.Generation != 0 {
   331:                 obj = obj.Generation(req.Generation)
   332:         }
   333:
   334:         if req.MetaGenerationPrecondition != nil {
   335:                 obj = obj.If(storage.Conditions{MetagenerationMatch: *req.MetaGenerationPrecondition})
   336:         }
   337:
   338:         updateQuery := storage.ObjectAttrsToUpdate{}
   339:
   340:         if req.ContentType != nil {
   341:                 updateQuery.ContentType = *req.ContentType
   342:         }
   343:
   344:         if req.ContentEncoding != nil {
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*debugBucket).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/debug_bucket.go:205 (PC: 0x18f387d)
Values returned:
        listing: ("*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing")(0xc001150040)
*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing {
                Objects: []*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object len: 1, cap: 1, [
                        *(*"github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object")(0xc0006d0000),
                ],
                CollapsedRuns: []string len: 0, cap: 0, nil,
                ContinuationToken: "Cgd3YWxrZWQv",}
        err: error nil

   185:         o, err = b.wrapped.ComposeObjects(ctx, req)
   186:         return
   187: }
   188:
   189: func (b *debugBucket) StatObject(
   190:         ctx context.Context,
   191:         req *gcs.StatObjectRequest) (m *gcs.MinObject, e *gcs.ExtendedObjectAttributes, err error) {
   192:         id, desc, start := b.startRequest("StatObject(%q)", req.Name)
   193:         defer b.finishRequest(id, desc, start, &err)
   194:
   195:         m, e, err = b.wrapped.StatObject(ctx, req)
   196:         return
   197: }
   198:
   199: func (b *debugBucket) ListObjects(
   200:         ctx context.Context,
   201:         req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   202:         id, desc, start := b.startRequest("ListObjects(%q)", req.Prefix)
   203:         defer b.finishRequest(id, desc, start, &err)
   204:
=> 205:         listing, err = b.wrapped.ListObjects(ctx, req)
   206:         return
   207: }
   208:
   209: func (b *debugBucket) UpdateObject(
   210:         ctx context.Context,
   211:         req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   212:         id, desc, start := b.startRequest("UpdateObject(%q)", req.Name)
   213:         defer b.finishRequest(id, desc, start, &err)
   214:
   215:         o, err = b.wrapped.UpdateObject(ctx, req)
   216:         return
   217: }
   218:
   219: func (b *debugBucket) DeleteObject(
   220:         ctx context.Context,
   221:         req *gcs.DeleteObjectRequest) (err error) {
   222:         id, desc, start := b.startRequest("DeleteObject(%q)", req.Name)
   223:         defer b.finishRequest(id, desc, start, &err)
   224:
   225:         err = b.wrapped.DeleteObject(ctx, req)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.findDirInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:335 (PC: 0x19443e8)
Values returned:
        ~r0: ("*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing")(0xc001150040)
*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing {
                Objects: []*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object len: 1, cap: 1, [
                        *(*"github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object")(0xc0006d0000),
                ],
                CollapsedRuns: []string len: 0, cap: 0, nil,
                ContinuationToken: "Cgd3YWxrZWQv",}
        ~r1: error nil

   315:         }
   316:
   317:         return &Core{
   318:                 Bucket:    bucket,
   319:                 FullName:  name,
   320:                 MinObject: m,
   321:         }, nil
   322: }
   323:
   324: // findDirInode finds the dir inode core where the directory is either explicit
   325: // or implicit. Returns nil if no such directory exists.
   326: func findDirInode(ctx context.Context, bucket *gcsx.SyncerBucket, name Name) (*Core, error) {
   327:         if !name.IsDir() {
   328:                 return nil, fmt.Errorf("%q is not directory", name)
   329:         }
   330:
   331:         req := &gcs.ListObjectsRequest{
   332:                 Prefix:     name.GcsObjectName(),
   333:                 MaxResults: 1,
   334:         }
=> 335:         listing, err := bucket.ListObjects(ctx, req)
   336:         if err != nil {
   337:                 return nil, fmt.Errorf("list objects: %w", err)
   338:         }
   339:
   340:         if len(listing.Objects) == 0 {
   341:                 return nil, nil
   342:         }
   343:
   344:         result := &Core{
   345:                 Bucket:   bucket,
   346:                 FullName: name,
   347:         }
   348:         if o := listing.Objects[0]; o.Name == name.GcsObjectName() {
   349:                 result.MinObject = storageutil.ConvertObjToMinObject(o)
   350:         }
   351:         return result, nil
   352: }
   353:
   354: // Fail if the name already exists. Pass on errors directly.
   355: func (d *dirInode) createNewObject(
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func3() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454 (PC: 0x1945acc)
Values returned:
        ~r0: ("*github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Core")(0xc0007fc040)
*github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Core {
                FullName: github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Name {bucketName: "", objectName: "walked/"},
                Bucket: *github.com/googlecloudplatform/gcsfuse/v2/internal/gcsx.SyncerBucket {
                        Bucket: (unreadable invalid interface type),
                        Syncer: (unreadable invalid interface type),},
                MinObject: *github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.MinObject {
                        Name: "walked/",
                        Size: 0,
                        Generation: 1715194144661809,
                        MetaGeneration: 1,
                        Updated: (*time.Time)(0xc000b18028),
                        Metadata: map[string]string nil,
                        ContentEncoding: "",},
                Local: false,}
        ~r1: error nil

   434: const ConflictingFileNameSuffix = "\n"
   435:
   436: // LOCKS_REQUIRED(d)
   437: func (d *dirInode) LookUpChild(ctx context.Context, name string) (*Core, error) {
   438:         // Is this a conflict marker name?
   439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
=> 454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
(dlv) 
> github.com/jacobsa/syncutil.(*Bundle).Add.func1() /usr/local/google/home/gargnitin/go/pkg/mod/github.com/jacobsa/syncutil@v0.0.0-20180201203307-228ac8e5a6c3/bundle.go:89 (PC: 0xf5ea91)
Values returned:
        err: error nil

    69: type Bundle struct {
    70:         context context.Context
    71:         cancel  context.CancelFunc
    72:
    73:         waitGroup sync.WaitGroup
    74:
    75:         errorOnce  sync.Once
    76:         firstError error
    77: }
    78:
    79: // Add a new operation to the bundle. The operation will be invoked with a
    80: // context that will be cancelled if any other operation fails or has already
    81: // failed.
    82: func (b *Bundle) Add(f func(context.Context) error) {
    83:         b.waitGroup.Add(1)
    84:
    85:         // Run the function in the background.
    86:         go func() {
    87:                 defer b.waitGroup.Done()
    88:
=>  89:                 err := f(b.context)
    90:                 if err == nil {
    91:                         return
    92:                 }
    93:
    94:                 // On first error, cancel the context and save the error.
    95:                 b.errorOnce.Do(func() {
    96:                         b.firstError = err
    97:                         b.cancel()
    98:                 })
    99:         }()
   100: }
   101:
   102: // Wait for all previously-added operations to complete. Return nil if all
   103: // operations succeeded. Otherwise return the first error.
   104: //
   105: // Add must not be called concurrently with or after Join.
   106: func (b *Bundle) Join() error {
   107:         b.waitGroup.Wait()
   108:
   109:         // context.WithCancel requires that we arrange for this to be called
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1335 (hits goroutine(338):1 total:1) (PC: 0x1968d05)
> runtime.goexit() /usr/lib/google-golang/src/runtime/asm_amd64.s:1696 (PC: 0x481d01)
Warning: debugging optimized function
Values returned:

  1676:
  1677: TEXT runtime·return0(SB), NOSPLIT, $0
  1678:         MOVL    $0, AX
  1679:         RET
  1680:
  1681:
  1682: // Called from cgo wrappers, this function returns g->m->curg.stack.hi.
  1683: // Must obey the gcc calling convention.
  1684: TEXT _cgo_topofstack(SB),NOSPLIT,$0
  1685:         get_tls(CX)
  1686:         MOVQ    g(CX), AX
  1687:         MOVQ    g_m(AX), AX
  1688:         MOVQ    m_curg(AX), AX
  1689:         MOVQ    (g_stack+stack_hi)(AX), AX
  1690:         RET
  1691:
  1692: // The top-most function running on a goroutine
  1693: // returns to goexit+PCQuantum.
  1694: TEXT runtime·goexit(SB),NOSPLIT|TOPFRAME|NOFRAME,$0-0
  1695:         BYTE    $0x90   // NOP
=>1696:         CALL    runtime·goexit1(SB)     // does not return
  1697:         // traceback from goexit1 must hit code range of goexit
  1698:         BYTE    $0x90   // NOP
  1699:
  1700: // This is called from .init_array and follows the platform, not Go, ABI.
  1701: TEXT runtime·addmoduledata(SB),NOSPLIT,$0-0
  1702:         PUSHQ   R15 // The access to global variables below implicitly uses R15, which is callee-save
  1703:         MOVQ    runtime·lastmoduledatap(SB), AX
  1704:         MOVQ    DI, moduledata_next(AX)
  1705:         MOVQ    DI, runtime·lastmoduledatap(SB)
  1706:         POPQ    R15
  1707:         RET
  1708:
  1709: // Initialize special registers then jump to sigpanic.
  1710: // This function is injected from the signal handler for panicking
  1711: // signals. It is quite painful to set X15 in the signal context,
  1712: // so we do it here.
  1713: TEXT ·sigpanic0(SB),NOSPLIT,$0-0
  1714:         get_tls(R14)
  1715:         MOVQ    g(R14), R14
  1716: #ifndef GOOS_plan9
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 (hits goroutine(341):1 total:2) (PC: 0x1968a36)
  1294:         // Simulate a large amount of free space so that the Finder doesn't refuse to
  1295:         // copy in files. (See issue #125.) Use 2^17 as the block size because that
  1296:         // is the largest that OS X will pass on.
  1297:         op.BlockSize = 1 << 17
  1298:         op.Blocks = 1 << 33
  1299:         op.BlocksFree = op.Blocks
  1300:         op.BlocksAvailable = op.Blocks
  1301:
  1302:         // Similarly with inodes.
  1303:         op.Inodes = 1 << 50
  1304:         op.InodesFree = op.Inodes
  1305:
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
=>1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
(dlv) p op
("*github.com/jacobsa/fuse/fuseops.LookUpInodeOp")(0xc0009fe2d0)
*github.com/jacobsa/fuse/fuseops.LookUpInodeOp {
        Parent: 1,
        Name: "walked",
        Entry: github.com/jacobsa/fuse/fuseops.ChildInodeEntry {
                Child: 0,
                Generation: 0,
                Attributes: (*"github.com/jacobsa/fuse/fuseops.InodeAttributes")(0xc0009fe2f8),
                AttributesExpiration: (*time.Time)(0xc0009fe378),
                EntryExpiration: (*time.Time)(0xc0009fe390),},
        OpContext: github.com/jacobsa/fuse/fuseops.OpContext {FuseID: 392, Pid: 1576076, Uid: 1012083},}
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306 (hits goroutine(354):1 total:2) (PC: 0x18ef473)
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
   292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
=> 306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
   323:         listing = &list
   324:         return
   325: }
   326:
(dlv) p attrs.Name
"walked/"
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:324 (hits goroutine(354):1 total:2) (PC: 0x18ef5c5)
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
   323:         listing = &list
=> 324:         return
   325: }
   326:
   327: func (b *bucketHandle) UpdateObject(ctx context.Context, req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   328:         obj := b.bucket.Object(req.Name)
   329:
   330:         if req.Generation != 0 {
   331:                 obj = obj.Generation(req.Generation)
   332:         }
   333:
   334:         if req.MetaGenerationPrecondition != nil {
   335:                 obj = obj.If(storage.Conditions{MetagenerationMatch: *req.MetaGenerationPrecondition})
   336:         }
   337:
   338:         updateQuery := storage.ObjectAttrsToUpdate{}
   339:
   340:         if req.ContentType != nil {
   341:                 updateQuery.ContentType = *req.ContentType
   342:         }
   343:
   344:         if req.ContentEncoding != nil {
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*debugBucket).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/debug_bucket.go:205 (PC: 0x18f387d)
Values returned:
        listing: ("*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing")(0xc0007fc180)
*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing {
                Objects: []*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object len: 1, cap: 1, [
                        *(*"github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object")(0xc0005c17c0),
                ],
                CollapsedRuns: []string len: 0, cap: 0, nil,
                ContinuationToken: "Cgd3YWxrZWQv",}
        err: error nil

   185:         o, err = b.wrapped.ComposeObjects(ctx, req)
   186:         return
   187: }
   188:
   189: func (b *debugBucket) StatObject(
   190:         ctx context.Context,
   191:         req *gcs.StatObjectRequest) (m *gcs.MinObject, e *gcs.ExtendedObjectAttributes, err error) {
   192:         id, desc, start := b.startRequest("StatObject(%q)", req.Name)
   193:         defer b.finishRequest(id, desc, start, &err)
   194:
   195:         m, e, err = b.wrapped.StatObject(ctx, req)
   196:         return
   197: }
   198:
   199: func (b *debugBucket) ListObjects(
   200:         ctx context.Context,
   201:         req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   202:         id, desc, start := b.startRequest("ListObjects(%q)", req.Prefix)
   203:         defer b.finishRequest(id, desc, start, &err)
   204:
=> 205:         listing, err = b.wrapped.ListObjects(ctx, req)
   206:         return
   207: }
   208:
   209: func (b *debugBucket) UpdateObject(
   210:         ctx context.Context,
   211:         req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   212:         id, desc, start := b.startRequest("UpdateObject(%q)", req.Name)
   213:         defer b.finishRequest(id, desc, start, &err)
   214:
   215:         o, err = b.wrapped.UpdateObject(ctx, req)
   216:         return
   217: }
   218:
   219: func (b *debugBucket) DeleteObject(
   220:         ctx context.Context,
   221:         req *gcs.DeleteObjectRequest) (err error) {
   222:         id, desc, start := b.startRequest("DeleteObject(%q)", req.Name)
   223:         defer b.finishRequest(id, desc, start, &err)
   224:
   225:         err = b.wrapped.DeleteObject(ctx, req)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.findDirInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:335 (PC: 0x19443e8)
Values returned:
        ~r0: ("*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing")(0xc0007fc180)
*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing {
                Objects: []*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object len: 1, cap: 1, [
                        *(*"github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object")(0xc0005c17c0),
                ],
                CollapsedRuns: []string len: 0, cap: 0, nil,
                ContinuationToken: "Cgd3YWxrZWQv",}
        ~r1: error nil

   315:         }
   316:
   317:         return &Core{
   318:                 Bucket:    bucket,
   319:                 FullName:  name,
   320:                 MinObject: m,
   321:         }, nil
   322: }
   323:
   324: // findDirInode finds the dir inode core where the directory is either explicit
   325: // or implicit. Returns nil if no such directory exists.
   326: func findDirInode(ctx context.Context, bucket *gcsx.SyncerBucket, name Name) (*Core, error) {
   327:         if !name.IsDir() {
   328:                 return nil, fmt.Errorf("%q is not directory", name)
   329:         }
   330:
   331:         req := &gcs.ListObjectsRequest{
   332:                 Prefix:     name.GcsObjectName(),
   333:                 MaxResults: 1,
   334:         }
=> 335:         listing, err := bucket.ListObjects(ctx, req)
   336:         if err != nil {
   337:                 return nil, fmt.Errorf("list objects: %w", err)
   338:         }
   339:
   340:         if len(listing.Objects) == 0 {
   341:                 return nil, nil
   342:         }
   343:
   344:         result := &Core{
   345:                 Bucket:   bucket,
   346:                 FullName: name,
   347:         }
   348:         if o := listing.Objects[0]; o.Name == name.GcsObjectName() {
   349:                 result.MinObject = storageutil.ConvertObjToMinObject(o)
   350:         }
   351:         return result, nil
   352: }
   353:
   354: // Fail if the name already exists. Pass on errors directly.
   355: func (d *dirInode) createNewObject(
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).LookUpChild.func3() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:454 (PC: 0x1945acc)
Values returned:
        ~r0: ("*github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Core")(0xc000777240)
*github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Core {
                FullName: github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Name {bucketName: "", objectName: "walked/"},
                Bucket: *github.com/googlecloudplatform/gcsfuse/v2/internal/gcsx.SyncerBucket {
                        Bucket: (unreadable invalid interface type),
                        Syncer: (unreadable invalid interface type),},
                MinObject: *github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.MinObject {
                        Name: "walked/",
                        Size: 0,
                        Generation: 1715194144661809,
                        MetaGeneration: 1,
                        Updated: (*time.Time)(0xc0006209e8),
                        Metadata: map[string]string nil,
                        ContentEncoding: "",},
                Local: false,}
        ~r1: error nil

   434: const ConflictingFileNameSuffix = "\n"
   435:
   436: // LOCKS_REQUIRED(d)
   437: func (d *dirInode) LookUpChild(ctx context.Context, name string) (*Core, error) {
   438:         // Is this a conflict marker name?
   439:         if strings.HasSuffix(name, ConflictingFileNameSuffix) {
   440:                 return d.lookUpConflicting(ctx, name)
   441:         }
   442:
   443:         var fileResult *Core
   444:         var dirResult *Core
   445:         lookUpFile := func(ctx context.Context) (err error) {
   446:                 fileResult, err = findExplicitInode(ctx, d.Bucket(), NewFileName(d.Name(), name))
   447:                 return
   448:         }
   449:         lookUpExplicitDir := func(ctx context.Context) (err error) {
   450:                 dirResult, err = findExplicitInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   451:                 return
   452:         }
   453:         lookUpImplicitOrExplicitDir := func(ctx context.Context) (err error) {
=> 454:                 dirResult, err = findDirInode(ctx, d.Bucket(), NewDirName(d.Name(), name))
   455:                 return
   456:         }
   457:
   458:         b := syncutil.NewBundle(ctx)
   459:
   460:         cachedType := d.cache.Get(d.cacheClock.Now(), name)
   461:         switch cachedType {
   462:         case metadata.ImplicitDirType:
   463:                 dirResult = &Core{
   464:                         Bucket:    d.Bucket(),
   465:                         FullName:  NewDirName(d.Name(), name),
   466:                         MinObject: nil,
   467:                 }
   468:         case metadata.ExplicitDirType:
   469:                 b.Add(lookUpExplicitDir)
   470:         case metadata.RegularFileType, metadata.SymlinkType:
   471:                 b.Add(lookUpFile)
   472:         case metadata.NonexistentType:
   473:                 return nil, nil
   474:         case metadata.UnknownType:
(dlv) 
> github.com/jacobsa/syncutil.(*Bundle).Add.func1() /usr/local/google/home/gargnitin/go/pkg/mod/github.com/jacobsa/syncutil@v0.0.0-20180201203307-228ac8e5a6c3/bundle.go:89 (PC: 0xf5ea91)
Values returned:
        err: error nil

    69: type Bundle struct {
    70:         context context.Context
    71:         cancel  context.CancelFunc
    72:
    73:         waitGroup sync.WaitGroup
    74:
    75:         errorOnce  sync.Once
    76:         firstError error
    77: }
    78:
    79: // Add a new operation to the bundle. The operation will be invoked with a
    80: // context that will be cancelled if any other operation fails or has already
    81: // failed.
    82: func (b *Bundle) Add(f func(context.Context) error) {
    83:         b.waitGroup.Add(1)
    84:
    85:         // Run the function in the background.
    86:         go func() {
    87:                 defer b.waitGroup.Done()
    88:
=>  89:                 err := f(b.context)
    90:                 if err == nil {
    91:                         return
    92:                 }
    93:
    94:                 // On first error, cancel the context and save the error.
    95:                 b.errorOnce.Do(func() {
    96:                         b.firstError = err
    97:                         b.cancel()
    98:                 })
    99:         }()
   100: }
   101:
   102: // Wait for all previously-added operations to complete. Return nil if all
   103: // operations succeeded. Otherwise return the first error.
   104: //
   105: // Add must not be called concurrently with or after Join.
   106: func (b *Bundle) Join() error {
   107:         b.waitGroup.Wait()
   108:
   109:         // context.WithCancel requires that we arrange for this to be called
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1335 (hits goroutine(341):1 total:2) (PC: 0x1968d05)
> runtime.goexit() /usr/lib/google-golang/src/runtime/asm_amd64.s:1696 (PC: 0x481d01)
Warning: debugging optimized function
Values returned:

  1676:
  1677: TEXT runtime·return0(SB), NOSPLIT, $0
  1678:         MOVL    $0, AX
  1679:         RET
  1680:
  1681:
  1682: // Called from cgo wrappers, this function returns g->m->curg.stack.hi.
  1683: // Must obey the gcc calling convention.
  1684: TEXT _cgo_topofstack(SB),NOSPLIT,$0
  1685:         get_tls(CX)
  1686:         MOVQ    g(CX), AX
  1687:         MOVQ    g_m(AX), AX
  1688:         MOVQ    m_curg(AX), AX
  1689:         MOVQ    (g_stack+stack_hi)(AX), AX
  1690:         RET
  1691:
  1692: // The top-most function running on a goroutine
  1693: // returns to goexit+PCQuantum.
  1694: TEXT runtime·goexit(SB),NOSPLIT|TOPFRAME|NOFRAME,$0-0
  1695:         BYTE    $0x90   // NOP
=>1696:         CALL    runtime·goexit1(SB)     // does not return
  1697:         // traceback from goexit1 must hit code range of goexit
  1698:         BYTE    $0x90   // NOP
  1699:
  1700: // This is called from .init_array and follows the platform, not Go, ABI.
  1701: TEXT runtime·addmoduledata(SB),NOSPLIT,$0-0
  1702:         PUSHQ   R15 // The access to global variables below implicitly uses R15, which is callee-save
  1703:         MOVQ    runtime·lastmoduledatap(SB), AX
  1704:         MOVQ    DI, moduledata_next(AX)
  1705:         MOVQ    DI, runtime·lastmoduledatap(SB)
  1706:         POPQ    R15
  1707:         RET
  1708:
  1709: // Initialize special registers then jump to sigpanic.
  1710: // This function is injected from the signal handler for panicking
  1711: // signals. It is quite painful to set X15 in the signal context,
  1712: // so we do it here.
  1713: TEXT ·sigpanic0(SB),NOSPLIT,$0-0
  1714:         get_tls(R14)
  1715:         MOVQ    g(R14), R14
  1716: #ifndef GOOS_plan9
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2126 (hits goroutine(132):1 total:1) (PC: 0x1972473)
  2106:         // Delete the backing object.
  2107:         err = parent.DeleteChildFile(
  2108:                 ctx,
  2109:                 op.Name,
  2110:                 0,   // Latest generation
  2111:                 nil) // No meta-generation precondition
  2112:
  2113:         if err != nil {
  2114:                 err = fmt.Errorf("DeleteChildFile: %w", err)
  2115:                 return err
  2116:         }
  2117:
  2118:         if err := fs.invalidateChildFileCacheIfExist(parent, fileName.GcsObjectName()); err != nil {
  2119:                 return fmt.Errorf("Unlink: while invalidating cache for delete file: %w", err)
  2120:         }
  2121:
  2122:         return
  2123: }
  2124:
  2125: // LOCKS_EXCLUDED(fs.mu)
=>2126: func (fs *fileSystem) OpenDir(
  2127:         ctx context.Context,
  2128:         op *fuseops.OpenDirOp) (err error) {
  2129:         fs.mu.Lock()
  2130:         defer fs.mu.Unlock()
  2131:
  2132:         // Make sure the inode still exists and is a directory. If not, something has
  2133:         // screwed up because the VFS layer shouldn't have let us forget the inode
  2134:         // before opening it.
  2135:         in := fs.dirInodeOrDie(op.Inode)
  2136:
  2137:         // Allocate a handle.
  2138:         handleID := fs.nextHandleID
  2139:         fs.nextHandleID++
  2140:
  2141:         fs.handles[handleID] = handle.NewDirHandle(in, fs.implicitDirs)
  2142:         op.Handle = handleID
  2143:
  2144:         return
  2145: }
  2146:
(dlv) p op
("*github.com/jacobsa/fuse/fuseops.OpenDirOp")(0xc000056140)
*github.com/jacobsa/fuse/fuseops.OpenDirOp {
        Inode: 2,
        Handle: 0,
        OpContext: github.com/jacobsa/fuse/fuseops.OpContext {FuseID: 396, Pid: 1576076, Uid: 1012083},}
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2129 (PC: 0x19724a0)
  2109:                 op.Name,
  2110:                 0,   // Latest generation
  2111:                 nil) // No meta-generation precondition
  2112:
  2113:         if err != nil {
  2114:                 err = fmt.Errorf("DeleteChildFile: %w", err)
  2115:                 return err
  2116:         }
  2117:
  2118:         if err := fs.invalidateChildFileCacheIfExist(parent, fileName.GcsObjectName()); err != nil {
  2119:                 return fmt.Errorf("Unlink: while invalidating cache for delete file: %w", err)
  2120:         }
  2121:
  2122:         return
  2123: }
  2124:
  2125: // LOCKS_EXCLUDED(fs.mu)
  2126: func (fs *fileSystem) OpenDir(
  2127:         ctx context.Context,
  2128:         op *fuseops.OpenDirOp) (err error) {
=>2129:         fs.mu.Lock()
  2130:         defer fs.mu.Unlock()
  2131:
  2132:         // Make sure the inode still exists and is a directory. If not, something has
  2133:         // screwed up because the VFS layer shouldn't have let us forget the inode
  2134:         // before opening it.
  2135:         in := fs.dirInodeOrDie(op.Inode)
  2136:
  2137:         // Allocate a handle.
  2138:         handleID := fs.nextHandleID
  2139:         fs.nextHandleID++
  2140:
  2141:         fs.handles[handleID] = handle.NewDirHandle(in, fs.implicitDirs)
  2142:         op.Handle = handleID
  2143:
  2144:         return
  2145: }
  2146:
  2147: // LOCKS_EXCLUDED(fs.mu)
  2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2130 (PC: 0x19724bd)
  2110:                 0,   // Latest generation
  2111:                 nil) // No meta-generation precondition
  2112:
  2113:         if err != nil {
  2114:                 err = fmt.Errorf("DeleteChildFile: %w", err)
  2115:                 return err
  2116:         }
  2117:
  2118:         if err := fs.invalidateChildFileCacheIfExist(parent, fileName.GcsObjectName()); err != nil {
  2119:                 return fmt.Errorf("Unlink: while invalidating cache for delete file: %w", err)
  2120:         }
  2121:
  2122:         return
  2123: }
  2124:
  2125: // LOCKS_EXCLUDED(fs.mu)
  2126: func (fs *fileSystem) OpenDir(
  2127:         ctx context.Context,
  2128:         op *fuseops.OpenDirOp) (err error) {
  2129:         fs.mu.Lock()
=>2130:         defer fs.mu.Unlock()
  2131:
  2132:         // Make sure the inode still exists and is a directory. If not, something has
  2133:         // screwed up because the VFS layer shouldn't have let us forget the inode
  2134:         // before opening it.
  2135:         in := fs.dirInodeOrDie(op.Inode)
  2136:
  2137:         // Allocate a handle.
  2138:         handleID := fs.nextHandleID
  2139:         fs.nextHandleID++
  2140:
  2141:         fs.handles[handleID] = handle.NewDirHandle(in, fs.implicitDirs)
  2142:         op.Handle = handleID
  2143:
  2144:         return
  2145: }
  2146:
  2147: // LOCKS_EXCLUDED(fs.mu)
  2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
  2150:         op *fuseops.ReadDirOp) (err error) {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2135 (PC: 0x197256a)
  2115:                 return err
  2116:         }
  2117:
  2118:         if err := fs.invalidateChildFileCacheIfExist(parent, fileName.GcsObjectName()); err != nil {
  2119:                 return fmt.Errorf("Unlink: while invalidating cache for delete file: %w", err)
  2120:         }
  2121:
  2122:         return
  2123: }
  2124:
  2125: // LOCKS_EXCLUDED(fs.mu)
  2126: func (fs *fileSystem) OpenDir(
  2127:         ctx context.Context,
  2128:         op *fuseops.OpenDirOp) (err error) {
  2129:         fs.mu.Lock()
  2130:         defer fs.mu.Unlock()
  2131:
  2132:         // Make sure the inode still exists and is a directory. If not, something has
  2133:         // screwed up because the VFS layer shouldn't have let us forget the inode
  2134:         // before opening it.
=>2135:         in := fs.dirInodeOrDie(op.Inode)
  2136:
  2137:         // Allocate a handle.
  2138:         handleID := fs.nextHandleID
  2139:         fs.nextHandleID++
  2140:
  2141:         fs.handles[handleID] = handle.NewDirHandle(in, fs.implicitDirs)
  2142:         op.Handle = handleID
  2143:
  2144:         return
  2145: }
  2146:
  2147: // LOCKS_EXCLUDED(fs.mu)
  2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
  2150:         op *fuseops.ReadDirOp) (err error) {
  2151:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  2152:                 // When ignore interrupts config is set, we are creating a new context not
  2153:                 // cancellable by parent context.
  2154:                 var cancel context.CancelFunc
  2155:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2138 (PC: 0x1972593)
  2118:         if err := fs.invalidateChildFileCacheIfExist(parent, fileName.GcsObjectName()); err != nil {
  2119:                 return fmt.Errorf("Unlink: while invalidating cache for delete file: %w", err)
  2120:         }
  2121:
  2122:         return
  2123: }
  2124:
  2125: // LOCKS_EXCLUDED(fs.mu)
  2126: func (fs *fileSystem) OpenDir(
  2127:         ctx context.Context,
  2128:         op *fuseops.OpenDirOp) (err error) {
  2129:         fs.mu.Lock()
  2130:         defer fs.mu.Unlock()
  2131:
  2132:         // Make sure the inode still exists and is a directory. If not, something has
  2133:         // screwed up because the VFS layer shouldn't have let us forget the inode
  2134:         // before opening it.
  2135:         in := fs.dirInodeOrDie(op.Inode)
  2136:
  2137:         // Allocate a handle.
=>2138:         handleID := fs.nextHandleID
  2139:         fs.nextHandleID++
  2140:
  2141:         fs.handles[handleID] = handle.NewDirHandle(in, fs.implicitDirs)
  2142:         op.Handle = handleID
  2143:
  2144:         return
  2145: }
  2146:
  2147: // LOCKS_EXCLUDED(fs.mu)
  2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
  2150:         op *fuseops.ReadDirOp) (err error) {
  2151:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  2152:                 // When ignore interrupts config is set, we are creating a new context not
  2153:                 // cancellable by parent context.
  2154:                 var cancel context.CancelFunc
  2155:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  2156:                 defer cancel()
  2157:         }
  2158:         // Find the handle.
(dlv) p in
(unreadable invalid interface type)
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2139 (PC: 0x19725a9)
  2119:                 return fmt.Errorf("Unlink: while invalidating cache for delete file: %w", err)
  2120:         }
  2121:
  2122:         return
  2123: }
  2124:
  2125: // LOCKS_EXCLUDED(fs.mu)
  2126: func (fs *fileSystem) OpenDir(
  2127:         ctx context.Context,
  2128:         op *fuseops.OpenDirOp) (err error) {
  2129:         fs.mu.Lock()
  2130:         defer fs.mu.Unlock()
  2131:
  2132:         // Make sure the inode still exists and is a directory. If not, something has
  2133:         // screwed up because the VFS layer shouldn't have let us forget the inode
  2134:         // before opening it.
  2135:         in := fs.dirInodeOrDie(op.Inode)
  2136:
  2137:         // Allocate a handle.
  2138:         handleID := fs.nextHandleID
=>2139:         fs.nextHandleID++
  2140:
  2141:         fs.handles[handleID] = handle.NewDirHandle(in, fs.implicitDirs)
  2142:         op.Handle = handleID
  2143:
  2144:         return
  2145: }
  2146:
  2147: // LOCKS_EXCLUDED(fs.mu)
  2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
  2150:         op *fuseops.ReadDirOp) (err error) {
  2151:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  2152:                 // When ignore interrupts config is set, we are creating a new context not
  2153:                 // cancellable by parent context.
  2154:                 var cancel context.CancelFunc
  2155:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  2156:                 defer cancel()
  2157:         }
  2158:         // Find the handle.
  2159:         fs.mu.Lock()
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2141 (PC: 0x19725ce)
  2121:
  2122:         return
  2123: }
  2124:
  2125: // LOCKS_EXCLUDED(fs.mu)
  2126: func (fs *fileSystem) OpenDir(
  2127:         ctx context.Context,
  2128:         op *fuseops.OpenDirOp) (err error) {
  2129:         fs.mu.Lock()
  2130:         defer fs.mu.Unlock()
  2131:
  2132:         // Make sure the inode still exists and is a directory. If not, something has
  2133:         // screwed up because the VFS layer shouldn't have let us forget the inode
  2134:         // before opening it.
  2135:         in := fs.dirInodeOrDie(op.Inode)
  2136:
  2137:         // Allocate a handle.
  2138:         handleID := fs.nextHandleID
  2139:         fs.nextHandleID++
  2140:
=>2141:         fs.handles[handleID] = handle.NewDirHandle(in, fs.implicitDirs)
  2142:         op.Handle = handleID
  2143:
  2144:         return
  2145: }
  2146:
  2147: // LOCKS_EXCLUDED(fs.mu)
  2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
  2150:         op *fuseops.ReadDirOp) (err error) {
  2151:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  2152:                 // When ignore interrupts config is set, we are creating a new context not
  2153:                 // cancellable by parent context.
  2154:                 var cancel context.CancelFunc
  2155:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  2156:                 defer cancel()
  2157:         }
  2158:         // Find the handle.
  2159:         fs.mu.Lock()
  2160:         dh := fs.handles[op.Handle].(*handle.DirHandle)
  2161:         in := fs.dirInodeOrDie(op.Inode)
(dlv) s
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.NewDirHandle() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:60 (PC: 0x1954033)
    40:         /////////////////////////
    41:
    42:         Mu locker.Locker
    43:
    44:         // All entries in the directory. Populated the first time we need one.
    45:         //
    46:         // INVARIANT: For each i, entries[i+1].Offset == entries[i].Offset + 1
    47:         //
    48:         // GUARDED_BY(Mu)
    49:         entries []fuseutil.Dirent
    50:
    51:         // Has entries yet been populated?
    52:         //
    53:         // INVARIANT: If !entriesValid, then len(entries) == 0
    54:         //
    55:         // GUARDED_BY(Mu)
    56:         entriesValid bool
    57: }
    58:
    59: // NewDirHandle creates a directory handle that obtains listings from the supplied inode.
=>  60: func NewDirHandle(
    61:         in inode.DirInode,
    62:         implicitDirs bool) (dh *DirHandle) {
    63:         // Set up the basic struct.
    64:         dh = &DirHandle{
    65:                 in:           in,
    66:                 implicitDirs: implicitDirs,
    67:         }
    68:
    69:         // Set up invariant checking.
    70:         dh.Mu = locker.New("DH."+in.Name().GcsObjectName(), dh.checkInvariants)
    71:
    72:         return
    73: }
    74:
    75: ////////////////////////////////////////////////////////////////////////
    76: // Helpers
    77: ////////////////////////////////////////////////////////////////////////
    78:
    79: // Directory entries, sorted by name.
    80: type sortedDirents []fuseutil.Dirent
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.NewDirHandle() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:64 (PC: 0x195405a)
    44:         // All entries in the directory. Populated the first time we need one.
    45:         //
    46:         // INVARIANT: For each i, entries[i+1].Offset == entries[i].Offset + 1
    47:         //
    48:         // GUARDED_BY(Mu)
    49:         entries []fuseutil.Dirent
    50:
    51:         // Has entries yet been populated?
    52:         //
    53:         // INVARIANT: If !entriesValid, then len(entries) == 0
    54:         //
    55:         // GUARDED_BY(Mu)
    56:         entriesValid bool
    57: }
    58:
    59: // NewDirHandle creates a directory handle that obtains listings from the supplied inode.
    60: func NewDirHandle(
    61:         in inode.DirInode,
    62:         implicitDirs bool) (dh *DirHandle) {
    63:         // Set up the basic struct.
=>  64:         dh = &DirHandle{
    65:                 in:           in,
    66:                 implicitDirs: implicitDirs,
    67:         }
    68:
    69:         // Set up invariant checking.
    70:         dh.Mu = locker.New("DH."+in.Name().GcsObjectName(), dh.checkInvariants)
    71:
    72:         return
    73: }
    74:
    75: ////////////////////////////////////////////////////////////////////////
    76: // Helpers
    77: ////////////////////////////////////////////////////////////////////////
    78:
    79: // Directory entries, sorted by name.
    80: type sortedDirents []fuseutil.Dirent
    81:
    82: func (p sortedDirents) Len() int           { return len(p) }
    83: func (p sortedDirents) Less(i, j int) bool { return p[i].Name < p[j].Name }
    84: func (p sortedDirents) Swap(i, j int)      { p[i], p[j] = p[j], p[i] }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.NewDirHandle() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:65 (PC: 0x19540b2)
    45:         //
    46:         // INVARIANT: For each i, entries[i+1].Offset == entries[i].Offset + 1
    47:         //
    48:         // GUARDED_BY(Mu)
    49:         entries []fuseutil.Dirent
    50:
    51:         // Has entries yet been populated?
    52:         //
    53:         // INVARIANT: If !entriesValid, then len(entries) == 0
    54:         //
    55:         // GUARDED_BY(Mu)
    56:         entriesValid bool
    57: }
    58:
    59: // NewDirHandle creates a directory handle that obtains listings from the supplied inode.
    60: func NewDirHandle(
    61:         in inode.DirInode,
    62:         implicitDirs bool) (dh *DirHandle) {
    63:         // Set up the basic struct.
    64:         dh = &DirHandle{
=>  65:                 in:           in,
    66:                 implicitDirs: implicitDirs,
    67:         }
    68:
    69:         // Set up invariant checking.
    70:         dh.Mu = locker.New("DH."+in.Name().GcsObjectName(), dh.checkInvariants)
    71:
    72:         return
    73: }
    74:
    75: ////////////////////////////////////////////////////////////////////////
    76: // Helpers
    77: ////////////////////////////////////////////////////////////////////////
    78:
    79: // Directory entries, sorted by name.
    80: type sortedDirents []fuseutil.Dirent
    81:
    82: func (p sortedDirents) Len() int           { return len(p) }
    83: func (p sortedDirents) Less(i, j int) bool { return p[i].Name < p[j].Name }
    84: func (p sortedDirents) Swap(i, j int)      { p[i], p[j] = p[j], p[i] }
    85:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.NewDirHandle() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:64 (PC: 0x19540e8)
    44:         // All entries in the directory. Populated the first time we need one.
    45:         //
    46:         // INVARIANT: For each i, entries[i+1].Offset == entries[i].Offset + 1
    47:         //
    48:         // GUARDED_BY(Mu)
    49:         entries []fuseutil.Dirent
    50:
    51:         // Has entries yet been populated?
    52:         //
    53:         // INVARIANT: If !entriesValid, then len(entries) == 0
    54:         //
    55:         // GUARDED_BY(Mu)
    56:         entriesValid bool
    57: }
    58:
    59: // NewDirHandle creates a directory handle that obtains listings from the supplied inode.
    60: func NewDirHandle(
    61:         in inode.DirInode,
    62:         implicitDirs bool) (dh *DirHandle) {
    63:         // Set up the basic struct.
=>  64:         dh = &DirHandle{
    65:                 in:           in,
    66:                 implicitDirs: implicitDirs,
    67:         }
    68:
    69:         // Set up invariant checking.
    70:         dh.Mu = locker.New("DH."+in.Name().GcsObjectName(), dh.checkInvariants)
    71:
    72:         return
    73: }
    74:
    75: ////////////////////////////////////////////////////////////////////////
    76: // Helpers
    77: ////////////////////////////////////////////////////////////////////////
    78:
    79: // Directory entries, sorted by name.
    80: type sortedDirents []fuseutil.Dirent
    81:
    82: func (p sortedDirents) Len() int           { return len(p) }
    83: func (p sortedDirents) Less(i, j int) bool { return p[i].Name < p[j].Name }
    84: func (p sortedDirents) Swap(i, j int)      { p[i], p[j] = p[j], p[i] }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.NewDirHandle() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:66 (PC: 0x19540ef)
    46:         // INVARIANT: For each i, entries[i+1].Offset == entries[i].Offset + 1
    47:         //
    48:         // GUARDED_BY(Mu)
    49:         entries []fuseutil.Dirent
    50:
    51:         // Has entries yet been populated?
    52:         //
    53:         // INVARIANT: If !entriesValid, then len(entries) == 0
    54:         //
    55:         // GUARDED_BY(Mu)
    56:         entriesValid bool
    57: }
    58:
    59: // NewDirHandle creates a directory handle that obtains listings from the supplied inode.
    60: func NewDirHandle(
    61:         in inode.DirInode,
    62:         implicitDirs bool) (dh *DirHandle) {
    63:         // Set up the basic struct.
    64:         dh = &DirHandle{
    65:                 in:           in,
=>  66:                 implicitDirs: implicitDirs,
    67:         }
    68:
    69:         // Set up invariant checking.
    70:         dh.Mu = locker.New("DH."+in.Name().GcsObjectName(), dh.checkInvariants)
    71:
    72:         return
    73: }
    74:
    75: ////////////////////////////////////////////////////////////////////////
    76: // Helpers
    77: ////////////////////////////////////////////////////////////////////////
    78:
    79: // Directory entries, sorted by name.
    80: type sortedDirents []fuseutil.Dirent
    81:
    82: func (p sortedDirents) Len() int           { return len(p) }
    83: func (p sortedDirents) Less(i, j int) bool { return p[i].Name < p[j].Name }
    84: func (p sortedDirents) Swap(i, j int)      { p[i], p[j] = p[j], p[i] }
    85:
    86: func (dh *DirHandle) checkInvariants() {
(dlv) frame 1
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.NewDirHandle() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:66 (PC: 0x19540ef)
Frame 1: /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2141 (PC: 19725ef)
  2121:
  2122:         return
  2123: }
  2124:
  2125: // LOCKS_EXCLUDED(fs.mu)
  2126: func (fs *fileSystem) OpenDir(
  2127:         ctx context.Context,
  2128:         op *fuseops.OpenDirOp) (err error) {
  2129:         fs.mu.Lock()
  2130:         defer fs.mu.Unlock()
  2131:
  2132:         // Make sure the inode still exists and is a directory. If not, something has
  2133:         // screwed up because the VFS layer shouldn't have let us forget the inode
  2134:         // before opening it.
  2135:         in := fs.dirInodeOrDie(op.Inode)
  2136:
  2137:         // Allocate a handle.
  2138:         handleID := fs.nextHandleID
  2139:         fs.nextHandleID++
  2140:
=>2141:         fs.handles[handleID] = handle.NewDirHandle(in, fs.implicitDirs)
  2142:         op.Handle = handleID
  2143:
  2144:         return
  2145: }
  2146:
  2147: // LOCKS_EXCLUDED(fs.mu)
  2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
  2150:         op *fuseops.ReadDirOp) (err error) {
  2151:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  2152:                 // When ignore interrupts config is set, we are creating a new context not
  2153:                 // cancellable by parent context.
  2154:                 var cancel context.CancelFunc
  2155:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  2156:                 defer cancel()
  2157:         }
  2158:         // Find the handle.
  2159:         fs.mu.Lock()
  2160:         dh := fs.handles[op.Handle].(*handle.DirHandle)
  2161:         in := fs.dirInodeOrDie(op.Inode)
(dlv) frame 0
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.NewDirHandle() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:66 (PC: 0x19540ef)
Frame 0: /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:66 (PC: 19540ef)
    46:         // INVARIANT: For each i, entries[i+1].Offset == entries[i].Offset + 1
    47:         //
    48:         // GUARDED_BY(Mu)
    49:         entries []fuseutil.Dirent
    50:
    51:         // Has entries yet been populated?
    52:         //
    53:         // INVARIANT: If !entriesValid, then len(entries) == 0
    54:         //
    55:         // GUARDED_BY(Mu)
    56:         entriesValid bool
    57: }
    58:
    59: // NewDirHandle creates a directory handle that obtains listings from the supplied inode.
    60: func NewDirHandle(
    61:         in inode.DirInode,
    62:         implicitDirs bool) (dh *DirHandle) {
    63:         // Set up the basic struct.
    64:         dh = &DirHandle{
    65:                 in:           in,
=>  66:                 implicitDirs: implicitDirs,
    67:         }
    68:
    69:         // Set up invariant checking.
    70:         dh.Mu = locker.New("DH."+in.Name().GcsObjectName(), dh.checkInvariants)
    71:
    72:         return
    73: }
    74:
    75: ////////////////////////////////////////////////////////////////////////
    76: // Helpers
    77: ////////////////////////////////////////////////////////////////////////
    78:
    79: // Directory entries, sorted by name.
    80: type sortedDirents []fuseutil.Dirent
    81:
    82: func (p sortedDirents) Len() int           { return len(p) }
    83: func (p sortedDirents) Less(i, j int) bool { return p[i].Name < p[j].Name }
    84: func (p sortedDirents) Swap(i, j int)      { p[i], p[j] = p[j], p[i] }
    85:
    86: func (dh *DirHandle) checkInvariants() {
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2141 (PC: 0x19725ef)
Values returned:
        dh: ("*github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.DirHandle")(0xc00114c0a0)
*github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.DirHandle {
                in: (unreadable invalid interface type),
                implicitDirs: true,
                Mu: (unreadable invalid interface type),
                entries: []github.com/jacobsa/fuse/fuseutil.Dirent len: 0, cap: 0, nil,
                entriesValid: false,}

  2121:
  2122:         return
  2123: }
  2124:
  2125: // LOCKS_EXCLUDED(fs.mu)
  2126: func (fs *fileSystem) OpenDir(
  2127:         ctx context.Context,
  2128:         op *fuseops.OpenDirOp) (err error) {
  2129:         fs.mu.Lock()
  2130:         defer fs.mu.Unlock()
  2131:
  2132:         // Make sure the inode still exists and is a directory. If not, something has
  2133:         // screwed up because the VFS layer shouldn't have let us forget the inode
  2134:         // before opening it.
  2135:         in := fs.dirInodeOrDie(op.Inode)
  2136:
  2137:         // Allocate a handle.
  2138:         handleID := fs.nextHandleID
  2139:         fs.nextHandleID++
  2140:
=>2141:         fs.handles[handleID] = handle.NewDirHandle(in, fs.implicitDirs)
  2142:         op.Handle = handleID
  2143:
  2144:         return
  2145: }
  2146:
  2147: // LOCKS_EXCLUDED(fs.mu)
  2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
  2150:         op *fuseops.ReadDirOp) (err error) {
  2151:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  2152:                 // When ignore interrupts config is set, we are creating a new context not
  2153:                 // cancellable by parent context.
  2154:                 var cancel context.CancelFunc
  2155:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  2156:                 defer cancel()
  2157:         }
  2158:         // Find the handle.
  2159:         fs.mu.Lock()
  2160:         dh := fs.handles[op.Handle].(*handle.DirHandle)
  2161:         in := fs.dirInodeOrDie(op.Inode)
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148 (hits goroutine(356):1 total:1) (PC: 0x1972776)
  2128:         op *fuseops.OpenDirOp) (err error) {
  2129:         fs.mu.Lock()
  2130:         defer fs.mu.Unlock()
  2131:
  2132:         // Make sure the inode still exists and is a directory. If not, something has
  2133:         // screwed up because the VFS layer shouldn't have let us forget the inode
  2134:         // before opening it.
  2135:         in := fs.dirInodeOrDie(op.Inode)
  2136:
  2137:         // Allocate a handle.
  2138:         handleID := fs.nextHandleID
  2139:         fs.nextHandleID++
  2140:
  2141:         fs.handles[handleID] = handle.NewDirHandle(in, fs.implicitDirs)
  2142:         op.Handle = handleID
  2143:
  2144:         return
  2145: }
  2146:
  2147: // LOCKS_EXCLUDED(fs.mu)
=>2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
  2150:         op *fuseops.ReadDirOp) (err error) {
  2151:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  2152:                 // When ignore interrupts config is set, we are creating a new context not
  2153:                 // cancellable by parent context.
  2154:                 var cancel context.CancelFunc
  2155:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  2156:                 defer cancel()
  2157:         }
  2158:         // Find the handle.
  2159:         fs.mu.Lock()
  2160:         dh := fs.handles[op.Handle].(*handle.DirHandle)
  2161:         in := fs.dirInodeOrDie(op.Inode)
  2162:         // Fetch local file entries beforehand and pass it to directory handle as
  2163:         // we need fs lock to fetch local file entries.
  2164:         localFileEntries := in.LocalFileEntries(fs.localFileInodes)
  2165:         fs.mu.Unlock()
  2166:
  2167:         dh.Mu.Lock()
  2168:         defer dh.Mu.Unlock()
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2151 (PC: 0x19727a6)
  2131:
  2132:         // Make sure the inode still exists and is a directory. If not, something has
  2133:         // screwed up because the VFS layer shouldn't have let us forget the inode
  2134:         // before opening it.
  2135:         in := fs.dirInodeOrDie(op.Inode)
  2136:
  2137:         // Allocate a handle.
  2138:         handleID := fs.nextHandleID
  2139:         fs.nextHandleID++
  2140:
  2141:         fs.handles[handleID] = handle.NewDirHandle(in, fs.implicitDirs)
  2142:         op.Handle = handleID
  2143:
  2144:         return
  2145: }
  2146:
  2147: // LOCKS_EXCLUDED(fs.mu)
  2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
  2150:         op *fuseops.ReadDirOp) (err error) {
=>2151:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  2152:                 // When ignore interrupts config is set, we are creating a new context not
  2153:                 // cancellable by parent context.
  2154:                 var cancel context.CancelFunc
  2155:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  2156:                 defer cancel()
  2157:         }
  2158:         // Find the handle.
  2159:         fs.mu.Lock()
  2160:         dh := fs.handles[op.Handle].(*handle.DirHandle)
  2161:         in := fs.dirInodeOrDie(op.Inode)
  2162:         // Fetch local file entries beforehand and pass it to directory handle as
  2163:         // we need fs lock to fetch local file entries.
  2164:         localFileEntries := in.LocalFileEntries(fs.localFileInodes)
  2165:         fs.mu.Unlock()
  2166:
  2167:         dh.Mu.Lock()
  2168:         defer dh.Mu.Unlock()
  2169:         // Serve the request.
  2170:         if err := dh.ReadDir(ctx, op, localFileEntries); err != nil {
  2171:                 return err
(dlv) p op
("*github.com/jacobsa/fuse/fuseops.ReadDirOp")(0xc00114c1e0)
*github.com/jacobsa/fuse/fuseops.ReadDirOp {
        Inode: 2,
        Handle: 26,
        Offset: 0,
        Dst: []uint8 len: 4096, cap: 4096, [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...+4032 more],
        BytesRead: 0,
        OpContext: github.com/jacobsa/fuse/fuseops.OpContext {FuseID: 400, Pid: 1576076, Uid: 1012083},}
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2159 (PC: 0x19728af)
  2139:         fs.nextHandleID++
  2140:
  2141:         fs.handles[handleID] = handle.NewDirHandle(in, fs.implicitDirs)
  2142:         op.Handle = handleID
  2143:
  2144:         return
  2145: }
  2146:
  2147: // LOCKS_EXCLUDED(fs.mu)
  2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
  2150:         op *fuseops.ReadDirOp) (err error) {
  2151:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  2152:                 // When ignore interrupts config is set, we are creating a new context not
  2153:                 // cancellable by parent context.
  2154:                 var cancel context.CancelFunc
  2155:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  2156:                 defer cancel()
  2157:         }
  2158:         // Find the handle.
=>2159:         fs.mu.Lock()
  2160:         dh := fs.handles[op.Handle].(*handle.DirHandle)
  2161:         in := fs.dirInodeOrDie(op.Inode)
  2162:         // Fetch local file entries beforehand and pass it to directory handle as
  2163:         // we need fs lock to fetch local file entries.
  2164:         localFileEntries := in.LocalFileEntries(fs.localFileInodes)
  2165:         fs.mu.Unlock()
  2166:
  2167:         dh.Mu.Lock()
  2168:         defer dh.Mu.Unlock()
  2169:         // Serve the request.
  2170:         if err := dh.ReadDir(ctx, op, localFileEntries); err != nil {
  2171:                 return err
  2172:         }
  2173:
  2174:         return
  2175: }
  2176:
  2177: // LOCKS_EXCLUDED(fs.mu)
  2178: func (fs *fileSystem) ReleaseDirHandle(
  2179:         ctx context.Context,
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2160 (PC: 0x19728cc)
  2140:
  2141:         fs.handles[handleID] = handle.NewDirHandle(in, fs.implicitDirs)
  2142:         op.Handle = handleID
  2143:
  2144:         return
  2145: }
  2146:
  2147: // LOCKS_EXCLUDED(fs.mu)
  2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
  2150:         op *fuseops.ReadDirOp) (err error) {
  2151:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  2152:                 // When ignore interrupts config is set, we are creating a new context not
  2153:                 // cancellable by parent context.
  2154:                 var cancel context.CancelFunc
  2155:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  2156:                 defer cancel()
  2157:         }
  2158:         // Find the handle.
  2159:         fs.mu.Lock()
=>2160:         dh := fs.handles[op.Handle].(*handle.DirHandle)
  2161:         in := fs.dirInodeOrDie(op.Inode)
  2162:         // Fetch local file entries beforehand and pass it to directory handle as
  2163:         // we need fs lock to fetch local file entries.
  2164:         localFileEntries := in.LocalFileEntries(fs.localFileInodes)
  2165:         fs.mu.Unlock()
  2166:
  2167:         dh.Mu.Lock()
  2168:         defer dh.Mu.Unlock()
  2169:         // Serve the request.
  2170:         if err := dh.ReadDir(ctx, op, localFileEntries); err != nil {
  2171:                 return err
  2172:         }
  2173:
  2174:         return
  2175: }
  2176:
  2177: // LOCKS_EXCLUDED(fs.mu)
  2178: func (fs *fileSystem) ReleaseDirHandle(
  2179:         ctx context.Context,
  2180:         op *fuseops.ReleaseDirHandleOp) (err error) {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2161 (PC: 0x1972927)
  2141:         fs.handles[handleID] = handle.NewDirHandle(in, fs.implicitDirs)
  2142:         op.Handle = handleID
  2143:
  2144:         return
  2145: }
  2146:
  2147: // LOCKS_EXCLUDED(fs.mu)
  2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
  2150:         op *fuseops.ReadDirOp) (err error) {
  2151:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  2152:                 // When ignore interrupts config is set, we are creating a new context not
  2153:                 // cancellable by parent context.
  2154:                 var cancel context.CancelFunc
  2155:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  2156:                 defer cancel()
  2157:         }
  2158:         // Find the handle.
  2159:         fs.mu.Lock()
  2160:         dh := fs.handles[op.Handle].(*handle.DirHandle)
=>2161:         in := fs.dirInodeOrDie(op.Inode)
  2162:         // Fetch local file entries beforehand and pass it to directory handle as
  2163:         // we need fs lock to fetch local file entries.
  2164:         localFileEntries := in.LocalFileEntries(fs.localFileInodes)
  2165:         fs.mu.Unlock()
  2166:
  2167:         dh.Mu.Lock()
  2168:         defer dh.Mu.Unlock()
  2169:         // Serve the request.
  2170:         if err := dh.ReadDir(ctx, op, localFileEntries); err != nil {
  2171:                 return err
  2172:         }
  2173:
  2174:         return
  2175: }
  2176:
  2177: // LOCKS_EXCLUDED(fs.mu)
  2178: func (fs *fileSystem) ReleaseDirHandle(
  2179:         ctx context.Context,
  2180:         op *fuseops.ReleaseDirHandleOp) (err error) {
  2181:         fs.mu.Lock()
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2164 (PC: 0x1972959)
  2144:         return
  2145: }
  2146:
  2147: // LOCKS_EXCLUDED(fs.mu)
  2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
  2150:         op *fuseops.ReadDirOp) (err error) {
  2151:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  2152:                 // When ignore interrupts config is set, we are creating a new context not
  2153:                 // cancellable by parent context.
  2154:                 var cancel context.CancelFunc
  2155:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  2156:                 defer cancel()
  2157:         }
  2158:         // Find the handle.
  2159:         fs.mu.Lock()
  2160:         dh := fs.handles[op.Handle].(*handle.DirHandle)
  2161:         in := fs.dirInodeOrDie(op.Inode)
  2162:         // Fetch local file entries beforehand and pass it to directory handle as
  2163:         // we need fs lock to fetch local file entries.
=>2164:         localFileEntries := in.LocalFileEntries(fs.localFileInodes)
  2165:         fs.mu.Unlock()
  2166:
  2167:         dh.Mu.Lock()
  2168:         defer dh.Mu.Unlock()
  2169:         // Serve the request.
  2170:         if err := dh.ReadDir(ctx, op, localFileEntries); err != nil {
  2171:                 return err
  2172:         }
  2173:
  2174:         return
  2175: }
  2176:
  2177: // LOCKS_EXCLUDED(fs.mu)
  2178: func (fs *fileSystem) ReleaseDirHandle(
  2179:         ctx context.Context,
  2180:         op *fuseops.ReleaseDirHandleOp) (err error) {
  2181:         fs.mu.Lock()
  2182:         defer fs.mu.Unlock()
  2183:
  2184:         // Sanity check that this handle exists and is of the correct type.
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2165 (PC: 0x19729a2)
  2145: }
  2146:
  2147: // LOCKS_EXCLUDED(fs.mu)
  2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
  2150:         op *fuseops.ReadDirOp) (err error) {
  2151:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  2152:                 // When ignore interrupts config is set, we are creating a new context not
  2153:                 // cancellable by parent context.
  2154:                 var cancel context.CancelFunc
  2155:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  2156:                 defer cancel()
  2157:         }
  2158:         // Find the handle.
  2159:         fs.mu.Lock()
  2160:         dh := fs.handles[op.Handle].(*handle.DirHandle)
  2161:         in := fs.dirInodeOrDie(op.Inode)
  2162:         // Fetch local file entries beforehand and pass it to directory handle as
  2163:         // we need fs lock to fetch local file entries.
  2164:         localFileEntries := in.LocalFileEntries(fs.localFileInodes)
=>2165:         fs.mu.Unlock()
  2166:
  2167:         dh.Mu.Lock()
  2168:         defer dh.Mu.Unlock()
  2169:         // Serve the request.
  2170:         if err := dh.ReadDir(ctx, op, localFileEntries); err != nil {
  2171:                 return err
  2172:         }
  2173:
  2174:         return
  2175: }
  2176:
  2177: // LOCKS_EXCLUDED(fs.mu)
  2178: func (fs *fileSystem) ReleaseDirHandle(
  2179:         ctx context.Context,
  2180:         op *fuseops.ReleaseDirHandleOp) (err error) {
  2181:         fs.mu.Lock()
  2182:         defer fs.mu.Unlock()
  2183:
  2184:         // Sanity check that this handle exists and is of the correct type.
  2185:         _ = fs.handles[op.Handle].(*handle.DirHandle)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2167 (PC: 0x19729bf)
  2147: // LOCKS_EXCLUDED(fs.mu)
  2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
  2150:         op *fuseops.ReadDirOp) (err error) {
  2151:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  2152:                 // When ignore interrupts config is set, we are creating a new context not
  2153:                 // cancellable by parent context.
  2154:                 var cancel context.CancelFunc
  2155:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  2156:                 defer cancel()
  2157:         }
  2158:         // Find the handle.
  2159:         fs.mu.Lock()
  2160:         dh := fs.handles[op.Handle].(*handle.DirHandle)
  2161:         in := fs.dirInodeOrDie(op.Inode)
  2162:         // Fetch local file entries beforehand and pass it to directory handle as
  2163:         // we need fs lock to fetch local file entries.
  2164:         localFileEntries := in.LocalFileEntries(fs.localFileInodes)
  2165:         fs.mu.Unlock()
  2166:
=>2167:         dh.Mu.Lock()
  2168:         defer dh.Mu.Unlock()
  2169:         // Serve the request.
  2170:         if err := dh.ReadDir(ctx, op, localFileEntries); err != nil {
  2171:                 return err
  2172:         }
  2173:
  2174:         return
  2175: }
  2176:
  2177: // LOCKS_EXCLUDED(fs.mu)
  2178: func (fs *fileSystem) ReleaseDirHandle(
  2179:         ctx context.Context,
  2180:         op *fuseops.ReleaseDirHandleOp) (err error) {
  2181:         fs.mu.Lock()
  2182:         defer fs.mu.Unlock()
  2183:
  2184:         // Sanity check that this handle exists and is of the correct type.
  2185:         _ = fs.handles[op.Handle].(*handle.DirHandle)
  2186:
  2187:         // Clear the entry from the map.
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2168 (PC: 0x19729d9)
  2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
  2150:         op *fuseops.ReadDirOp) (err error) {
  2151:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  2152:                 // When ignore interrupts config is set, we are creating a new context not
  2153:                 // cancellable by parent context.
  2154:                 var cancel context.CancelFunc
  2155:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  2156:                 defer cancel()
  2157:         }
  2158:         // Find the handle.
  2159:         fs.mu.Lock()
  2160:         dh := fs.handles[op.Handle].(*handle.DirHandle)
  2161:         in := fs.dirInodeOrDie(op.Inode)
  2162:         // Fetch local file entries beforehand and pass it to directory handle as
  2163:         // we need fs lock to fetch local file entries.
  2164:         localFileEntries := in.LocalFileEntries(fs.localFileInodes)
  2165:         fs.mu.Unlock()
  2166:
  2167:         dh.Mu.Lock()
=>2168:         defer dh.Mu.Unlock()
  2169:         // Serve the request.
  2170:         if err := dh.ReadDir(ctx, op, localFileEntries); err != nil {
  2171:                 return err
  2172:         }
  2173:
  2174:         return
  2175: }
  2176:
  2177: // LOCKS_EXCLUDED(fs.mu)
  2178: func (fs *fileSystem) ReleaseDirHandle(
  2179:         ctx context.Context,
  2180:         op *fuseops.ReleaseDirHandleOp) (err error) {
  2181:         fs.mu.Lock()
  2182:         defer fs.mu.Unlock()
  2183:
  2184:         // Sanity check that this handle exists and is of the correct type.
  2185:         _ = fs.handles[op.Handle].(*handle.DirHandle)
  2186:
  2187:         // Clear the entry from the map.
  2188:         delete(fs.handles, op.Handle)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2170 (PC: 0x1972a82)
  2150:         op *fuseops.ReadDirOp) (err error) {
  2151:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  2152:                 // When ignore interrupts config is set, we are creating a new context not
  2153:                 // cancellable by parent context.
  2154:                 var cancel context.CancelFunc
  2155:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  2156:                 defer cancel()
  2157:         }
  2158:         // Find the handle.
  2159:         fs.mu.Lock()
  2160:         dh := fs.handles[op.Handle].(*handle.DirHandle)
  2161:         in := fs.dirInodeOrDie(op.Inode)
  2162:         // Fetch local file entries beforehand and pass it to directory handle as
  2163:         // we need fs lock to fetch local file entries.
  2164:         localFileEntries := in.LocalFileEntries(fs.localFileInodes)
  2165:         fs.mu.Unlock()
  2166:
  2167:         dh.Mu.Lock()
  2168:         defer dh.Mu.Unlock()
  2169:         // Serve the request.
=>2170:         if err := dh.ReadDir(ctx, op, localFileEntries); err != nil {
  2171:                 return err
  2172:         }
  2173:
  2174:         return
  2175: }
  2176:
  2177: // LOCKS_EXCLUDED(fs.mu)
  2178: func (fs *fileSystem) ReleaseDirHandle(
  2179:         ctx context.Context,
  2180:         op *fuseops.ReleaseDirHandleOp) (err error) {
  2181:         fs.mu.Lock()
  2182:         defer fs.mu.Unlock()
  2183:
  2184:         // Sanity check that this handle exists and is of the correct type.
  2185:         _ = fs.handles[op.Handle].(*handle.DirHandle)
  2186:
  2187:         // Clear the entry from the map.
  2188:         delete(fs.handles, op.Handle)
  2189:
  2190:         return
(dlv) s
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:270 (PC: 0x1955a73)
   250:
   251:         // Update state.
   252:         dh.entries = entries
   253:         dh.entriesValid = true
   254:
   255:         return
   256: }
   257:
   258: ////////////////////////////////////////////////////////////////////////
   259: // Public interface
   260: ////////////////////////////////////////////////////////////////////////
   261:
   262: // ReadDir handles a request to read from the directory, without responding.
   263: //
   264: // Special case: we assume that a zero offset indicates that rewinddir has been
   265: // called (since fuse gives us no way to intercept and know for sure), and
   266: // start the listing process over again.
   267: //
   268: // LOCKS_REQUIRED(dh.Mu)
   269: // LOCKS_EXCLUDED(du.in)
=> 270: func (dh *DirHandle) ReadDir(
   271:         ctx context.Context,
   272:         op *fuseops.ReadDirOp,
   273:         localFileEntries []fuseutil.Dirent) (err error) {
   274:         // If the request is for offset zero, we assume that either this is the first
   275:         // call or rewinddir has been called. Reset state.
   276:         if op.Offset == 0 {
   277:                 dh.entries = nil
   278:                 dh.entriesValid = false
   279:         }
   280:
   281:         // Do we need to read entries from GCS?
   282:         if !dh.entriesValid {
   283:                 err = dh.ensureEntries(ctx, localFileEntries)
   284:                 if err != nil {
   285:                         return
   286:                 }
   287:         }
   288:
   289:         // Is the offset past the end of what we have buffered? If so, this must be
   290:         // an invalid seekdir according to posix.
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:276 (PC: 0x1955ab8)
   256: }
   257:
   258: ////////////////////////////////////////////////////////////////////////
   259: // Public interface
   260: ////////////////////////////////////////////////////////////////////////
   261:
   262: // ReadDir handles a request to read from the directory, without responding.
   263: //
   264: // Special case: we assume that a zero offset indicates that rewinddir has been
   265: // called (since fuse gives us no way to intercept and know for sure), and
   266: // start the listing process over again.
   267: //
   268: // LOCKS_REQUIRED(dh.Mu)
   269: // LOCKS_EXCLUDED(du.in)
   270: func (dh *DirHandle) ReadDir(
   271:         ctx context.Context,
   272:         op *fuseops.ReadDirOp,
   273:         localFileEntries []fuseutil.Dirent) (err error) {
   274:         // If the request is for offset zero, we assume that either this is the first
   275:         // call or rewinddir has been called. Reset state.
=> 276:         if op.Offset == 0 {
   277:                 dh.entries = nil
   278:                 dh.entriesValid = false
   279:         }
   280:
   281:         // Do we need to read entries from GCS?
   282:         if !dh.entriesValid {
   283:                 err = dh.ensureEntries(ctx, localFileEntries)
   284:                 if err != nil {
   285:                         return
   286:                 }
   287:         }
   288:
   289:         // Is the offset past the end of what we have buffered? If so, this must be
   290:         // an invalid seekdir according to posix.
   291:         index := int(op.Offset)
   292:         if index > len(dh.entries) {
   293:                 err = fuse.EINVAL
   294:                 return
   295:         }
   296:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:277 (PC: 0x1955acb)
   257:
   258: ////////////////////////////////////////////////////////////////////////
   259: // Public interface
   260: ////////////////////////////////////////////////////////////////////////
   261:
   262: // ReadDir handles a request to read from the directory, without responding.
   263: //
   264: // Special case: we assume that a zero offset indicates that rewinddir has been
   265: // called (since fuse gives us no way to intercept and know for sure), and
   266: // start the listing process over again.
   267: //
   268: // LOCKS_REQUIRED(dh.Mu)
   269: // LOCKS_EXCLUDED(du.in)
   270: func (dh *DirHandle) ReadDir(
   271:         ctx context.Context,
   272:         op *fuseops.ReadDirOp,
   273:         localFileEntries []fuseutil.Dirent) (err error) {
   274:         // If the request is for offset zero, we assume that either this is the first
   275:         // call or rewinddir has been called. Reset state.
   276:         if op.Offset == 0 {
=> 277:                 dh.entries = nil
   278:                 dh.entriesValid = false
   279:         }
   280:
   281:         // Do we need to read entries from GCS?
   282:         if !dh.entriesValid {
   283:                 err = dh.ensureEntries(ctx, localFileEntries)
   284:                 if err != nil {
   285:                         return
   286:                 }
   287:         }
   288:
   289:         // Is the offset past the end of what we have buffered? If so, this must be
   290:         // an invalid seekdir according to posix.
   291:         index := int(op.Offset)
   292:         if index > len(dh.entries) {
   293:                 err = fuse.EINVAL
   294:                 return
   295:         }
   296:
   297:         // We copy out entries until we run out of entries or space.
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:278 (PC: 0x1955b00)
   258: ////////////////////////////////////////////////////////////////////////
   259: // Public interface
   260: ////////////////////////////////////////////////////////////////////////
   261:
   262: // ReadDir handles a request to read from the directory, without responding.
   263: //
   264: // Special case: we assume that a zero offset indicates that rewinddir has been
   265: // called (since fuse gives us no way to intercept and know for sure), and
   266: // start the listing process over again.
   267: //
   268: // LOCKS_REQUIRED(dh.Mu)
   269: // LOCKS_EXCLUDED(du.in)
   270: func (dh *DirHandle) ReadDir(
   271:         ctx context.Context,
   272:         op *fuseops.ReadDirOp,
   273:         localFileEntries []fuseutil.Dirent) (err error) {
   274:         // If the request is for offset zero, we assume that either this is the first
   275:         // call or rewinddir has been called. Reset state.
   276:         if op.Offset == 0 {
   277:                 dh.entries = nil
=> 278:                 dh.entriesValid = false
   279:         }
   280:
   281:         // Do we need to read entries from GCS?
   282:         if !dh.entriesValid {
   283:                 err = dh.ensureEntries(ctx, localFileEntries)
   284:                 if err != nil {
   285:                         return
   286:                 }
   287:         }
   288:
   289:         // Is the offset past the end of what we have buffered? If so, this must be
   290:         // an invalid seekdir according to posix.
   291:         index := int(op.Offset)
   292:         if index > len(dh.entries) {
   293:                 err = fuse.EINVAL
   294:                 return
   295:         }
   296:
   297:         // We copy out entries until we run out of entries or space.
   298:         for i := index; i < len(dh.entries); i++ {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:282 (PC: 0x1955b12)
   262: // ReadDir handles a request to read from the directory, without responding.
   263: //
   264: // Special case: we assume that a zero offset indicates that rewinddir has been
   265: // called (since fuse gives us no way to intercept and know for sure), and
   266: // start the listing process over again.
   267: //
   268: // LOCKS_REQUIRED(dh.Mu)
   269: // LOCKS_EXCLUDED(du.in)
   270: func (dh *DirHandle) ReadDir(
   271:         ctx context.Context,
   272:         op *fuseops.ReadDirOp,
   273:         localFileEntries []fuseutil.Dirent) (err error) {
   274:         // If the request is for offset zero, we assume that either this is the first
   275:         // call or rewinddir has been called. Reset state.
   276:         if op.Offset == 0 {
   277:                 dh.entries = nil
   278:                 dh.entriesValid = false
   279:         }
   280:
   281:         // Do we need to read entries from GCS?
=> 282:         if !dh.entriesValid {
   283:                 err = dh.ensureEntries(ctx, localFileEntries)
   284:                 if err != nil {
   285:                         return
   286:                 }
   287:         }
   288:
   289:         // Is the offset past the end of what we have buffered? If so, this must be
   290:         // an invalid seekdir according to posix.
   291:         index := int(op.Offset)
   292:         if index > len(dh.entries) {
   293:                 err = fuse.EINVAL
   294:                 return
   295:         }
   296:
   297:         // We copy out entries until we run out of entries or space.
   298:         for i := index; i < len(dh.entries); i++ {
   299:                 n := fuseutil.WriteDirent(op.Dst[op.BytesRead:], dh.entries[i])
   300:                 if n == 0 {
   301:                         break
   302:                 }
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:283 (PC: 0x1955b26)
   263: //
   264: // Special case: we assume that a zero offset indicates that rewinddir has been
   265: // called (since fuse gives us no way to intercept and know for sure), and
   266: // start the listing process over again.
   267: //
   268: // LOCKS_REQUIRED(dh.Mu)
   269: // LOCKS_EXCLUDED(du.in)
   270: func (dh *DirHandle) ReadDir(
   271:         ctx context.Context,
   272:         op *fuseops.ReadDirOp,
   273:         localFileEntries []fuseutil.Dirent) (err error) {
   274:         // If the request is for offset zero, we assume that either this is the first
   275:         // call or rewinddir has been called. Reset state.
   276:         if op.Offset == 0 {
   277:                 dh.entries = nil
   278:                 dh.entriesValid = false
   279:         }
   280:
   281:         // Do we need to read entries from GCS?
   282:         if !dh.entriesValid {
=> 283:                 err = dh.ensureEntries(ctx, localFileEntries)
   284:                 if err != nil {
   285:                         return
   286:                 }
   287:         }
   288:
   289:         // Is the offset past the end of what we have buffered? If so, this must be
   290:         // an invalid seekdir according to posix.
   291:         index := int(op.Offset)
   292:         if index > len(dh.entries) {
   293:                 err = fuse.EINVAL
   294:                 return
   295:         }
   296:
   297:         // We copy out entries until we run out of entries or space.
   298:         for i := index; i < len(dh.entries); i++ {
   299:                 n := fuseutil.WriteDirent(op.Dst[op.BytesRead:], dh.entries[i])
   300:                 if n == 0 {
   301:                         break
   302:                 }
   303:
(dlv) s
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ensureEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:239 (PC: 0x19555d6)
   219:         // NOTE: As far as I can tell this is harmless. Minting and
   220:         // returning a real inode ID is difficult because fuse does not count
   221:         // readdir as an operation that increases the inode ID's lookup count, and
   222:         // we therefore don't get a forget for it later, but we would like to not
   223:         // have to remember every inode ID that we've ever minted for readdir.
   224:         //
   225:         // If it turns out this is not harmless, we'll need to switch to something
   226:         // like inode IDs based on (object name, generation) hashes. But then what
   227:         // about the birthday problem? And more importantly, what about our
   228:         // semantic of not minting a new inode ID when the generation changes due
   229:         // to a local action?
   230:         for i := range entries {
   231:                 entries[i].Inode = fuseops.RootInodeID + 1
   232:         }
   233:
   234:         return
   235: }
   236:
   237: // LOCKS_REQUIRED(dh.Mu)
   238: // LOCKS_EXCLUDED(dh.in)
=> 239: func (dh *DirHandle) ensureEntries(ctx context.Context, localFileEntries []fuseutil.Dirent) (err error) {
   240:         dh.in.Lock()
   241:         defer dh.in.Unlock()
   242:
   243:         // Read entries.
   244:         var entries []fuseutil.Dirent
   245:         entries, err = readAllEntries(ctx, dh.in, localFileEntries)
   246:         if err != nil {
   247:                 err = fmt.Errorf("readAllEntries: %w", err)
   248:                 return
   249:         }
   250:
   251:         // Update state.
   252:         dh.entries = entries
   253:         dh.entriesValid = true
   254:
   255:         return
   256: }
   257:
   258: ////////////////////////////////////////////////////////////////////////
   259: // Public interface
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ensureEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:240 (PC: 0x1955613)
   220:         // returning a real inode ID is difficult because fuse does not count
   221:         // readdir as an operation that increases the inode ID's lookup count, and
   222:         // we therefore don't get a forget for it later, but we would like to not
   223:         // have to remember every inode ID that we've ever minted for readdir.
   224:         //
   225:         // If it turns out this is not harmless, we'll need to switch to something
   226:         // like inode IDs based on (object name, generation) hashes. But then what
   227:         // about the birthday problem? And more importantly, what about our
   228:         // semantic of not minting a new inode ID when the generation changes due
   229:         // to a local action?
   230:         for i := range entries {
   231:                 entries[i].Inode = fuseops.RootInodeID + 1
   232:         }
   233:
   234:         return
   235: }
   236:
   237: // LOCKS_REQUIRED(dh.Mu)
   238: // LOCKS_EXCLUDED(dh.in)
   239: func (dh *DirHandle) ensureEntries(ctx context.Context, localFileEntries []fuseutil.Dirent) (err error) {
=> 240:         dh.in.Lock()
   241:         defer dh.in.Unlock()
   242:
   243:         // Read entries.
   244:         var entries []fuseutil.Dirent
   245:         entries, err = readAllEntries(ctx, dh.in, localFileEntries)
   246:         if err != nil {
   247:                 err = fmt.Errorf("readAllEntries: %w", err)
   248:                 return
   249:         }
   250:
   251:         // Update state.
   252:         dh.entries = entries
   253:         dh.entriesValid = true
   254:
   255:         return
   256: }
   257:
   258: ////////////////////////////////////////////////////////////////////////
   259: // Public interface
   260: ////////////////////////////////////////////////////////////////////////
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ensureEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:241 (PC: 0x195562f)
   221:         // readdir as an operation that increases the inode ID's lookup count, and
   222:         // we therefore don't get a forget for it later, but we would like to not
   223:         // have to remember every inode ID that we've ever minted for readdir.
   224:         //
   225:         // If it turns out this is not harmless, we'll need to switch to something
   226:         // like inode IDs based on (object name, generation) hashes. But then what
   227:         // about the birthday problem? And more importantly, what about our
   228:         // semantic of not minting a new inode ID when the generation changes due
   229:         // to a local action?
   230:         for i := range entries {
   231:                 entries[i].Inode = fuseops.RootInodeID + 1
   232:         }
   233:
   234:         return
   235: }
   236:
   237: // LOCKS_REQUIRED(dh.Mu)
   238: // LOCKS_EXCLUDED(dh.in)
   239: func (dh *DirHandle) ensureEntries(ctx context.Context, localFileEntries []fuseutil.Dirent) (err error) {
   240:         dh.in.Lock()
=> 241:         defer dh.in.Unlock()
   242:
   243:         // Read entries.
   244:         var entries []fuseutil.Dirent
   245:         entries, err = readAllEntries(ctx, dh.in, localFileEntries)
   246:         if err != nil {
   247:                 err = fmt.Errorf("readAllEntries: %w", err)
   248:                 return
   249:         }
   250:
   251:         // Update state.
   252:         dh.entries = entries
   253:         dh.entriesValid = true
   254:
   255:         return
   256: }
   257:
   258: ////////////////////////////////////////////////////////////////////////
   259: // Public interface
   260: ////////////////////////////////////////////////////////////////////////
   261:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ensureEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:244 (PC: 0x19556d5)
   224:         //
   225:         // If it turns out this is not harmless, we'll need to switch to something
   226:         // like inode IDs based on (object name, generation) hashes. But then what
   227:         // about the birthday problem? And more importantly, what about our
   228:         // semantic of not minting a new inode ID when the generation changes due
   229:         // to a local action?
   230:         for i := range entries {
   231:                 entries[i].Inode = fuseops.RootInodeID + 1
   232:         }
   233:
   234:         return
   235: }
   236:
   237: // LOCKS_REQUIRED(dh.Mu)
   238: // LOCKS_EXCLUDED(dh.in)
   239: func (dh *DirHandle) ensureEntries(ctx context.Context, localFileEntries []fuseutil.Dirent) (err error) {
   240:         dh.in.Lock()
   241:         defer dh.in.Unlock()
   242:
   243:         // Read entries.
=> 244:         var entries []fuseutil.Dirent
   245:         entries, err = readAllEntries(ctx, dh.in, localFileEntries)
   246:         if err != nil {
   247:                 err = fmt.Errorf("readAllEntries: %w", err)
   248:                 return
   249:         }
   250:
   251:         // Update state.
   252:         dh.entries = entries
   253:         dh.entriesValid = true
   254:
   255:         return
   256: }
   257:
   258: ////////////////////////////////////////////////////////////////////////
   259: // Public interface
   260: ////////////////////////////////////////////////////////////////////////
   261:
   262: // ReadDir handles a request to read from the directory, without responding.
   263: //
   264: // Special case: we assume that a zero offset indicates that rewinddir has been
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ensureEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:245 (PC: 0x19556e7)
   225:         // If it turns out this is not harmless, we'll need to switch to something
   226:         // like inode IDs based on (object name, generation) hashes. But then what
   227:         // about the birthday problem? And more importantly, what about our
   228:         // semantic of not minting a new inode ID when the generation changes due
   229:         // to a local action?
   230:         for i := range entries {
   231:                 entries[i].Inode = fuseops.RootInodeID + 1
   232:         }
   233:
   234:         return
   235: }
   236:
   237: // LOCKS_REQUIRED(dh.Mu)
   238: // LOCKS_EXCLUDED(dh.in)
   239: func (dh *DirHandle) ensureEntries(ctx context.Context, localFileEntries []fuseutil.Dirent) (err error) {
   240:         dh.in.Lock()
   241:         defer dh.in.Unlock()
   242:
   243:         // Read entries.
   244:         var entries []fuseutil.Dirent
=> 245:         entries, err = readAllEntries(ctx, dh.in, localFileEntries)
   246:         if err != nil {
   247:                 err = fmt.Errorf("readAllEntries: %w", err)
   248:                 return
   249:         }
   250:
   251:         // Update state.
   252:         dh.entries = entries
   253:         dh.entriesValid = true
   254:
   255:         return
   256: }
   257:
   258: ////////////////////////////////////////////////////////////////////////
   259: // Public interface
   260: ////////////////////////////////////////////////////////////////////////
   261:
   262: // ReadDir handles a request to read from the directory, without responding.
   263: //
   264: // Special case: we assume that a zero offset indicates that rewinddir has been
   265: // called (since fuse gives us no way to intercept and know for sure), and
(dlv) s
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:161 (PC: 0x1954d96)
   141:                                 prev.Type)
   142:
   143:                         return
   144:                 }
   145:
   146:                 // Repair whichever is not the directory.
   147:                 if eIsDir {
   148:                         prev.Name += inode.ConflictingFileNameSuffix
   149:                 } else {
   150:                         e.Name += inode.ConflictingFileNameSuffix
   151:                 }
   152:         }
   153:
   154:         return
   155: }
   156:
   157: // Read all entries for the directory, fix up conflicting names, and fill in
   158: // offset fields.
   159: //
   160: // LOCKS_REQUIRED(in)
=> 161: func readAllEntries(
   162:         ctx context.Context,
   163:         in inode.DirInode,
   164:         localEntries []fuseutil.Dirent) (entries []fuseutil.Dirent, err error) {
   165:         // Read entries from GCS.
   166:         // Read one batch at a time.
   167:         var tok string
   168:         for {
   169:                 // Read a batch.
   170:                 var batch []fuseutil.Dirent
   171:
   172:                 batch, tok, err = in.ReadEntries(ctx, tok)
   173:                 if err != nil {
   174:                         err = fmt.Errorf("ReadEntries: %w", err)
   175:                         return
   176:                 }
   177:
   178:                 // Accumulate.
   179:                 entries = append(entries, batch...)
   180:
   181:                 // Are we done?
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:167 (PC: 0x1954df0)
   147:                 if eIsDir {
   148:                         prev.Name += inode.ConflictingFileNameSuffix
   149:                 } else {
   150:                         e.Name += inode.ConflictingFileNameSuffix
   151:                 }
   152:         }
   153:
   154:         return
   155: }
   156:
   157: // Read all entries for the directory, fix up conflicting names, and fill in
   158: // offset fields.
   159: //
   160: // LOCKS_REQUIRED(in)
   161: func readAllEntries(
   162:         ctx context.Context,
   163:         in inode.DirInode,
   164:         localEntries []fuseutil.Dirent) (entries []fuseutil.Dirent, err error) {
   165:         // Read entries from GCS.
   166:         // Read one batch at a time.
=> 167:         var tok string
   168:         for {
   169:                 // Read a batch.
   170:                 var batch []fuseutil.Dirent
   171:
   172:                 batch, tok, err = in.ReadEntries(ctx, tok)
   173:                 if err != nil {
   174:                         err = fmt.Errorf("ReadEntries: %w", err)
   175:                         return
   176:                 }
   177:
   178:                 // Accumulate.
   179:                 entries = append(entries, batch...)
   180:
   181:                 // Are we done?
   182:                 if tok == "" {
   183:                         break
   184:                 }
   185:         }
   186:
   187:         // Append local file entries (not synced to GCS).
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:168 (PC: 0x1954df6)
   148:                         prev.Name += inode.ConflictingFileNameSuffix
   149:                 } else {
   150:                         e.Name += inode.ConflictingFileNameSuffix
   151:                 }
   152:         }
   153:
   154:         return
   155: }
   156:
   157: // Read all entries for the directory, fix up conflicting names, and fill in
   158: // offset fields.
   159: //
   160: // LOCKS_REQUIRED(in)
   161: func readAllEntries(
   162:         ctx context.Context,
   163:         in inode.DirInode,
   164:         localEntries []fuseutil.Dirent) (entries []fuseutil.Dirent, err error) {
   165:         // Read entries from GCS.
   166:         // Read one batch at a time.
   167:         var tok string
=> 168:         for {
   169:                 // Read a batch.
   170:                 var batch []fuseutil.Dirent
   171:
   172:                 batch, tok, err = in.ReadEntries(ctx, tok)
   173:                 if err != nil {
   174:                         err = fmt.Errorf("ReadEntries: %w", err)
   175:                         return
   176:                 }
   177:
   178:                 // Accumulate.
   179:                 entries = append(entries, batch...)
   180:
   181:                 // Are we done?
   182:                 if tok == "" {
   183:                         break
   184:                 }
   185:         }
   186:
   187:         // Append local file entries (not synced to GCS).
   188:         entries = append(entries, localEntries...)
(dlv) config source-list-line-count 40
(dlv) l
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:168 (PC: 0x1954df6)
   128:                 if e.Name != prev.Name {
   129:                         continue
   130:                 }
   131:
   132:                 // We expect exactly one to be a directory.
   133:                 eIsDir := e.Type == fuseutil.DT_Directory
   134:                 prevIsDir := prev.Type == fuseutil.DT_Directory
   135:
   136:                 if eIsDir == prevIsDir {
   137:                         err = fmt.Errorf(
   138:                                 "weird dirent type pair for name %q: %v, %v",
   139:                                 e.Name,
   140:                                 e.Type,
   141:                                 prev.Type)
   142:
   143:                         return
   144:                 }
   145:
   146:                 // Repair whichever is not the directory.
   147:                 if eIsDir {
   148:                         prev.Name += inode.ConflictingFileNameSuffix
   149:                 } else {
   150:                         e.Name += inode.ConflictingFileNameSuffix
   151:                 }
   152:         }
   153:
   154:         return
   155: }
   156:
   157: // Read all entries for the directory, fix up conflicting names, and fill in
   158: // offset fields.
   159: //
   160: // LOCKS_REQUIRED(in)
   161: func readAllEntries(
   162:         ctx context.Context,
   163:         in inode.DirInode,
   164:         localEntries []fuseutil.Dirent) (entries []fuseutil.Dirent, err error) {
   165:         // Read entries from GCS.
   166:         // Read one batch at a time.
   167:         var tok string
=> 168:         for {
   169:                 // Read a batch.
   170:                 var batch []fuseutil.Dirent
   171:
   172:                 batch, tok, err = in.ReadEntries(ctx, tok)
   173:                 if err != nil {
   174:                         err = fmt.Errorf("ReadEntries: %w", err)
   175:                         return
   176:                 }
   177:
   178:                 // Accumulate.
   179:                 entries = append(entries, batch...)
   180:
   181:                 // Are we done?
   182:                 if tok == "" {
   183:                         break
   184:                 }
   185:         }
   186:
   187:         // Append local file entries (not synced to GCS).
   188:         entries = append(entries, localEntries...)
   189:
   190:         // Ensure that the entries are sorted, for use in fixConflictingNames
   191:         // below.
   192:         sort.Sort(sortedDirents(entries))
   193:
   194:         // Fix name conflicts.
   195:         // When a local file is synced to GCS but not removed from the local file map,
   196:         // the entries list will have two duplicate entries.
   197:         // To handle this scenario, we had 2 options:
   198:         // Option 1: [Selected]
   199:         // Throw an error while fixing conflicting names. The error will be fixed in
   200:         // subsequent ls calls assuming that entry will be removed from localFileInodes.
   201:         // Option 2: [Not Selected]
   202:         // Restrict fixConflictingNames to only GCS entries and show duplicate
   203:         // entries when ReadDir is called. In this case, a local file can have
   204:         // same name as directory and LookUpInode call will fetch directory details
   205:         // for both of them.
   206:         err = fixConflictingNames(entries)
   207:         if err != nil {
   208:                 err = fmt.Errorf("fixConflictingNames: %w", err)
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:170 (PC: 0x1954df8)
   130:                 }
   131:
   132:                 // We expect exactly one to be a directory.
   133:                 eIsDir := e.Type == fuseutil.DT_Directory
   134:                 prevIsDir := prev.Type == fuseutil.DT_Directory
   135:
   136:                 if eIsDir == prevIsDir {
   137:                         err = fmt.Errorf(
   138:                                 "weird dirent type pair for name %q: %v, %v",
   139:                                 e.Name,
   140:                                 e.Type,
   141:                                 prev.Type)
   142:
   143:                         return
   144:                 }
   145:
   146:                 // Repair whichever is not the directory.
   147:                 if eIsDir {
   148:                         prev.Name += inode.ConflictingFileNameSuffix
   149:                 } else {
   150:                         e.Name += inode.ConflictingFileNameSuffix
   151:                 }
   152:         }
   153:
   154:         return
   155: }
   156:
   157: // Read all entries for the directory, fix up conflicting names, and fill in
   158: // offset fields.
   159: //
   160: // LOCKS_REQUIRED(in)
   161: func readAllEntries(
   162:         ctx context.Context,
   163:         in inode.DirInode,
   164:         localEntries []fuseutil.Dirent) (entries []fuseutil.Dirent, err error) {
   165:         // Read entries from GCS.
   166:         // Read one batch at a time.
   167:         var tok string
   168:         for {
   169:                 // Read a batch.
=> 170:                 var batch []fuseutil.Dirent
   171:
   172:                 batch, tok, err = in.ReadEntries(ctx, tok)
   173:                 if err != nil {
   174:                         err = fmt.Errorf("ReadEntries: %w", err)
   175:                         return
   176:                 }
   177:
   178:                 // Accumulate.
   179:                 entries = append(entries, batch...)
   180:
   181:                 // Are we done?
   182:                 if tok == "" {
   183:                         break
   184:                 }
   185:         }
   186:
   187:         // Append local file entries (not synced to GCS).
   188:         entries = append(entries, localEntries...)
   189:
   190:         // Ensure that the entries are sorted, for use in fixConflictingNames
   191:         // below.
   192:         sort.Sort(sortedDirents(entries))
   193:
   194:         // Fix name conflicts.
   195:         // When a local file is synced to GCS but not removed from the local file map,
   196:         // the entries list will have two duplicate entries.
   197:         // To handle this scenario, we had 2 options:
   198:         // Option 1: [Selected]
   199:         // Throw an error while fixing conflicting names. The error will be fixed in
   200:         // subsequent ls calls assuming that entry will be removed from localFileInodes.
   201:         // Option 2: [Not Selected]
   202:         // Restrict fixConflictingNames to only GCS entries and show duplicate
   203:         // entries when ReadDir is called. In this case, a local file can have
   204:         // same name as directory and LookUpInode call will fetch directory details
   205:         // for both of them.
   206:         err = fixConflictingNames(entries)
   207:         if err != nil {
   208:                 err = fmt.Errorf("fixConflictingNames: %w", err)
   209:                 return
   210:         }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:172 (PC: 0x1954e0f)
   132:                 // We expect exactly one to be a directory.
   133:                 eIsDir := e.Type == fuseutil.DT_Directory
   134:                 prevIsDir := prev.Type == fuseutil.DT_Directory
   135:
   136:                 if eIsDir == prevIsDir {
   137:                         err = fmt.Errorf(
   138:                                 "weird dirent type pair for name %q: %v, %v",
   139:                                 e.Name,
   140:                                 e.Type,
   141:                                 prev.Type)
   142:
   143:                         return
   144:                 }
   145:
   146:                 // Repair whichever is not the directory.
   147:                 if eIsDir {
   148:                         prev.Name += inode.ConflictingFileNameSuffix
   149:                 } else {
   150:                         e.Name += inode.ConflictingFileNameSuffix
   151:                 }
   152:         }
   153:
   154:         return
   155: }
   156:
   157: // Read all entries for the directory, fix up conflicting names, and fill in
   158: // offset fields.
   159: //
   160: // LOCKS_REQUIRED(in)
   161: func readAllEntries(
   162:         ctx context.Context,
   163:         in inode.DirInode,
   164:         localEntries []fuseutil.Dirent) (entries []fuseutil.Dirent, err error) {
   165:         // Read entries from GCS.
   166:         // Read one batch at a time.
   167:         var tok string
   168:         for {
   169:                 // Read a batch.
   170:                 var batch []fuseutil.Dirent
   171:
=> 172:                 batch, tok, err = in.ReadEntries(ctx, tok)
   173:                 if err != nil {
   174:                         err = fmt.Errorf("ReadEntries: %w", err)
   175:                         return
   176:                 }
   177:
   178:                 // Accumulate.
   179:                 entries = append(entries, batch...)
   180:
   181:                 // Are we done?
   182:                 if tok == "" {
   183:                         break
   184:                 }
   185:         }
   186:
   187:         // Append local file entries (not synced to GCS).
   188:         entries = append(entries, localEntries...)
   189:
   190:         // Ensure that the entries are sorted, for use in fixConflictingNames
   191:         // below.
   192:         sort.Sort(sortedDirents(entries))
   193:
   194:         // Fix name conflicts.
   195:         // When a local file is synced to GCS but not removed from the local file map,
   196:         // the entries list will have two duplicate entries.
   197:         // To handle this scenario, we had 2 options:
   198:         // Option 1: [Selected]
   199:         // Throw an error while fixing conflicting names. The error will be fixed in
   200:         // subsequent ls calls assuming that entry will be removed from localFileInodes.
   201:         // Option 2: [Not Selected]
   202:         // Restrict fixConflictingNames to only GCS entries and show duplicate
   203:         // entries when ReadDir is called. In this case, a local file can have
   204:         // same name as directory and LookUpInode call will fetch directory details
   205:         // for both of them.
   206:         err = fixConflictingNames(entries)
   207:         if err != nil {
   208:                 err = fmt.Errorf("fixConflictingNames: %w", err)
   209:                 return
   210:         }
   211:
   212:         // Fix up offset fields.
(dlv) p tok
""
(dlv) p in
(unreadable invalid interface type)
(dlv) s
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:628 (PC: 0x19478d6)
   588:                                 FullName:  dirName,
   589:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   590:                         }
   591:                         cores[dirName] = explicitDir
   592:                 } else {
   593:                         fileName := NewFileName(d.Name(), nameBase)
   594:                         file := &Core{
   595:                                 Bucket:    d.Bucket(),
   596:                                 FullName:  fileName,
   597:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   598:                         }
   599:                         cores[fileName] = file
   600:                 }
   601:         }
   602:
   603:         // Return an appropriate continuation token, if any.
   604:         newTok = listing.ContinuationToken
   605:
   606:         if !d.implicitDirs {
   607:                 return
   608:         }
   609:
   610:         // Add implicit directories into the result.
   611:         for _, p := range listing.CollapsedRuns {
   612:                 pathBase := path.Base(p)
   613:                 dirName := NewDirName(d.Name(), pathBase)
   614:                 if c, ok := cores[dirName]; ok && c.Type() == metadata.ExplicitDirType {
   615:                         continue
   616:                 }
   617:
   618:                 implicitDir := &Core{
   619:                         Bucket:    d.Bucket(),
   620:                         FullName:  dirName,
   621:                         MinObject: nil,
   622:                 }
   623:                 cores[dirName] = implicitDir
   624:         }
   625:         return
   626: }
   627:
=> 628: func (d *dirInode) ReadEntries(
   629:         ctx context.Context,
   630:         tok string) (entries []fuseutil.Dirent, newTok string, err error) {
   631:         var cores map[Name]*Core
   632:         cores, newTok, err = d.readObjects(ctx, tok)
   633:         if err != nil {
   634:                 err = fmt.Errorf("read objects: %w", err)
   635:                 return
   636:         }
   637:
   638:         for fullName, core := range cores {
   639:                 entry := fuseutil.Dirent{
   640:                         Name: path.Base(fullName.LocalName()),
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
   643:                 switch core.Type() {
   644:                 case metadata.SymlinkType:
   645:                         entry.Type = fuseutil.DT_Link
   646:                 case metadata.RegularFileType:
   647:                         entry.Type = fuseutil.DT_File
   648:                 case metadata.ImplicitDirType, metadata.ExplicitDirType:
   649:                         entry.Type = fuseutil.DT_Directory
   650:                 }
   651:                 entries = append(entries, entry)
   652:         }
   653:         return
   654: }
   655:
   656: // LOCKS_REQUIRED(d)
   657: func (d *dirInode) CreateChildFile(ctx context.Context, name string) (*Core, error) {
   658:         childMetadata := map[string]string{
   659:                 FileMtimeMetadataKey: d.mtimeClock.Now().UTC().Format(time.RFC3339Nano),
   660:         }
   661:         fullName := NewFileName(d.Name(), name)
   662:
   663:         o, err := d.createNewObject(ctx, fullName, childMetadata)
   664:         if err != nil {
   665:                 return nil, err
   666:         }
   667:         m := storageutil.ConvertObjToMinObject(o)
   668:
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:631 (PC: 0x1947929)
   591:                         cores[dirName] = explicitDir
   592:                 } else {
   593:                         fileName := NewFileName(d.Name(), nameBase)
   594:                         file := &Core{
   595:                                 Bucket:    d.Bucket(),
   596:                                 FullName:  fileName,
   597:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   598:                         }
   599:                         cores[fileName] = file
   600:                 }
   601:         }
   602:
   603:         // Return an appropriate continuation token, if any.
   604:         newTok = listing.ContinuationToken
   605:
   606:         if !d.implicitDirs {
   607:                 return
   608:         }
   609:
   610:         // Add implicit directories into the result.
   611:         for _, p := range listing.CollapsedRuns {
   612:                 pathBase := path.Base(p)
   613:                 dirName := NewDirName(d.Name(), pathBase)
   614:                 if c, ok := cores[dirName]; ok && c.Type() == metadata.ExplicitDirType {
   615:                         continue
   616:                 }
   617:
   618:                 implicitDir := &Core{
   619:                         Bucket:    d.Bucket(),
   620:                         FullName:  dirName,
   621:                         MinObject: nil,
   622:                 }
   623:                 cores[dirName] = implicitDir
   624:         }
   625:         return
   626: }
   627:
   628: func (d *dirInode) ReadEntries(
   629:         ctx context.Context,
   630:         tok string) (entries []fuseutil.Dirent, newTok string, err error) {
=> 631:         var cores map[Name]*Core
   632:         cores, newTok, err = d.readObjects(ctx, tok)
   633:         if err != nil {
   634:                 err = fmt.Errorf("read objects: %w", err)
   635:                 return
   636:         }
   637:
   638:         for fullName, core := range cores {
   639:                 entry := fuseutil.Dirent{
   640:                         Name: path.Base(fullName.LocalName()),
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
   643:                 switch core.Type() {
   644:                 case metadata.SymlinkType:
   645:                         entry.Type = fuseutil.DT_Link
   646:                 case metadata.RegularFileType:
   647:                         entry.Type = fuseutil.DT_File
   648:                 case metadata.ImplicitDirType, metadata.ExplicitDirType:
   649:                         entry.Type = fuseutil.DT_Directory
   650:                 }
   651:                 entries = append(entries, entry)
   652:         }
   653:         return
   654: }
   655:
   656: // LOCKS_REQUIRED(d)
   657: func (d *dirInode) CreateChildFile(ctx context.Context, name string) (*Core, error) {
   658:         childMetadata := map[string]string{
   659:                 FileMtimeMetadataKey: d.mtimeClock.Now().UTC().Format(time.RFC3339Nano),
   660:         }
   661:         fullName := NewFileName(d.Name(), name)
   662:
   663:         o, err := d.createNewObject(ctx, fullName, childMetadata)
   664:         if err != nil {
   665:                 return nil, err
   666:         }
   667:         m := storageutil.ConvertObjToMinObject(o)
   668:
   669:         d.cache.Insert(d.cacheClock.Now(), name, metadata.RegularFileType)
   670:         return &Core{
   671:                 Bucket:    d.Bucket(),
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:632 (PC: 0x1947935)
   592:                 } else {
   593:                         fileName := NewFileName(d.Name(), nameBase)
   594:                         file := &Core{
   595:                                 Bucket:    d.Bucket(),
   596:                                 FullName:  fileName,
   597:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   598:                         }
   599:                         cores[fileName] = file
   600:                 }
   601:         }
   602:
   603:         // Return an appropriate continuation token, if any.
   604:         newTok = listing.ContinuationToken
   605:
   606:         if !d.implicitDirs {
   607:                 return
   608:         }
   609:
   610:         // Add implicit directories into the result.
   611:         for _, p := range listing.CollapsedRuns {
   612:                 pathBase := path.Base(p)
   613:                 dirName := NewDirName(d.Name(), pathBase)
   614:                 if c, ok := cores[dirName]; ok && c.Type() == metadata.ExplicitDirType {
   615:                         continue
   616:                 }
   617:
   618:                 implicitDir := &Core{
   619:                         Bucket:    d.Bucket(),
   620:                         FullName:  dirName,
   621:                         MinObject: nil,
   622:                 }
   623:                 cores[dirName] = implicitDir
   624:         }
   625:         return
   626: }
   627:
   628: func (d *dirInode) ReadEntries(
   629:         ctx context.Context,
   630:         tok string) (entries []fuseutil.Dirent, newTok string, err error) {
   631:         var cores map[Name]*Core
=> 632:         cores, newTok, err = d.readObjects(ctx, tok)
   633:         if err != nil {
   634:                 err = fmt.Errorf("read objects: %w", err)
   635:                 return
   636:         }
   637:
   638:         for fullName, core := range cores {
   639:                 entry := fuseutil.Dirent{
   640:                         Name: path.Base(fullName.LocalName()),
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
   643:                 switch core.Type() {
   644:                 case metadata.SymlinkType:
   645:                         entry.Type = fuseutil.DT_Link
   646:                 case metadata.RegularFileType:
   647:                         entry.Type = fuseutil.DT_File
   648:                 case metadata.ImplicitDirType, metadata.ExplicitDirType:
   649:                         entry.Type = fuseutil.DT_Directory
   650:                 }
   651:                 entries = append(entries, entry)
   652:         }
   653:         return
   654: }
   655:
   656: // LOCKS_REQUIRED(d)
   657: func (d *dirInode) CreateChildFile(ctx context.Context, name string) (*Core, error) {
   658:         childMetadata := map[string]string{
   659:                 FileMtimeMetadataKey: d.mtimeClock.Now().UTC().Format(time.RFC3339Nano),
   660:         }
   661:         fullName := NewFileName(d.Name(), name)
   662:
   663:         o, err := d.createNewObject(ctx, fullName, childMetadata)
   664:         if err != nil {
   665:                 return nil, err
   666:         }
   667:         m := storageutil.ConvertObjToMinObject(o)
   668:
   669:         d.cache.Insert(d.cacheClock.Now(), name, metadata.RegularFileType)
   670:         return &Core{
   671:                 Bucket:    d.Bucket(),
   672:                 FullName:  fullName,
(dlv) s
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:543 (PC: 0x1946716)
   503: // LOCKS_REQUIRED(d)
   504: func (d *dirInode) ReadDescendants(ctx context.Context, limit int) (map[Name]*Core, error) {
   505:         var tok string
   506:         descendants := make(map[Name]*Core)
   507:         for {
   508:                 listing, err := d.bucket.ListObjects(ctx, &gcs.ListObjectsRequest{
   509:                         Delimiter:         "", // recursively
   510:                         Prefix:            d.Name().GcsObjectName(),
   511:                         ContinuationToken: tok,
   512:                         MaxResults:        limit + 1, // to exclude itself
   513:                 })
   514:                 if err != nil {
   515:                         return nil, fmt.Errorf("list objects: %w", err)
   516:                 }
   517:
   518:                 for _, o := range listing.Objects {
   519:                         if len(descendants) >= limit {
   520:                                 return descendants, nil
   521:                         }
   522:                         // skip the current directory
   523:                         if o.Name == d.Name().GcsObjectName() {
   524:                                 continue
   525:                         }
   526:                         name := NewDescendantName(d.Name(), o.Name)
   527:                         descendants[name] = &Core{
   528:                                 Bucket:    d.Bucket(),
   529:                                 FullName:  name,
   530:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   531:                         }
   532:                 }
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
=> 543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
   547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:550 (PC: 0x1946763)
   510:                         Prefix:            d.Name().GcsObjectName(),
   511:                         ContinuationToken: tok,
   512:                         MaxResults:        limit + 1, // to exclude itself
   513:                 })
   514:                 if err != nil {
   515:                         return nil, fmt.Errorf("list objects: %w", err)
   516:                 }
   517:
   518:                 for _, o := range listing.Objects {
   519:                         if len(descendants) >= limit {
   520:                                 return descendants, nil
   521:                         }
   522:                         // skip the current directory
   523:                         if o.Name == d.Name().GcsObjectName() {
   524:                                 continue
   525:                         }
   526:                         name := NewDescendantName(d.Name(), o.Name)
   527:                         descendants[name] = &Core{
   528:                                 Bucket:    d.Bucket(),
   529:                                 FullName:  name,
   530:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   531:                         }
   532:                 }
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
   547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
=> 550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
   588:                                 FullName:  dirName,
   589:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   590:                         }
(dlv) p d
("*github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.dirInode")(0xc0004c5440)
*github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.dirInode {
        bucket: *github.com/googlecloudplatform/gcsfuse/v2/internal/gcsx.SyncerBucket {
                Bucket: (unreadable invalid interface type),
                Syncer: (unreadable invalid interface type),},
        mtimeClock: (unreadable invalid interface type),
        cacheClock: (unreadable invalid interface type),
        id: 2,
        implicitDirs: true,
        enableManagedFoldersListing: false,
        enableNonexistentTypeCache: false,
        name: github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Name {bucketName: "", objectName: "walked/"},
        attrs: github.com/jacobsa/fuse/fuseops.InodeAttributes {
                Size: 0,
                Nlink: 0,
                Mode: 2147484141,
                Rdev: 0,
                Atime: (*time.Time)(0xc0004c54b0),
                Mtime: (*time.Time)(0xc0004c54c8),
                Ctime: (*time.Time)(0xc0004c54e0),
                Crtime: (*time.Time)(0xc0004c54f8),
                Uid: 1012083,
                Gid: 89939,},
        mu: (unreadable invalid interface type),
        lc: github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.lookupCount {id: 2, count: 2, destroyed: false},
        cache: (unreadable invalid interface type),}
(dlv) l
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:550 (PC: 0x1946763)
   510:                         Prefix:            d.Name().GcsObjectName(),
   511:                         ContinuationToken: tok,
   512:                         MaxResults:        limit + 1, // to exclude itself
   513:                 })
   514:                 if err != nil {
   515:                         return nil, fmt.Errorf("list objects: %w", err)
   516:                 }
   517:
   518:                 for _, o := range listing.Objects {
   519:                         if len(descendants) >= limit {
   520:                                 return descendants, nil
   521:                         }
   522:                         // skip the current directory
   523:                         if o.Name == d.Name().GcsObjectName() {
   524:                                 continue
   525:                         }
   526:                         name := NewDescendantName(d.Name(), o.Name)
   527:                         descendants[name] = &Core{
   528:                                 Bucket:    d.Bucket(),
   529:                                 FullName:  name,
   530:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   531:                         }
   532:                 }
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
   547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
=> 550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
   588:                                 FullName:  dirName,
   589:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   590:                         }
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:547 (PC: 0x19467a5)
   507:         for {
   508:                 listing, err := d.bucket.ListObjects(ctx, &gcs.ListObjectsRequest{
   509:                         Delimiter:         "", // recursively
   510:                         Prefix:            d.Name().GcsObjectName(),
   511:                         ContinuationToken: tok,
   512:                         MaxResults:        limit + 1, // to exclude itself
   513:                 })
   514:                 if err != nil {
   515:                         return nil, fmt.Errorf("list objects: %w", err)
   516:                 }
   517:
   518:                 for _, o := range listing.Objects {
   519:                         if len(descendants) >= limit {
   520:                                 return descendants, nil
   521:                         }
   522:                         // skip the current directory
   523:                         if o.Name == d.Name().GcsObjectName() {
   524:                                 continue
   525:                         }
   526:                         name := NewDescendantName(d.Name(), o.Name)
   527:                         descendants[name] = &Core{
   528:                                 Bucket:    d.Bucket(),
   529:                                 FullName:  name,
   530:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   531:                         }
   532:                 }
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
=> 547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:548 (PC: 0x19467b9)
   508:                 listing, err := d.bucket.ListObjects(ctx, &gcs.ListObjectsRequest{
   509:                         Delimiter:         "", // recursively
   510:                         Prefix:            d.Name().GcsObjectName(),
   511:                         ContinuationToken: tok,
   512:                         MaxResults:        limit + 1, // to exclude itself
   513:                 })
   514:                 if err != nil {
   515:                         return nil, fmt.Errorf("list objects: %w", err)
   516:                 }
   517:
   518:                 for _, o := range listing.Objects {
   519:                         if len(descendants) >= limit {
   520:                                 return descendants, nil
   521:                         }
   522:                         // skip the current directory
   523:                         if o.Name == d.Name().GcsObjectName() {
   524:                                 continue
   525:                         }
   526:                         name := NewDescendantName(d.Name(), o.Name)
   527:                         descendants[name] = &Core{
   528:                                 Bucket:    d.Bucket(),
   529:                                 FullName:  name,
   530:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   531:                         }
   532:                 }
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
   547:         req := &gcs.ListObjectsRequest{
=> 548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
   588:                                 FullName:  dirName,
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:547 (PC: 0x19467e7)
   507:         for {
   508:                 listing, err := d.bucket.ListObjects(ctx, &gcs.ListObjectsRequest{
   509:                         Delimiter:         "", // recursively
   510:                         Prefix:            d.Name().GcsObjectName(),
   511:                         ContinuationToken: tok,
   512:                         MaxResults:        limit + 1, // to exclude itself
   513:                 })
   514:                 if err != nil {
   515:                         return nil, fmt.Errorf("list objects: %w", err)
   516:                 }
   517:
   518:                 for _, o := range listing.Objects {
   519:                         if len(descendants) >= limit {
   520:                                 return descendants, nil
   521:                         }
   522:                         // skip the current directory
   523:                         if o.Name == d.Name().GcsObjectName() {
   524:                                 continue
   525:                         }
   526:                         name := NewDescendantName(d.Name(), o.Name)
   527:                         descendants[name] = &Core{
   528:                                 Bucket:    d.Bucket(),
   529:                                 FullName:  name,
   530:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   531:                         }
   532:                 }
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
=> 547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:549 (PC: 0x19467f1)
   509:                         Delimiter:         "", // recursively
   510:                         Prefix:            d.Name().GcsObjectName(),
   511:                         ContinuationToken: tok,
   512:                         MaxResults:        limit + 1, // to exclude itself
   513:                 })
   514:                 if err != nil {
   515:                         return nil, fmt.Errorf("list objects: %w", err)
   516:                 }
   517:
   518:                 for _, o := range listing.Objects {
   519:                         if len(descendants) >= limit {
   520:                                 return descendants, nil
   521:                         }
   522:                         // skip the current directory
   523:                         if o.Name == d.Name().GcsObjectName() {
   524:                                 continue
   525:                         }
   526:                         name := NewDescendantName(d.Name(), o.Name)
   527:                         descendants[name] = &Core{
   528:                                 Bucket:    d.Bucket(),
   529:                                 FullName:  name,
   530:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   531:                         }
   532:                 }
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
   547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
=> 549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
   588:                                 FullName:  dirName,
   589:                                 MinObject: storageutil.ConvertObjToMinObject(o),
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:547 (PC: 0x19467f5)
   507:         for {
   508:                 listing, err := d.bucket.ListObjects(ctx, &gcs.ListObjectsRequest{
   509:                         Delimiter:         "", // recursively
   510:                         Prefix:            d.Name().GcsObjectName(),
   511:                         ContinuationToken: tok,
   512:                         MaxResults:        limit + 1, // to exclude itself
   513:                 })
   514:                 if err != nil {
   515:                         return nil, fmt.Errorf("list objects: %w", err)
   516:                 }
   517:
   518:                 for _, o := range listing.Objects {
   519:                         if len(descendants) >= limit {
   520:                                 return descendants, nil
   521:                         }
   522:                         // skip the current directory
   523:                         if o.Name == d.Name().GcsObjectName() {
   524:                                 continue
   525:                         }
   526:                         name := NewDescendantName(d.Name(), o.Name)
   527:                         descendants[name] = &Core{
   528:                                 Bucket:    d.Bucket(),
   529:                                 FullName:  name,
   530:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   531:                         }
   532:                 }
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
=> 547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:550 (PC: 0x19467ff)
   510:                         Prefix:            d.Name().GcsObjectName(),
   511:                         ContinuationToken: tok,
   512:                         MaxResults:        limit + 1, // to exclude itself
   513:                 })
   514:                 if err != nil {
   515:                         return nil, fmt.Errorf("list objects: %w", err)
   516:                 }
   517:
   518:                 for _, o := range listing.Objects {
   519:                         if len(descendants) >= limit {
   520:                                 return descendants, nil
   521:                         }
   522:                         // skip the current directory
   523:                         if o.Name == d.Name().GcsObjectName() {
   524:                                 continue
   525:                         }
   526:                         name := NewDescendantName(d.Name(), o.Name)
   527:                         descendants[name] = &Core{
   528:                                 Bucket:    d.Bucket(),
   529:                                 FullName:  name,
   530:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   531:                         }
   532:                 }
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
   547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
=> 550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
   588:                                 FullName:  dirName,
   589:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   590:                         }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:547 (PC: 0x1946836)
   507:         for {
   508:                 listing, err := d.bucket.ListObjects(ctx, &gcs.ListObjectsRequest{
   509:                         Delimiter:         "", // recursively
   510:                         Prefix:            d.Name().GcsObjectName(),
   511:                         ContinuationToken: tok,
   512:                         MaxResults:        limit + 1, // to exclude itself
   513:                 })
   514:                 if err != nil {
   515:                         return nil, fmt.Errorf("list objects: %w", err)
   516:                 }
   517:
   518:                 for _, o := range listing.Objects {
   519:                         if len(descendants) >= limit {
   520:                                 return descendants, nil
   521:                         }
   522:                         // skip the current directory
   523:                         if o.Name == d.Name().GcsObjectName() {
   524:                                 continue
   525:                         }
   526:                         name := NewDescendantName(d.Name(), o.Name)
   527:                         descendants[name] = &Core{
   528:                                 Bucket:    d.Bucket(),
   529:                                 FullName:  name,
   530:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   531:                         }
   532:                 }
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
=> 547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:551 (PC: 0x1946840)
   511:                         ContinuationToken: tok,
   512:                         MaxResults:        limit + 1, // to exclude itself
   513:                 })
   514:                 if err != nil {
   515:                         return nil, fmt.Errorf("list objects: %w", err)
   516:                 }
   517:
   518:                 for _, o := range listing.Objects {
   519:                         if len(descendants) >= limit {
   520:                                 return descendants, nil
   521:                         }
   522:                         // skip the current directory
   523:                         if o.Name == d.Name().GcsObjectName() {
   524:                                 continue
   525:                         }
   526:                         name := NewDescendantName(d.Name(), o.Name)
   527:                         descendants[name] = &Core{
   528:                                 Bucket:    d.Bucket(),
   529:                                 FullName:  name,
   530:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   531:                         }
   532:                 }
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
   547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
=> 551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
   588:                                 FullName:  dirName,
   589:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   590:                         }
   591:                         cores[dirName] = explicitDir
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:547 (PC: 0x1946878)
   507:         for {
   508:                 listing, err := d.bucket.ListObjects(ctx, &gcs.ListObjectsRequest{
   509:                         Delimiter:         "", // recursively
   510:                         Prefix:            d.Name().GcsObjectName(),
   511:                         ContinuationToken: tok,
   512:                         MaxResults:        limit + 1, // to exclude itself
   513:                 })
   514:                 if err != nil {
   515:                         return nil, fmt.Errorf("list objects: %w", err)
   516:                 }
   517:
   518:                 for _, o := range listing.Objects {
   519:                         if len(descendants) >= limit {
   520:                                 return descendants, nil
   521:                         }
   522:                         // skip the current directory
   523:                         if o.Name == d.Name().GcsObjectName() {
   524:                                 continue
   525:                         }
   526:                         name := NewDescendantName(d.Name(), o.Name)
   527:                         descendants[name] = &Core{
   528:                                 Bucket:    d.Bucket(),
   529:                                 FullName:  name,
   530:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   531:                         }
   532:                 }
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
=> 547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:552 (PC: 0x1946882)
   512:                         MaxResults:        limit + 1, // to exclude itself
   513:                 })
   514:                 if err != nil {
   515:                         return nil, fmt.Errorf("list objects: %w", err)
   516:                 }
   517:
   518:                 for _, o := range listing.Objects {
   519:                         if len(descendants) >= limit {
   520:                                 return descendants, nil
   521:                         }
   522:                         // skip the current directory
   523:                         if o.Name == d.Name().GcsObjectName() {
   524:                                 continue
   525:                         }
   526:                         name := NewDescendantName(d.Name(), o.Name)
   527:                         descendants[name] = &Core{
   528:                                 Bucket:    d.Bucket(),
   529:                                 FullName:  name,
   530:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   531:                         }
   532:                 }
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
   547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
=> 552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
   588:                                 FullName:  dirName,
   589:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   590:                         }
   591:                         cores[dirName] = explicitDir
   592:                 } else {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:547 (PC: 0x194688a)
   507:         for {
   508:                 listing, err := d.bucket.ListObjects(ctx, &gcs.ListObjectsRequest{
   509:                         Delimiter:         "", // recursively
   510:                         Prefix:            d.Name().GcsObjectName(),
   511:                         ContinuationToken: tok,
   512:                         MaxResults:        limit + 1, // to exclude itself
   513:                 })
   514:                 if err != nil {
   515:                         return nil, fmt.Errorf("list objects: %w", err)
   516:                 }
   517:
   518:                 for _, o := range listing.Objects {
   519:                         if len(descendants) >= limit {
   520:                                 return descendants, nil
   521:                         }
   522:                         // skip the current directory
   523:                         if o.Name == d.Name().GcsObjectName() {
   524:                                 continue
   525:                         }
   526:                         name := NewDescendantName(d.Name(), o.Name)
   527:                         descendants[name] = &Core{
   528:                                 Bucket:    d.Bucket(),
   529:                                 FullName:  name,
   530:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   531:                         }
   532:                 }
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
=> 547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:555 (PC: 0x1946894)
   515:                         return nil, fmt.Errorf("list objects: %w", err)
   516:                 }
   517:
   518:                 for _, o := range listing.Objects {
   519:                         if len(descendants) >= limit {
   520:                                 return descendants, nil
   521:                         }
   522:                         // skip the current directory
   523:                         if o.Name == d.Name().GcsObjectName() {
   524:                                 continue
   525:                         }
   526:                         name := NewDescendantName(d.Name(), o.Name)
   527:                         descendants[name] = &Core{
   528:                                 Bucket:    d.Bucket(),
   529:                                 FullName:  name,
   530:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   531:                         }
   532:                 }
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
   547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
=> 555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
   588:                                 FullName:  dirName,
   589:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   590:                         }
   591:                         cores[dirName] = explicitDir
   592:                 } else {
   593:                         fileName := NewFileName(d.Name(), nameBase)
   594:                         file := &Core{
   595:                                 Bucket:    d.Bucket(),
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:547 (PC: 0x194689c)
   507:         for {
   508:                 listing, err := d.bucket.ListObjects(ctx, &gcs.ListObjectsRequest{
   509:                         Delimiter:         "", // recursively
   510:                         Prefix:            d.Name().GcsObjectName(),
   511:                         ContinuationToken: tok,
   512:                         MaxResults:        limit + 1, // to exclude itself
   513:                 })
   514:                 if err != nil {
   515:                         return nil, fmt.Errorf("list objects: %w", err)
   516:                 }
   517:
   518:                 for _, o := range listing.Objects {
   519:                         if len(descendants) >= limit {
   520:                                 return descendants, nil
   521:                         }
   522:                         // skip the current directory
   523:                         if o.Name == d.Name().GcsObjectName() {
   524:                                 continue
   525:                         }
   526:                         name := NewDescendantName(d.Name(), o.Name)
   527:                         descendants[name] = &Core{
   528:                                 Bucket:    d.Bucket(),
   529:                                 FullName:  name,
   530:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   531:                         }
   532:                 }
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
=> 547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:556 (PC: 0x19468a6)
   516:                 }
   517:
   518:                 for _, o := range listing.Objects {
   519:                         if len(descendants) >= limit {
   520:                                 return descendants, nil
   521:                         }
   522:                         // skip the current directory
   523:                         if o.Name == d.Name().GcsObjectName() {
   524:                                 continue
   525:                         }
   526:                         name := NewDescendantName(d.Name(), o.Name)
   527:                         descendants[name] = &Core{
   528:                                 Bucket:    d.Bucket(),
   529:                                 FullName:  name,
   530:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   531:                         }
   532:                 }
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
   547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
=> 556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
   588:                                 FullName:  dirName,
   589:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   590:                         }
   591:                         cores[dirName] = explicitDir
   592:                 } else {
   593:                         fileName := NewFileName(d.Name(), nameBase)
   594:                         file := &Core{
   595:                                 Bucket:    d.Bucket(),
   596:                                 FullName:  fileName,
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:547 (PC: 0x19468b8)
   507:         for {
   508:                 listing, err := d.bucket.ListObjects(ctx, &gcs.ListObjectsRequest{
   509:                         Delimiter:         "", // recursively
   510:                         Prefix:            d.Name().GcsObjectName(),
   511:                         ContinuationToken: tok,
   512:                         MaxResults:        limit + 1, // to exclude itself
   513:                 })
   514:                 if err != nil {
   515:                         return nil, fmt.Errorf("list objects: %w", err)
   516:                 }
   517:
   518:                 for _, o := range listing.Objects {
   519:                         if len(descendants) >= limit {
   520:                                 return descendants, nil
   521:                         }
   522:                         // skip the current directory
   523:                         if o.Name == d.Name().GcsObjectName() {
   524:                                 continue
   525:                         }
   526:                         name := NewDescendantName(d.Name(), o.Name)
   527:                         descendants[name] = &Core{
   528:                                 Bucket:    d.Bucket(),
   529:                                 FullName:  name,
   530:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   531:                         }
   532:                 }
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
=> 547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:559 (PC: 0x19468c8)
   519:                         if len(descendants) >= limit {
   520:                                 return descendants, nil
   521:                         }
   522:                         // skip the current directory
   523:                         if o.Name == d.Name().GcsObjectName() {
   524:                                 continue
   525:                         }
   526:                         name := NewDescendantName(d.Name(), o.Name)
   527:                         descendants[name] = &Core{
   528:                                 Bucket:    d.Bucket(),
   529:                                 FullName:  name,
   530:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   531:                         }
   532:                 }
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
   547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
=> 559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
   588:                                 FullName:  dirName,
   589:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   590:                         }
   591:                         cores[dirName] = explicitDir
   592:                 } else {
   593:                         fileName := NewFileName(d.Name(), nameBase)
   594:                         file := &Core{
   595:                                 Bucket:    d.Bucket(),
   596:                                 FullName:  fileName,
   597:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   598:                         }
   599:                         cores[fileName] = file
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306 (hits goroutine(356):1 total:3) (PC: 0x18ef473)
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("Error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 // Do not list unsupported directories such as '.', '..',
   285:                                 // '/', and '\0' as prefixes, which become implicit directories,
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
   292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
=> 306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
   323:         listing = &list
   324:         return
   325: }
   326:
   327: func (b *bucketHandle) UpdateObject(ctx context.Context, req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   328:         obj := b.bucket.Object(req.Name)
   329:
   330:         if req.Generation != 0 {
   331:                 obj = obj.Generation(req.Generation)
   332:         }
   333:
   334:         if req.MetaGenerationPrecondition != nil {
   335:                 obj = obj.If(storage.Conditions{MetagenerationMatch: *req.MetaGenerationPrecondition})
   336:         }
   337:
   338:         updateQuery := storage.ObjectAttrsToUpdate{}
   339:
   340:         if req.ContentType != nil {
   341:                 updateQuery.ContentType = *req.ContentType
   342:         }
   343:
   344:         if req.ContentEncoding != nil {
   345:                 updateQuery.ContentEncoding = *req.ContentEncoding
   346:         }
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:292 (hits goroutine(356):1 total:1) (PC: 0x18ef1ca)
   252:                 Delimiter:                req.Delimiter,
   253:                 Prefix:                   req.Prefix,
   254:                 Projection:               getProjectionValue(req.ProjectionVal),
   255:                 IncludeTrailingDelimiter: req.IncludeTrailingDelimiter,
   256:                 IncludeFoldersAsPrefixes: req.IncludeFoldersAsPrefixes,
   257:                 //MaxResults: , (Field not present in storage.Query of Go Storage Library but present in ListObjectsQuery in Jacobsa code.)
   258:         }
   259:         itr := b.bucket.Objects(ctx, query) // Returning iterator to the list of objects.
   260:         pi := itr.PageInfo()
   261:         pi.MaxSize = req.MaxResults
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("Error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 // Do not list unsupported directories such as '.', '..',
   285:                                 // '/', and '\0' as prefixes, which become implicit directories,
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
=> 292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
   323:         listing = &list
   324:         return
   325: }
   326:
   327: func (b *bucketHandle) UpdateObject(ctx context.Context, req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   328:         obj := b.bucket.Object(req.Name)
   329:
   330:         if req.Generation != 0 {
   331:                 obj = obj.Generation(req.Generation)
   332:         }
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:324 (hits goroutine(356):1 total:3) (PC: 0x18ef5c5)
   284:                                 // Do not list unsupported directories such as '.', '..',
   285:                                 // '/', and '\0' as prefixes, which become implicit directories,
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
   292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
   323:         listing = &list
=> 324:         return
   325: }
   326:
   327: func (b *bucketHandle) UpdateObject(ctx context.Context, req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   328:         obj := b.bucket.Object(req.Name)
   329:
   330:         if req.Generation != 0 {
   331:                 obj = obj.Generation(req.Generation)
   332:         }
   333:
   334:         if req.MetaGenerationPrecondition != nil {
   335:                 obj = obj.If(storage.Conditions{MetagenerationMatch: *req.MetaGenerationPrecondition})
   336:         }
   337:
   338:         updateQuery := storage.ObjectAttrsToUpdate{}
   339:
   340:         if req.ContentType != nil {
   341:                 updateQuery.ContentType = *req.ContentType
   342:         }
   343:
   344:         if req.ContentEncoding != nil {
   345:                 updateQuery.ContentEncoding = *req.ContentEncoding
   346:         }
   347:
   348:         if req.ContentLanguage != nil {
   349:                 updateQuery.ContentLanguage = *req.ContentLanguage
   350:         }
   351:
   352:         if req.CacheControl != nil {
   353:                 updateQuery.CacheControl = *req.CacheControl
   354:         }
   355:
   356:         if req.Metadata != nil {
   357:                 updateQuery.Metadata = make(map[string]string)
   358:                 for key, element := range req.Metadata {
   359:                         if element != nil {
   360:                                 updateQuery.Metadata[key] = *element
   361:                         }
   362:                 }
   363:         }
   364:
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*debugBucket).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/debug_bucket.go:205 (PC: 0x18f387d)
Values returned:
        listing: ("*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing")(0xc0001f81c0)
*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing {
                Objects: []*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object len: 1, cap: 1, [
                        *(*"github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object")(0xc000640500),
                ],
                CollapsedRuns: []string len: 0, cap: 0, nil,
                ContinuationToken: "",}
        err: error nil

   165:         id, desc, start := b.startRequest(
   166:                 "CopyObject(%q, %q)",
   167:                 req.SrcName,
   168:                 req.DstName)
   169:
   170:         defer b.finishRequest(id, desc, start, &err)
   171:
   172:         o, err = b.wrapped.CopyObject(ctx, req)
   173:         return
   174: }
   175:
   176: func (b *debugBucket) ComposeObjects(
   177:         ctx context.Context,
   178:         req *gcs.ComposeObjectsRequest) (o *gcs.Object, err error) {
   179:         id, desc, start := b.startRequest(
   180:                 "ComposeObjects(%q)",
   181:                 req.DstName)
   182:
   183:         defer b.finishRequest(id, desc, start, &err)
   184:
   185:         o, err = b.wrapped.ComposeObjects(ctx, req)
   186:         return
   187: }
   188:
   189: func (b *debugBucket) StatObject(
   190:         ctx context.Context,
   191:         req *gcs.StatObjectRequest) (m *gcs.MinObject, e *gcs.ExtendedObjectAttributes, err error) {
   192:         id, desc, start := b.startRequest("StatObject(%q)", req.Name)
   193:         defer b.finishRequest(id, desc, start, &err)
   194:
   195:         m, e, err = b.wrapped.StatObject(ctx, req)
   196:         return
   197: }
   198:
   199: func (b *debugBucket) ListObjects(
   200:         ctx context.Context,
   201:         req *gcs.ListObjectsRequest) (listing *gcs.Listing, err error) {
   202:         id, desc, start := b.startRequest("ListObjects(%q)", req.Prefix)
   203:         defer b.finishRequest(id, desc, start, &err)
   204:
=> 205:         listing, err = b.wrapped.ListObjects(ctx, req)
   206:         return
   207: }
   208:
   209: func (b *debugBucket) UpdateObject(
   210:         ctx context.Context,
   211:         req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   212:         id, desc, start := b.startRequest("UpdateObject(%q)", req.Name)
   213:         defer b.finishRequest(id, desc, start, &err)
   214:
   215:         o, err = b.wrapped.UpdateObject(ctx, req)
   216:         return
   217: }
   218:
   219: func (b *debugBucket) DeleteObject(
   220:         ctx context.Context,
   221:         req *gcs.DeleteObjectRequest) (err error) {
   222:         id, desc, start := b.startRequest("DeleteObject(%q)", req.Name)
   223:         defer b.finishRequest(id, desc, start, &err)
   224:
   225:         err = b.wrapped.DeleteObject(ctx, req)
   226:         return
   227: }
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:559 (PC: 0x1946913)
Values returned:
        ~r0: ("*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing")(0xc0001f81c0)
*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing {
                Objects: []*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object len: 1, cap: 1, [
                        *(*"github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object")(0xc000640500),
                ],
                CollapsedRuns: []string len: 0, cap: 0, nil,
                ContinuationToken: "",}
        ~r1: error nil

   519:                         if len(descendants) >= limit {
   520:                                 return descendants, nil
   521:                         }
   522:                         // skip the current directory
   523:                         if o.Name == d.Name().GcsObjectName() {
   524:                                 continue
   525:                         }
   526:                         name := NewDescendantName(d.Name(), o.Name)
   527:                         descendants[name] = &Core{
   528:                                 Bucket:    d.Bucket(),
   529:                                 FullName:  name,
   530:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   531:                         }
   532:                 }
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
   547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
=> 559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
   588:                                 FullName:  dirName,
   589:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   590:                         }
   591:                         cores[dirName] = explicitDir
   592:                 } else {
   593:                         fileName := NewFileName(d.Name(), nameBase)
   594:                         file := &Core{
   595:                                 Bucket:    d.Bucket(),
   596:                                 FullName:  fileName,
   597:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   598:                         }
   599:                         cores[fileName] = file
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:560 (PC: 0x194698b)
   520:                                 return descendants, nil
   521:                         }
   522:                         // skip the current directory
   523:                         if o.Name == d.Name().GcsObjectName() {
   524:                                 continue
   525:                         }
   526:                         name := NewDescendantName(d.Name(), o.Name)
   527:                         descendants[name] = &Core{
   528:                                 Bucket:    d.Bucket(),
   529:                                 FullName:  name,
   530:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   531:                         }
   532:                 }
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
   547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
=> 560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
   588:                                 FullName:  dirName,
   589:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   590:                         }
   591:                         cores[dirName] = explicitDir
   592:                 } else {
   593:                         fileName := NewFileName(d.Name(), nameBase)
   594:                         file := &Core{
   595:                                 Bucket:    d.Bucket(),
   596:                                 FullName:  fileName,
   597:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   598:                         }
   599:                         cores[fileName] = file
   600:                 }
(dlv) p listing
("*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing")(0xc0001f81c0)
*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing {
        Objects: []*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object len: 1, cap: 1, [
                *(*"github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object")(0xc000640500),
        ],
        CollapsedRuns: []string len: 0, cap: 0, nil,
        ContinuationToken: "",}
(dlv) p listing.Objects
[]*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object len: 1, cap: 1, [
        *{
                Name: "walked/",
                ContentType: "text/plain",
                ContentLanguage: "",
                CacheControl: "",
                Owner: "",
                Size: 0,
                ContentEncoding: "",
                MD5: *[16]uint8 [212,29,140,217,143,0,178,4,233,128,9,152,236,248,66,126],
                CRC32C: *0,
                MediaLink: "https://storage.googleapis.com/download/storage/v1/b/gargnitin-t...+76 more",
                Metadata: map[string]string nil,
                Generation: 1715194144661809,
                MetaGeneration: 1,
                StorageClass: "STANDARD",
                Deleted: (*time.Time)(0xc0006405b0),
                Updated: (*time.Time)(0xc0006405c8),
                ComponentCount: 0,
                ContentDisposition: "",
                CustomTime: "0001-01-01T00:00:00Z",
                EventBasedHold: false,
                Acl: []*google.golang.org/api/storage/v1.ObjectAccessControl len: 0, cap: 0, nil,},
]
(dlv) l
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:560 (PC: 0x194698b)
   520:                                 return descendants, nil
   521:                         }
   522:                         // skip the current directory
   523:                         if o.Name == d.Name().GcsObjectName() {
   524:                                 continue
   525:                         }
   526:                         name := NewDescendantName(d.Name(), o.Name)
   527:                         descendants[name] = &Core{
   528:                                 Bucket:    d.Bucket(),
   529:                                 FullName:  name,
   530:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   531:                         }
   532:                 }
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
   547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
=> 560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
   588:                                 FullName:  dirName,
   589:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   590:                         }
   591:                         cores[dirName] = explicitDir
   592:                 } else {
   593:                         fileName := NewFileName(d.Name(), nameBase)
   594:                         file := &Core{
   595:                                 Bucket:    d.Bucket(),
   596:                                 FullName:  fileName,
   597:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   598:                         }
   599:                         cores[fileName] = file
   600:                 }
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:565 (PC: 0x1946acb)
   525:                         }
   526:                         name := NewDescendantName(d.Name(), o.Name)
   527:                         descendants[name] = &Core{
   528:                                 Bucket:    d.Bucket(),
   529:                                 FullName:  name,
   530:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   531:                         }
   532:                 }
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
   547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
=> 565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
   588:                                 FullName:  dirName,
   589:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   590:                         }
   591:                         cores[dirName] = explicitDir
   592:                 } else {
   593:                         fileName := NewFileName(d.Name(), nameBase)
   594:                         file := &Core{
   595:                                 Bucket:    d.Bucket(),
   596:                                 FullName:  fileName,
   597:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   598:                         }
   599:                         cores[fileName] = file
   600:                 }
   601:         }
   602:
   603:         // Return an appropriate continuation token, if any.
   604:         newTok = listing.ContinuationToken
   605:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:566 (PC: 0x1946ad8)
   526:                         name := NewDescendantName(d.Name(), o.Name)
   527:                         descendants[name] = &Core{
   528:                                 Bucket:    d.Bucket(),
   529:                                 FullName:  name,
   530:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   531:                         }
   532:                 }
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
   547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
=> 566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
   588:                                 FullName:  dirName,
   589:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   590:                         }
   591:                         cores[dirName] = explicitDir
   592:                 } else {
   593:                         fileName := NewFileName(d.Name(), nameBase)
   594:                         file := &Core{
   595:                                 Bucket:    d.Bucket(),
   596:                                 FullName:  fileName,
   597:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   598:                         }
   599:                         cores[fileName] = file
   600:                 }
   601:         }
   602:
   603:         // Return an appropriate continuation token, if any.
   604:         newTok = listing.ContinuationToken
   605:
   606:         if !d.implicitDirs {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:573 (PC: 0x1946b86)
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
   547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
=> 573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
   588:                                 FullName:  dirName,
   589:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   590:                         }
   591:                         cores[dirName] = explicitDir
   592:                 } else {
   593:                         fileName := NewFileName(d.Name(), nameBase)
   594:                         file := &Core{
   595:                                 Bucket:    d.Bucket(),
   596:                                 FullName:  fileName,
   597:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   598:                         }
   599:                         cores[fileName] = file
   600:                 }
   601:         }
   602:
   603:         // Return an appropriate continuation token, if any.
   604:         newTok = listing.ContinuationToken
   605:
   606:         if !d.implicitDirs {
   607:                 return
   608:         }
   609:
   610:         // Add implicit directories into the result.
   611:         for _, p := range listing.CollapsedRuns {
   612:                 pathBase := path.Base(p)
   613:                 dirName := NewDirName(d.Name(), pathBase)
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:575 (PC: 0x1946c35)
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
   547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
=> 575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
   588:                                 FullName:  dirName,
   589:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   590:                         }
   591:                         cores[dirName] = explicitDir
   592:                 } else {
   593:                         fileName := NewFileName(d.Name(), nameBase)
   594:                         file := &Core{
   595:                                 Bucket:    d.Bucket(),
   596:                                 FullName:  fileName,
   597:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   598:                         }
   599:                         cores[fileName] = file
   600:                 }
   601:         }
   602:
   603:         // Return an appropriate continuation token, if any.
   604:         newTok = listing.ContinuationToken
   605:
   606:         if !d.implicitDirs {
   607:                 return
   608:         }
   609:
   610:         // Add implicit directories into the result.
   611:         for _, p := range listing.CollapsedRuns {
   612:                 pathBase := path.Base(p)
   613:                 dirName := NewDirName(d.Name(), pathBase)
   614:                 if c, ok := cores[dirName]; ok && c.Type() == metadata.ExplicitDirType {
   615:                         continue
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:576 (PC: 0x1946ced)
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
   547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
=> 576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
   588:                                 FullName:  dirName,
   589:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   590:                         }
   591:                         cores[dirName] = explicitDir
   592:                 } else {
   593:                         fileName := NewFileName(d.Name(), nameBase)
   594:                         file := &Core{
   595:                                 Bucket:    d.Bucket(),
   596:                                 FullName:  fileName,
   597:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   598:                         }
   599:                         cores[fileName] = file
   600:                 }
   601:         }
   602:
   603:         // Return an appropriate continuation token, if any.
   604:         newTok = listing.ContinuationToken
   605:
   606:         if !d.implicitDirs {
   607:                 return
   608:         }
   609:
   610:         // Add implicit directories into the result.
   611:         for _, p := range listing.CollapsedRuns {
   612:                 pathBase := path.Base(p)
   613:                 dirName := NewDirName(d.Name(), pathBase)
   614:                 if c, ok := cores[dirName]; ok && c.Type() == metadata.ExplicitDirType {
   615:                         continue
   616:                 }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:573 (PC: 0x194721e)
   533:
   534:                 // Are we done listing?
   535:                 if tok = listing.ContinuationToken; tok == "" {
   536:                         return descendants, nil
   537:                 }
   538:         }
   539:
   540: }
   541:
   542: // LOCKS_REQUIRED(d)
   543: func (d *dirInode) readObjects(
   544:         ctx context.Context,
   545:         tok string) (cores map[Name]*Core, newTok string, err error) {
   546:         // Ask the bucket to list some objects.
   547:         req := &gcs.ListObjectsRequest{
   548:                 Delimiter:                "/",
   549:                 IncludeTrailingDelimiter: true,
   550:                 Prefix:                   d.Name().GcsObjectName(),
   551:                 ContinuationToken:        tok,
   552:                 MaxResults:               MaxResultsForListObjectsCall,
   553:                 // Setting Projection param to noAcl since fetching owner and acls are not
   554:                 // required.
   555:                 ProjectionVal:            gcs.NoAcl,
   556:                 IncludeFoldersAsPrefixes: d.enableManagedFoldersListing,
   557:         }
   558:
   559:         listing, err := d.bucket.ListObjects(ctx, req)
   560:         if err != nil {
   561:                 err = fmt.Errorf("ListObjects: %w", err)
   562:                 return
   563:         }
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
=> 573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
   588:                                 FullName:  dirName,
   589:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   590:                         }
   591:                         cores[dirName] = explicitDir
   592:                 } else {
   593:                         fileName := NewFileName(d.Name(), nameBase)
   594:                         file := &Core{
   595:                                 Bucket:    d.Bucket(),
   596:                                 FullName:  fileName,
   597:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   598:                         }
   599:                         cores[fileName] = file
   600:                 }
   601:         }
   602:
   603:         // Return an appropriate continuation token, if any.
   604:         newTok = listing.ContinuationToken
   605:
   606:         if !d.implicitDirs {
   607:                 return
   608:         }
   609:
   610:         // Add implicit directories into the result.
   611:         for _, p := range listing.CollapsedRuns {
   612:                 pathBase := path.Base(p)
   613:                 dirName := NewDirName(d.Name(), pathBase)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:604 (PC: 0x194722b)
   564:
   565:         cores = make(map[Name]*Core)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
   588:                                 FullName:  dirName,
   589:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   590:                         }
   591:                         cores[dirName] = explicitDir
   592:                 } else {
   593:                         fileName := NewFileName(d.Name(), nameBase)
   594:                         file := &Core{
   595:                                 Bucket:    d.Bucket(),
   596:                                 FullName:  fileName,
   597:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   598:                         }
   599:                         cores[fileName] = file
   600:                 }
   601:         }
   602:
   603:         // Return an appropriate continuation token, if any.
=> 604:         newTok = listing.ContinuationToken
   605:
   606:         if !d.implicitDirs {
   607:                 return
   608:         }
   609:
   610:         // Add implicit directories into the result.
   611:         for _, p := range listing.CollapsedRuns {
   612:                 pathBase := path.Base(p)
   613:                 dirName := NewDirName(d.Name(), pathBase)
   614:                 if c, ok := cores[dirName]; ok && c.Type() == metadata.ExplicitDirType {
   615:                         continue
   616:                 }
   617:
   618:                 implicitDir := &Core{
   619:                         Bucket:    d.Bucket(),
   620:                         FullName:  dirName,
   621:                         MinObject: nil,
   622:                 }
   623:                 cores[dirName] = implicitDir
   624:         }
   625:         return
   626: }
   627:
   628: func (d *dirInode) ReadEntries(
   629:         ctx context.Context,
   630:         tok string) (entries []fuseutil.Dirent, newTok string, err error) {
   631:         var cores map[Name]*Core
   632:         cores, newTok, err = d.readObjects(ctx, tok)
   633:         if err != nil {
   634:                 err = fmt.Errorf("read objects: %w", err)
   635:                 return
   636:         }
   637:
   638:         for fullName, core := range cores {
   639:                 entry := fuseutil.Dirent{
   640:                         Name: path.Base(fullName.LocalName()),
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
   643:                 switch core.Type() {
   644:                 case metadata.SymlinkType:
(dlv) p cores
map[github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Name]*github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Core []
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:606 (PC: 0x194724d)
   566:         defer func() {
   567:                 now := d.cacheClock.Now()
   568:                 for fullName, c := range cores {
   569:                         d.cache.Insert(now, path.Base(fullName.LocalName()), c.Type())
   570:                 }
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
   588:                                 FullName:  dirName,
   589:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   590:                         }
   591:                         cores[dirName] = explicitDir
   592:                 } else {
   593:                         fileName := NewFileName(d.Name(), nameBase)
   594:                         file := &Core{
   595:                                 Bucket:    d.Bucket(),
   596:                                 FullName:  fileName,
   597:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   598:                         }
   599:                         cores[fileName] = file
   600:                 }
   601:         }
   602:
   603:         // Return an appropriate continuation token, if any.
   604:         newTok = listing.ContinuationToken
   605:
=> 606:         if !d.implicitDirs {
   607:                 return
   608:         }
   609:
   610:         // Add implicit directories into the result.
   611:         for _, p := range listing.CollapsedRuns {
   612:                 pathBase := path.Base(p)
   613:                 dirName := NewDirName(d.Name(), pathBase)
   614:                 if c, ok := cores[dirName]; ok && c.Type() == metadata.ExplicitDirType {
   615:                         continue
   616:                 }
   617:
   618:                 implicitDir := &Core{
   619:                         Bucket:    d.Bucket(),
   620:                         FullName:  dirName,
   621:                         MinObject: nil,
   622:                 }
   623:                 cores[dirName] = implicitDir
   624:         }
   625:         return
   626: }
   627:
   628: func (d *dirInode) ReadEntries(
   629:         ctx context.Context,
   630:         tok string) (entries []fuseutil.Dirent, newTok string, err error) {
   631:         var cores map[Name]*Core
   632:         cores, newTok, err = d.readObjects(ctx, tok)
   633:         if err != nil {
   634:                 err = fmt.Errorf("read objects: %w", err)
   635:                 return
   636:         }
   637:
   638:         for fullName, core := range cores {
   639:                 entry := fuseutil.Dirent{
   640:                         Name: path.Base(fullName.LocalName()),
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
   643:                 switch core.Type() {
   644:                 case metadata.SymlinkType:
   645:                         entry.Type = fuseutil.DT_Link
   646:                 case metadata.RegularFileType:
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:611 (PC: 0x194725f)
   571:         }()
   572:
   573:         for _, o := range listing.Objects {
   574:                 // Skip empty results or the directory object backing this inode.
   575:                 if o.Name == d.Name().GcsObjectName() || o.Name == "" {
   576:                         continue
   577:                 }
   578:
   579:                 nameBase := path.Base(o.Name) // ie. "bar" from "foo/bar/" or "foo/bar"
   580:
   581:                 // Given the alphabetical order of the objects, if a file "foo" and
   582:                 // directory "foo/" coexist, the directory would eventually occupy
   583:                 // the value of records["foo"].
   584:                 if strings.HasSuffix(o.Name, "/") {
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
   588:                                 FullName:  dirName,
   589:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   590:                         }
   591:                         cores[dirName] = explicitDir
   592:                 } else {
   593:                         fileName := NewFileName(d.Name(), nameBase)
   594:                         file := &Core{
   595:                                 Bucket:    d.Bucket(),
   596:                                 FullName:  fileName,
   597:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   598:                         }
   599:                         cores[fileName] = file
   600:                 }
   601:         }
   602:
   603:         // Return an appropriate continuation token, if any.
   604:         newTok = listing.ContinuationToken
   605:
   606:         if !d.implicitDirs {
   607:                 return
   608:         }
   609:
   610:         // Add implicit directories into the result.
=> 611:         for _, p := range listing.CollapsedRuns {
   612:                 pathBase := path.Base(p)
   613:                 dirName := NewDirName(d.Name(), pathBase)
   614:                 if c, ok := cores[dirName]; ok && c.Type() == metadata.ExplicitDirType {
   615:                         continue
   616:                 }
   617:
   618:                 implicitDir := &Core{
   619:                         Bucket:    d.Bucket(),
   620:                         FullName:  dirName,
   621:                         MinObject: nil,
   622:                 }
   623:                 cores[dirName] = implicitDir
   624:         }
   625:         return
   626: }
   627:
   628: func (d *dirInode) ReadEntries(
   629:         ctx context.Context,
   630:         tok string) (entries []fuseutil.Dirent, newTok string, err error) {
   631:         var cores map[Name]*Core
   632:         cores, newTok, err = d.readObjects(ctx, tok)
   633:         if err != nil {
   634:                 err = fmt.Errorf("read objects: %w", err)
   635:                 return
   636:         }
   637:
   638:         for fullName, core := range cores {
   639:                 entry := fuseutil.Dirent{
   640:                         Name: path.Base(fullName.LocalName()),
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
   643:                 switch core.Type() {
   644:                 case metadata.SymlinkType:
   645:                         entry.Type = fuseutil.DT_Link
   646:                 case metadata.RegularFileType:
   647:                         entry.Type = fuseutil.DT_File
   648:                 case metadata.ImplicitDirType, metadata.ExplicitDirType:
   649:                         entry.Type = fuseutil.DT_Directory
   650:                 }
   651:                 entries = append(entries, entry)
(dlv) p listing.CollapsedRuns
[]string len: 0, cap: 0, nil
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).readObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:625 (PC: 0x1947658)
   585:                         dirName := NewDirName(d.Name(), nameBase)
   586:                         explicitDir := &Core{
   587:                                 Bucket:    d.Bucket(),
   588:                                 FullName:  dirName,
   589:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   590:                         }
   591:                         cores[dirName] = explicitDir
   592:                 } else {
   593:                         fileName := NewFileName(d.Name(), nameBase)
   594:                         file := &Core{
   595:                                 Bucket:    d.Bucket(),
   596:                                 FullName:  fileName,
   597:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   598:                         }
   599:                         cores[fileName] = file
   600:                 }
   601:         }
   602:
   603:         // Return an appropriate continuation token, if any.
   604:         newTok = listing.ContinuationToken
   605:
   606:         if !d.implicitDirs {
   607:                 return
   608:         }
   609:
   610:         // Add implicit directories into the result.
   611:         for _, p := range listing.CollapsedRuns {
   612:                 pathBase := path.Base(p)
   613:                 dirName := NewDirName(d.Name(), pathBase)
   614:                 if c, ok := cores[dirName]; ok && c.Type() == metadata.ExplicitDirType {
   615:                         continue
   616:                 }
   617:
   618:                 implicitDir := &Core{
   619:                         Bucket:    d.Bucket(),
   620:                         FullName:  dirName,
   621:                         MinObject: nil,
   622:                 }
   623:                 cores[dirName] = implicitDir
   624:         }
=> 625:         return
   626: }
   627:
   628: func (d *dirInode) ReadEntries(
   629:         ctx context.Context,
   630:         tok string) (entries []fuseutil.Dirent, newTok string, err error) {
   631:         var cores map[Name]*Core
   632:         cores, newTok, err = d.readObjects(ctx, tok)
   633:         if err != nil {
   634:                 err = fmt.Errorf("read objects: %w", err)
   635:                 return
   636:         }
   637:
   638:         for fullName, core := range cores {
   639:                 entry := fuseutil.Dirent{
   640:                         Name: path.Base(fullName.LocalName()),
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
   643:                 switch core.Type() {
   644:                 case metadata.SymlinkType:
   645:                         entry.Type = fuseutil.DT_Link
   646:                 case metadata.RegularFileType:
   647:                         entry.Type = fuseutil.DT_File
   648:                 case metadata.ImplicitDirType, metadata.ExplicitDirType:
   649:                         entry.Type = fuseutil.DT_Directory
   650:                 }
   651:                 entries = append(entries, entry)
   652:         }
   653:         return
   654: }
   655:
   656: // LOCKS_REQUIRED(d)
   657: func (d *dirInode) CreateChildFile(ctx context.Context, name string) (*Core, error) {
   658:         childMetadata := map[string]string{
   659:                 FileMtimeMetadataKey: d.mtimeClock.Now().UTC().Format(time.RFC3339Nano),
   660:         }
   661:         fullName := NewFileName(d.Name(), name)
   662:
   663:         o, err := d.createNewObject(ctx, fullName, childMetadata)
   664:         if err != nil {
   665:                 return nil, err
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:632 (PC: 0x1947985)
Values returned:
        cores: map[github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Name]*github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.Core []
        newTok: ""
        err: error nil

   592:                 } else {
   593:                         fileName := NewFileName(d.Name(), nameBase)
   594:                         file := &Core{
   595:                                 Bucket:    d.Bucket(),
   596:                                 FullName:  fileName,
   597:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   598:                         }
   599:                         cores[fileName] = file
   600:                 }
   601:         }
   602:
   603:         // Return an appropriate continuation token, if any.
   604:         newTok = listing.ContinuationToken
   605:
   606:         if !d.implicitDirs {
   607:                 return
   608:         }
   609:
   610:         // Add implicit directories into the result.
   611:         for _, p := range listing.CollapsedRuns {
   612:                 pathBase := path.Base(p)
   613:                 dirName := NewDirName(d.Name(), pathBase)
   614:                 if c, ok := cores[dirName]; ok && c.Type() == metadata.ExplicitDirType {
   615:                         continue
   616:                 }
   617:
   618:                 implicitDir := &Core{
   619:                         Bucket:    d.Bucket(),
   620:                         FullName:  dirName,
   621:                         MinObject: nil,
   622:                 }
   623:                 cores[dirName] = implicitDir
   624:         }
   625:         return
   626: }
   627:
   628: func (d *dirInode) ReadEntries(
   629:         ctx context.Context,
   630:         tok string) (entries []fuseutil.Dirent, newTok string, err error) {
   631:         var cores map[Name]*Core
=> 632:         cores, newTok, err = d.readObjects(ctx, tok)
   633:         if err != nil {
   634:                 err = fmt.Errorf("read objects: %w", err)
   635:                 return
   636:         }
   637:
   638:         for fullName, core := range cores {
   639:                 entry := fuseutil.Dirent{
   640:                         Name: path.Base(fullName.LocalName()),
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
   643:                 switch core.Type() {
   644:                 case metadata.SymlinkType:
   645:                         entry.Type = fuseutil.DT_Link
   646:                 case metadata.RegularFileType:
   647:                         entry.Type = fuseutil.DT_File
   648:                 case metadata.ImplicitDirType, metadata.ExplicitDirType:
   649:                         entry.Type = fuseutil.DT_Directory
   650:                 }
   651:                 entries = append(entries, entry)
   652:         }
   653:         return
   654: }
   655:
   656: // LOCKS_REQUIRED(d)
   657: func (d *dirInode) CreateChildFile(ctx context.Context, name string) (*Core, error) {
   658:         childMetadata := map[string]string{
   659:                 FileMtimeMetadataKey: d.mtimeClock.Now().UTC().Format(time.RFC3339Nano),
   660:         }
   661:         fullName := NewFileName(d.Name(), name)
   662:
   663:         o, err := d.createNewObject(ctx, fullName, childMetadata)
   664:         if err != nil {
   665:                 return nil, err
   666:         }
   667:         m := storageutil.ConvertObjToMinObject(o)
   668:
   669:         d.cache.Insert(d.cacheClock.Now(), name, metadata.RegularFileType)
   670:         return &Core{
   671:                 Bucket:    d.Bucket(),
   672:                 FullName:  fullName,
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:633 (PC: 0x1947a47)
   593:                         fileName := NewFileName(d.Name(), nameBase)
   594:                         file := &Core{
   595:                                 Bucket:    d.Bucket(),
   596:                                 FullName:  fileName,
   597:                                 MinObject: storageutil.ConvertObjToMinObject(o),
   598:                         }
   599:                         cores[fileName] = file
   600:                 }
   601:         }
   602:
   603:         // Return an appropriate continuation token, if any.
   604:         newTok = listing.ContinuationToken
   605:
   606:         if !d.implicitDirs {
   607:                 return
   608:         }
   609:
   610:         // Add implicit directories into the result.
   611:         for _, p := range listing.CollapsedRuns {
   612:                 pathBase := path.Base(p)
   613:                 dirName := NewDirName(d.Name(), pathBase)
   614:                 if c, ok := cores[dirName]; ok && c.Type() == metadata.ExplicitDirType {
   615:                         continue
   616:                 }
   617:
   618:                 implicitDir := &Core{
   619:                         Bucket:    d.Bucket(),
   620:                         FullName:  dirName,
   621:                         MinObject: nil,
   622:                 }
   623:                 cores[dirName] = implicitDir
   624:         }
   625:         return
   626: }
   627:
   628: func (d *dirInode) ReadEntries(
   629:         ctx context.Context,
   630:         tok string) (entries []fuseutil.Dirent, newTok string, err error) {
   631:         var cores map[Name]*Core
   632:         cores, newTok, err = d.readObjects(ctx, tok)
=> 633:         if err != nil {
   634:                 err = fmt.Errorf("read objects: %w", err)
   635:                 return
   636:         }
   637:
   638:         for fullName, core := range cores {
   639:                 entry := fuseutil.Dirent{
   640:                         Name: path.Base(fullName.LocalName()),
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
   643:                 switch core.Type() {
   644:                 case metadata.SymlinkType:
   645:                         entry.Type = fuseutil.DT_Link
   646:                 case metadata.RegularFileType:
   647:                         entry.Type = fuseutil.DT_File
   648:                 case metadata.ImplicitDirType, metadata.ExplicitDirType:
   649:                         entry.Type = fuseutil.DT_Directory
   650:                 }
   651:                 entries = append(entries, entry)
   652:         }
   653:         return
   654: }
   655:
   656: // LOCKS_REQUIRED(d)
   657: func (d *dirInode) CreateChildFile(ctx context.Context, name string) (*Core, error) {
   658:         childMetadata := map[string]string{
   659:                 FileMtimeMetadataKey: d.mtimeClock.Now().UTC().Format(time.RFC3339Nano),
   660:         }
   661:         fullName := NewFileName(d.Name(), name)
   662:
   663:         o, err := d.createNewObject(ctx, fullName, childMetadata)
   664:         if err != nil {
   665:                 return nil, err
   666:         }
   667:         m := storageutil.ConvertObjToMinObject(o)
   668:
   669:         d.cache.Insert(d.cacheClock.Now(), name, metadata.RegularFileType)
   670:         return &Core{
   671:                 Bucket:    d.Bucket(),
   672:                 FullName:  fullName,
   673:                 MinObject: m,
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:638 (PC: 0x1947b84)
   598:                         }
   599:                         cores[fileName] = file
   600:                 }
   601:         }
   602:
   603:         // Return an appropriate continuation token, if any.
   604:         newTok = listing.ContinuationToken
   605:
   606:         if !d.implicitDirs {
   607:                 return
   608:         }
   609:
   610:         // Add implicit directories into the result.
   611:         for _, p := range listing.CollapsedRuns {
   612:                 pathBase := path.Base(p)
   613:                 dirName := NewDirName(d.Name(), pathBase)
   614:                 if c, ok := cores[dirName]; ok && c.Type() == metadata.ExplicitDirType {
   615:                         continue
   616:                 }
   617:
   618:                 implicitDir := &Core{
   619:                         Bucket:    d.Bucket(),
   620:                         FullName:  dirName,
   621:                         MinObject: nil,
   622:                 }
   623:                 cores[dirName] = implicitDir
   624:         }
   625:         return
   626: }
   627:
   628: func (d *dirInode) ReadEntries(
   629:         ctx context.Context,
   630:         tok string) (entries []fuseutil.Dirent, newTok string, err error) {
   631:         var cores map[Name]*Core
   632:         cores, newTok, err = d.readObjects(ctx, tok)
   633:         if err != nil {
   634:                 err = fmt.Errorf("read objects: %w", err)
   635:                 return
   636:         }
   637:
=> 638:         for fullName, core := range cores {
   639:                 entry := fuseutil.Dirent{
   640:                         Name: path.Base(fullName.LocalName()),
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
   643:                 switch core.Type() {
   644:                 case metadata.SymlinkType:
   645:                         entry.Type = fuseutil.DT_Link
   646:                 case metadata.RegularFileType:
   647:                         entry.Type = fuseutil.DT_File
   648:                 case metadata.ImplicitDirType, metadata.ExplicitDirType:
   649:                         entry.Type = fuseutil.DT_Directory
   650:                 }
   651:                 entries = append(entries, entry)
   652:         }
   653:         return
   654: }
   655:
   656: // LOCKS_REQUIRED(d)
   657: func (d *dirInode) CreateChildFile(ctx context.Context, name string) (*Core, error) {
   658:         childMetadata := map[string]string{
   659:                 FileMtimeMetadataKey: d.mtimeClock.Now().UTC().Format(time.RFC3339Nano),
   660:         }
   661:         fullName := NewFileName(d.Name(), name)
   662:
   663:         o, err := d.createNewObject(ctx, fullName, childMetadata)
   664:         if err != nil {
   665:                 return nil, err
   666:         }
   667:         m := storageutil.ConvertObjToMinObject(o)
   668:
   669:         d.cache.Insert(d.cacheClock.Now(), name, metadata.RegularFileType)
   670:         return &Core{
   671:                 Bucket:    d.Bucket(),
   672:                 FullName:  fullName,
   673:                 MinObject: m,
   674:         }, nil
   675: }
   676:
   677: func (d *dirInode) CreateLocalChildFile(name string) (*Core, error) {
   678:         fullName := NewFileName(d.Name(), name)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/inode.(*dirInode).ReadEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/inode/dir.go:653 (PC: 0x1947e25)
   613:                 dirName := NewDirName(d.Name(), pathBase)
   614:                 if c, ok := cores[dirName]; ok && c.Type() == metadata.ExplicitDirType {
   615:                         continue
   616:                 }
   617:
   618:                 implicitDir := &Core{
   619:                         Bucket:    d.Bucket(),
   620:                         FullName:  dirName,
   621:                         MinObject: nil,
   622:                 }
   623:                 cores[dirName] = implicitDir
   624:         }
   625:         return
   626: }
   627:
   628: func (d *dirInode) ReadEntries(
   629:         ctx context.Context,
   630:         tok string) (entries []fuseutil.Dirent, newTok string, err error) {
   631:         var cores map[Name]*Core
   632:         cores, newTok, err = d.readObjects(ctx, tok)
   633:         if err != nil {
   634:                 err = fmt.Errorf("read objects: %w", err)
   635:                 return
   636:         }
   637:
   638:         for fullName, core := range cores {
   639:                 entry := fuseutil.Dirent{
   640:                         Name: path.Base(fullName.LocalName()),
   641:                         Type: fuseutil.DT_Unknown,
   642:                 }
   643:                 switch core.Type() {
   644:                 case metadata.SymlinkType:
   645:                         entry.Type = fuseutil.DT_Link
   646:                 case metadata.RegularFileType:
   647:                         entry.Type = fuseutil.DT_File
   648:                 case metadata.ImplicitDirType, metadata.ExplicitDirType:
   649:                         entry.Type = fuseutil.DT_Directory
   650:                 }
   651:                 entries = append(entries, entry)
   652:         }
=> 653:         return
   654: }
   655:
   656: // LOCKS_REQUIRED(d)
   657: func (d *dirInode) CreateChildFile(ctx context.Context, name string) (*Core, error) {
   658:         childMetadata := map[string]string{
   659:                 FileMtimeMetadataKey: d.mtimeClock.Now().UTC().Format(time.RFC3339Nano),
   660:         }
   661:         fullName := NewFileName(d.Name(), name)
   662:
   663:         o, err := d.createNewObject(ctx, fullName, childMetadata)
   664:         if err != nil {
   665:                 return nil, err
   666:         }
   667:         m := storageutil.ConvertObjToMinObject(o)
   668:
   669:         d.cache.Insert(d.cacheClock.Now(), name, metadata.RegularFileType)
   670:         return &Core{
   671:                 Bucket:    d.Bucket(),
   672:                 FullName:  fullName,
   673:                 MinObject: m,
   674:         }, nil
   675: }
   676:
   677: func (d *dirInode) CreateLocalChildFile(name string) (*Core, error) {
   678:         fullName := NewFileName(d.Name(), name)
   679:
   680:         return &Core{
   681:                 Bucket:    d.Bucket(),
   682:                 FullName:  fullName,
   683:                 MinObject: nil,
   684:                 Local:     true,
   685:         }, nil
   686: }
   687:
   688: // LOCKS_REQUIRED(d)
   689: func (d *dirInode) CloneToChildFile(ctx context.Context, name string, src *gcs.MinObject) (*Core, error) {
   690:         // Erase any existing type information for this name.
   691:         d.cache.Erase(name)
   692:         fullName := NewFileName(d.Name(), name)
   693:
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:172 (PC: 0x1954e6b)
Values returned:
        entries: []github.com/jacobsa/fuse/fuseutil.Dirent len: 0, cap: 0, nil
        newTok: ""
        err: error nil

   132:                 // We expect exactly one to be a directory.
   133:                 eIsDir := e.Type == fuseutil.DT_Directory
   134:                 prevIsDir := prev.Type == fuseutil.DT_Directory
   135:
   136:                 if eIsDir == prevIsDir {
   137:                         err = fmt.Errorf(
   138:                                 "weird dirent type pair for name %q: %v, %v",
   139:                                 e.Name,
   140:                                 e.Type,
   141:                                 prev.Type)
   142:
   143:                         return
   144:                 }
   145:
   146:                 // Repair whichever is not the directory.
   147:                 if eIsDir {
   148:                         prev.Name += inode.ConflictingFileNameSuffix
   149:                 } else {
   150:                         e.Name += inode.ConflictingFileNameSuffix
   151:                 }
   152:         }
   153:
   154:         return
   155: }
   156:
   157: // Read all entries for the directory, fix up conflicting names, and fill in
   158: // offset fields.
   159: //
   160: // LOCKS_REQUIRED(in)
   161: func readAllEntries(
   162:         ctx context.Context,
   163:         in inode.DirInode,
   164:         localEntries []fuseutil.Dirent) (entries []fuseutil.Dirent, err error) {
   165:         // Read entries from GCS.
   166:         // Read one batch at a time.
   167:         var tok string
   168:         for {
   169:                 // Read a batch.
   170:                 var batch []fuseutil.Dirent
   171:
=> 172:                 batch, tok, err = in.ReadEntries(ctx, tok)
   173:                 if err != nil {
   174:                         err = fmt.Errorf("ReadEntries: %w", err)
   175:                         return
   176:                 }
   177:
   178:                 // Accumulate.
   179:                 entries = append(entries, batch...)
   180:
   181:                 // Are we done?
   182:                 if tok == "" {
   183:                         break
   184:                 }
   185:         }
   186:
   187:         // Append local file entries (not synced to GCS).
   188:         entries = append(entries, localEntries...)
   189:
   190:         // Ensure that the entries are sorted, for use in fixConflictingNames
   191:         // below.
   192:         sort.Sort(sortedDirents(entries))
   193:
   194:         // Fix name conflicts.
   195:         // When a local file is synced to GCS but not removed from the local file map,
   196:         // the entries list will have two duplicate entries.
   197:         // To handle this scenario, we had 2 options:
   198:         // Option 1: [Selected]
   199:         // Throw an error while fixing conflicting names. The error will be fixed in
   200:         // subsequent ls calls assuming that entry will be removed from localFileInodes.
   201:         // Option 2: [Not Selected]
   202:         // Restrict fixConflictingNames to only GCS entries and show duplicate
   203:         // entries when ReadDir is called. In this case, a local file can have
   204:         // same name as directory and LookUpInode call will fetch directory details
   205:         // for both of them.
   206:         err = fixConflictingNames(entries)
   207:         if err != nil {
   208:                 err = fmt.Errorf("fixConflictingNames: %w", err)
   209:                 return
   210:         }
   211:
   212:         // Fix up offset fields.
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:173 (PC: 0x1954f77)
   133:                 eIsDir := e.Type == fuseutil.DT_Directory
   134:                 prevIsDir := prev.Type == fuseutil.DT_Directory
   135:
   136:                 if eIsDir == prevIsDir {
   137:                         err = fmt.Errorf(
   138:                                 "weird dirent type pair for name %q: %v, %v",
   139:                                 e.Name,
   140:                                 e.Type,
   141:                                 prev.Type)
   142:
   143:                         return
   144:                 }
   145:
   146:                 // Repair whichever is not the directory.
   147:                 if eIsDir {
   148:                         prev.Name += inode.ConflictingFileNameSuffix
   149:                 } else {
   150:                         e.Name += inode.ConflictingFileNameSuffix
   151:                 }
   152:         }
   153:
   154:         return
   155: }
   156:
   157: // Read all entries for the directory, fix up conflicting names, and fill in
   158: // offset fields.
   159: //
   160: // LOCKS_REQUIRED(in)
   161: func readAllEntries(
   162:         ctx context.Context,
   163:         in inode.DirInode,
   164:         localEntries []fuseutil.Dirent) (entries []fuseutil.Dirent, err error) {
   165:         // Read entries from GCS.
   166:         // Read one batch at a time.
   167:         var tok string
   168:         for {
   169:                 // Read a batch.
   170:                 var batch []fuseutil.Dirent
   171:
   172:                 batch, tok, err = in.ReadEntries(ctx, tok)
=> 173:                 if err != nil {
   174:                         err = fmt.Errorf("ReadEntries: %w", err)
   175:                         return
   176:                 }
   177:
   178:                 // Accumulate.
   179:                 entries = append(entries, batch...)
   180:
   181:                 // Are we done?
   182:                 if tok == "" {
   183:                         break
   184:                 }
   185:         }
   186:
   187:         // Append local file entries (not synced to GCS).
   188:         entries = append(entries, localEntries...)
   189:
   190:         // Ensure that the entries are sorted, for use in fixConflictingNames
   191:         // below.
   192:         sort.Sort(sortedDirents(entries))
   193:
   194:         // Fix name conflicts.
   195:         // When a local file is synced to GCS but not removed from the local file map,
   196:         // the entries list will have two duplicate entries.
   197:         // To handle this scenario, we had 2 options:
   198:         // Option 1: [Selected]
   199:         // Throw an error while fixing conflicting names. The error will be fixed in
   200:         // subsequent ls calls assuming that entry will be removed from localFileInodes.
   201:         // Option 2: [Not Selected]
   202:         // Restrict fixConflictingNames to only GCS entries and show duplicate
   203:         // entries when ReadDir is called. In this case, a local file can have
   204:         // same name as directory and LookUpInode call will fetch directory details
   205:         // for both of them.
   206:         err = fixConflictingNames(entries)
   207:         if err != nil {
   208:                 err = fmt.Errorf("fixConflictingNames: %w", err)
   209:                 return
   210:         }
   211:
   212:         // Fix up offset fields.
   213:         for i := 0; i < len(entries); i++ {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:179 (PC: 0x19550a2)
   139:                                 e.Name,
   140:                                 e.Type,
   141:                                 prev.Type)
   142:
   143:                         return
   144:                 }
   145:
   146:                 // Repair whichever is not the directory.
   147:                 if eIsDir {
   148:                         prev.Name += inode.ConflictingFileNameSuffix
   149:                 } else {
   150:                         e.Name += inode.ConflictingFileNameSuffix
   151:                 }
   152:         }
   153:
   154:         return
   155: }
   156:
   157: // Read all entries for the directory, fix up conflicting names, and fill in
   158: // offset fields.
   159: //
   160: // LOCKS_REQUIRED(in)
   161: func readAllEntries(
   162:         ctx context.Context,
   163:         in inode.DirInode,
   164:         localEntries []fuseutil.Dirent) (entries []fuseutil.Dirent, err error) {
   165:         // Read entries from GCS.
   166:         // Read one batch at a time.
   167:         var tok string
   168:         for {
   169:                 // Read a batch.
   170:                 var batch []fuseutil.Dirent
   171:
   172:                 batch, tok, err = in.ReadEntries(ctx, tok)
   173:                 if err != nil {
   174:                         err = fmt.Errorf("ReadEntries: %w", err)
   175:                         return
   176:                 }
   177:
   178:                 // Accumulate.
=> 179:                 entries = append(entries, batch...)
   180:
   181:                 // Are we done?
   182:                 if tok == "" {
   183:                         break
   184:                 }
   185:         }
   186:
   187:         // Append local file entries (not synced to GCS).
   188:         entries = append(entries, localEntries...)
   189:
   190:         // Ensure that the entries are sorted, for use in fixConflictingNames
   191:         // below.
   192:         sort.Sort(sortedDirents(entries))
   193:
   194:         // Fix name conflicts.
   195:         // When a local file is synced to GCS but not removed from the local file map,
   196:         // the entries list will have two duplicate entries.
   197:         // To handle this scenario, we had 2 options:
   198:         // Option 1: [Selected]
   199:         // Throw an error while fixing conflicting names. The error will be fixed in
   200:         // subsequent ls calls assuming that entry will be removed from localFileInodes.
   201:         // Option 2: [Not Selected]
   202:         // Restrict fixConflictingNames to only GCS entries and show duplicate
   203:         // entries when ReadDir is called. In this case, a local file can have
   204:         // same name as directory and LookUpInode call will fetch directory details
   205:         // for both of them.
   206:         err = fixConflictingNames(entries)
   207:         if err != nil {
   208:                 err = fmt.Errorf("fixConflictingNames: %w", err)
   209:                 return
   210:         }
   211:
   212:         // Fix up offset fields.
   213:         for i := 0; i < len(entries); i++ {
   214:                 entries[i].Offset = fuseops.DirOffset(i) + 1
   215:         }
   216:
   217:         // Return a bogus inode ID for each entry, but not the root inode ID.
   218:         //
   219:         // NOTE: As far as I can tell this is harmless. Minting and
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:188 (PC: 0x19551ae)
   148:                         prev.Name += inode.ConflictingFileNameSuffix
   149:                 } else {
   150:                         e.Name += inode.ConflictingFileNameSuffix
   151:                 }
   152:         }
   153:
   154:         return
   155: }
   156:
   157: // Read all entries for the directory, fix up conflicting names, and fill in
   158: // offset fields.
   159: //
   160: // LOCKS_REQUIRED(in)
   161: func readAllEntries(
   162:         ctx context.Context,
   163:         in inode.DirInode,
   164:         localEntries []fuseutil.Dirent) (entries []fuseutil.Dirent, err error) {
   165:         // Read entries from GCS.
   166:         // Read one batch at a time.
   167:         var tok string
   168:         for {
   169:                 // Read a batch.
   170:                 var batch []fuseutil.Dirent
   171:
   172:                 batch, tok, err = in.ReadEntries(ctx, tok)
   173:                 if err != nil {
   174:                         err = fmt.Errorf("ReadEntries: %w", err)
   175:                         return
   176:                 }
   177:
   178:                 // Accumulate.
   179:                 entries = append(entries, batch...)
   180:
   181:                 // Are we done?
   182:                 if tok == "" {
   183:                         break
   184:                 }
   185:         }
   186:
   187:         // Append local file entries (not synced to GCS).
=> 188:         entries = append(entries, localEntries...)
   189:
   190:         // Ensure that the entries are sorted, for use in fixConflictingNames
   191:         // below.
   192:         sort.Sort(sortedDirents(entries))
   193:
   194:         // Fix name conflicts.
   195:         // When a local file is synced to GCS but not removed from the local file map,
   196:         // the entries list will have two duplicate entries.
   197:         // To handle this scenario, we had 2 options:
   198:         // Option 1: [Selected]
   199:         // Throw an error while fixing conflicting names. The error will be fixed in
   200:         // subsequent ls calls assuming that entry will be removed from localFileInodes.
   201:         // Option 2: [Not Selected]
   202:         // Restrict fixConflictingNames to only GCS entries and show duplicate
   203:         // entries when ReadDir is called. In this case, a local file can have
   204:         // same name as directory and LookUpInode call will fetch directory details
   205:         // for both of them.
   206:         err = fixConflictingNames(entries)
   207:         if err != nil {
   208:                 err = fmt.Errorf("fixConflictingNames: %w", err)
   209:                 return
   210:         }
   211:
   212:         // Fix up offset fields.
   213:         for i := 0; i < len(entries); i++ {
   214:                 entries[i].Offset = fuseops.DirOffset(i) + 1
   215:         }
   216:
   217:         // Return a bogus inode ID for each entry, but not the root inode ID.
   218:         //
   219:         // NOTE: As far as I can tell this is harmless. Minting and
   220:         // returning a real inode ID is difficult because fuse does not count
   221:         // readdir as an operation that increases the inode ID's lookup count, and
   222:         // we therefore don't get a forget for it later, but we would like to not
   223:         // have to remember every inode ID that we've ever minted for readdir.
   224:         //
   225:         // If it turns out this is not harmless, we'll need to switch to something
   226:         // like inode IDs based on (object name, generation) hashes. But then what
   227:         // about the birthday problem? And more importantly, what about our
   228:         // semantic of not minting a new inode ID when the generation changes due
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:182 (PC: 0x19551ce)
   142:
   143:                         return
   144:                 }
   145:
   146:                 // Repair whichever is not the directory.
   147:                 if eIsDir {
   148:                         prev.Name += inode.ConflictingFileNameSuffix
   149:                 } else {
   150:                         e.Name += inode.ConflictingFileNameSuffix
   151:                 }
   152:         }
   153:
   154:         return
   155: }
   156:
   157: // Read all entries for the directory, fix up conflicting names, and fill in
   158: // offset fields.
   159: //
   160: // LOCKS_REQUIRED(in)
   161: func readAllEntries(
   162:         ctx context.Context,
   163:         in inode.DirInode,
   164:         localEntries []fuseutil.Dirent) (entries []fuseutil.Dirent, err error) {
   165:         // Read entries from GCS.
   166:         // Read one batch at a time.
   167:         var tok string
   168:         for {
   169:                 // Read a batch.
   170:                 var batch []fuseutil.Dirent
   171:
   172:                 batch, tok, err = in.ReadEntries(ctx, tok)
   173:                 if err != nil {
   174:                         err = fmt.Errorf("ReadEntries: %w", err)
   175:                         return
   176:                 }
   177:
   178:                 // Accumulate.
   179:                 entries = append(entries, batch...)
   180:
   181:                 // Are we done?
=> 182:                 if tok == "" {
   183:                         break
   184:                 }
   185:         }
   186:
   187:         // Append local file entries (not synced to GCS).
   188:         entries = append(entries, localEntries...)
   189:
   190:         // Ensure that the entries are sorted, for use in fixConflictingNames
   191:         // below.
   192:         sort.Sort(sortedDirents(entries))
   193:
   194:         // Fix name conflicts.
   195:         // When a local file is synced to GCS but not removed from the local file map,
   196:         // the entries list will have two duplicate entries.
   197:         // To handle this scenario, we had 2 options:
   198:         // Option 1: [Selected]
   199:         // Throw an error while fixing conflicting names. The error will be fixed in
   200:         // subsequent ls calls assuming that entry will be removed from localFileInodes.
   201:         // Option 2: [Not Selected]
   202:         // Restrict fixConflictingNames to only GCS entries and show duplicate
   203:         // entries when ReadDir is called. In this case, a local file can have
   204:         // same name as directory and LookUpInode call will fetch directory details
   205:         // for both of them.
   206:         err = fixConflictingNames(entries)
   207:         if err != nil {
   208:                 err = fmt.Errorf("fixConflictingNames: %w", err)
   209:                 return
   210:         }
   211:
   212:         // Fix up offset fields.
   213:         for i := 0; i < len(entries); i++ {
   214:                 entries[i].Offset = fuseops.DirOffset(i) + 1
   215:         }
   216:
   217:         // Return a bogus inode ID for each entry, but not the root inode ID.
   218:         //
   219:         // NOTE: As far as I can tell this is harmless. Minting and
   220:         // returning a real inode ID is difficult because fuse does not count
   221:         // readdir as an operation that increases the inode ID's lookup count, and
   222:         // we therefore don't get a forget for it later, but we would like to not
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:183 (PC: 0x19551db)
   143:                         return
   144:                 }
   145:
   146:                 // Repair whichever is not the directory.
   147:                 if eIsDir {
   148:                         prev.Name += inode.ConflictingFileNameSuffix
   149:                 } else {
   150:                         e.Name += inode.ConflictingFileNameSuffix
   151:                 }
   152:         }
   153:
   154:         return
   155: }
   156:
   157: // Read all entries for the directory, fix up conflicting names, and fill in
   158: // offset fields.
   159: //
   160: // LOCKS_REQUIRED(in)
   161: func readAllEntries(
   162:         ctx context.Context,
   163:         in inode.DirInode,
   164:         localEntries []fuseutil.Dirent) (entries []fuseutil.Dirent, err error) {
   165:         // Read entries from GCS.
   166:         // Read one batch at a time.
   167:         var tok string
   168:         for {
   169:                 // Read a batch.
   170:                 var batch []fuseutil.Dirent
   171:
   172:                 batch, tok, err = in.ReadEntries(ctx, tok)
   173:                 if err != nil {
   174:                         err = fmt.Errorf("ReadEntries: %w", err)
   175:                         return
   176:                 }
   177:
   178:                 // Accumulate.
   179:                 entries = append(entries, batch...)
   180:
   181:                 // Are we done?
   182:                 if tok == "" {
=> 183:                         break
   184:                 }
   185:         }
   186:
   187:         // Append local file entries (not synced to GCS).
   188:         entries = append(entries, localEntries...)
   189:
   190:         // Ensure that the entries are sorted, for use in fixConflictingNames
   191:         // below.
   192:         sort.Sort(sortedDirents(entries))
   193:
   194:         // Fix name conflicts.
   195:         // When a local file is synced to GCS but not removed from the local file map,
   196:         // the entries list will have two duplicate entries.
   197:         // To handle this scenario, we had 2 options:
   198:         // Option 1: [Selected]
   199:         // Throw an error while fixing conflicting names. The error will be fixed in
   200:         // subsequent ls calls assuming that entry will be removed from localFileInodes.
   201:         // Option 2: [Not Selected]
   202:         // Restrict fixConflictingNames to only GCS entries and show duplicate
   203:         // entries when ReadDir is called. In this case, a local file can have
   204:         // same name as directory and LookUpInode call will fetch directory details
   205:         // for both of them.
   206:         err = fixConflictingNames(entries)
   207:         if err != nil {
   208:                 err = fmt.Errorf("fixConflictingNames: %w", err)
   209:                 return
   210:         }
   211:
   212:         // Fix up offset fields.
   213:         for i := 0; i < len(entries); i++ {
   214:                 entries[i].Offset = fuseops.DirOffset(i) + 1
   215:         }
   216:
   217:         // Return a bogus inode ID for each entry, but not the root inode ID.
   218:         //
   219:         // NOTE: As far as I can tell this is harmless. Minting and
   220:         // returning a real inode ID is difficult because fuse does not count
   221:         // readdir as an operation that increases the inode ID's lookup count, and
   222:         // we therefore don't get a forget for it later, but we would like to not
   223:         // have to remember every inode ID that we've ever minted for readdir.
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:188 (PC: 0x19551dd)
   148:                         prev.Name += inode.ConflictingFileNameSuffix
   149:                 } else {
   150:                         e.Name += inode.ConflictingFileNameSuffix
   151:                 }
   152:         }
   153:
   154:         return
   155: }
   156:
   157: // Read all entries for the directory, fix up conflicting names, and fill in
   158: // offset fields.
   159: //
   160: // LOCKS_REQUIRED(in)
   161: func readAllEntries(
   162:         ctx context.Context,
   163:         in inode.DirInode,
   164:         localEntries []fuseutil.Dirent) (entries []fuseutil.Dirent, err error) {
   165:         // Read entries from GCS.
   166:         // Read one batch at a time.
   167:         var tok string
   168:         for {
   169:                 // Read a batch.
   170:                 var batch []fuseutil.Dirent
   171:
   172:                 batch, tok, err = in.ReadEntries(ctx, tok)
   173:                 if err != nil {
   174:                         err = fmt.Errorf("ReadEntries: %w", err)
   175:                         return
   176:                 }
   177:
   178:                 // Accumulate.
   179:                 entries = append(entries, batch...)
   180:
   181:                 // Are we done?
   182:                 if tok == "" {
   183:                         break
   184:                 }
   185:         }
   186:
   187:         // Append local file entries (not synced to GCS).
=> 188:         entries = append(entries, localEntries...)
   189:
   190:         // Ensure that the entries are sorted, for use in fixConflictingNames
   191:         // below.
   192:         sort.Sort(sortedDirents(entries))
   193:
   194:         // Fix name conflicts.
   195:         // When a local file is synced to GCS but not removed from the local file map,
   196:         // the entries list will have two duplicate entries.
   197:         // To handle this scenario, we had 2 options:
   198:         // Option 1: [Selected]
   199:         // Throw an error while fixing conflicting names. The error will be fixed in
   200:         // subsequent ls calls assuming that entry will be removed from localFileInodes.
   201:         // Option 2: [Not Selected]
   202:         // Restrict fixConflictingNames to only GCS entries and show duplicate
   203:         // entries when ReadDir is called. In this case, a local file can have
   204:         // same name as directory and LookUpInode call will fetch directory details
   205:         // for both of them.
   206:         err = fixConflictingNames(entries)
   207:         if err != nil {
   208:                 err = fmt.Errorf("fixConflictingNames: %w", err)
   209:                 return
   210:         }
   211:
   212:         // Fix up offset fields.
   213:         for i := 0; i < len(entries); i++ {
   214:                 entries[i].Offset = fuseops.DirOffset(i) + 1
   215:         }
   216:
   217:         // Return a bogus inode ID for each entry, but not the root inode ID.
   218:         //
   219:         // NOTE: As far as I can tell this is harmless. Minting and
   220:         // returning a real inode ID is difficult because fuse does not count
   221:         // readdir as an operation that increases the inode ID's lookup count, and
   222:         // we therefore don't get a forget for it later, but we would like to not
   223:         // have to remember every inode ID that we've ever minted for readdir.
   224:         //
   225:         // If it turns out this is not harmless, we'll need to switch to something
   226:         // like inode IDs based on (object name, generation) hashes. But then what
   227:         // about the birthday problem? And more importantly, what about our
   228:         // semantic of not minting a new inode ID when the generation changes due
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:192 (PC: 0x19552e6)
   152:         }
   153:
   154:         return
   155: }
   156:
   157: // Read all entries for the directory, fix up conflicting names, and fill in
   158: // offset fields.
   159: //
   160: // LOCKS_REQUIRED(in)
   161: func readAllEntries(
   162:         ctx context.Context,
   163:         in inode.DirInode,
   164:         localEntries []fuseutil.Dirent) (entries []fuseutil.Dirent, err error) {
   165:         // Read entries from GCS.
   166:         // Read one batch at a time.
   167:         var tok string
   168:         for {
   169:                 // Read a batch.
   170:                 var batch []fuseutil.Dirent
   171:
   172:                 batch, tok, err = in.ReadEntries(ctx, tok)
   173:                 if err != nil {
   174:                         err = fmt.Errorf("ReadEntries: %w", err)
   175:                         return
   176:                 }
   177:
   178:                 // Accumulate.
   179:                 entries = append(entries, batch...)
   180:
   181:                 // Are we done?
   182:                 if tok == "" {
   183:                         break
   184:                 }
   185:         }
   186:
   187:         // Append local file entries (not synced to GCS).
   188:         entries = append(entries, localEntries...)
   189:
   190:         // Ensure that the entries are sorted, for use in fixConflictingNames
   191:         // below.
=> 192:         sort.Sort(sortedDirents(entries))
   193:
   194:         // Fix name conflicts.
   195:         // When a local file is synced to GCS but not removed from the local file map,
   196:         // the entries list will have two duplicate entries.
   197:         // To handle this scenario, we had 2 options:
   198:         // Option 1: [Selected]
   199:         // Throw an error while fixing conflicting names. The error will be fixed in
   200:         // subsequent ls calls assuming that entry will be removed from localFileInodes.
   201:         // Option 2: [Not Selected]
   202:         // Restrict fixConflictingNames to only GCS entries and show duplicate
   203:         // entries when ReadDir is called. In this case, a local file can have
   204:         // same name as directory and LookUpInode call will fetch directory details
   205:         // for both of them.
   206:         err = fixConflictingNames(entries)
   207:         if err != nil {
   208:                 err = fmt.Errorf("fixConflictingNames: %w", err)
   209:                 return
   210:         }
   211:
   212:         // Fix up offset fields.
   213:         for i := 0; i < len(entries); i++ {
   214:                 entries[i].Offset = fuseops.DirOffset(i) + 1
   215:         }
   216:
   217:         // Return a bogus inode ID for each entry, but not the root inode ID.
   218:         //
   219:         // NOTE: As far as I can tell this is harmless. Minting and
   220:         // returning a real inode ID is difficult because fuse does not count
   221:         // readdir as an operation that increases the inode ID's lookup count, and
   222:         // we therefore don't get a forget for it later, but we would like to not
   223:         // have to remember every inode ID that we've ever minted for readdir.
   224:         //
   225:         // If it turns out this is not harmless, we'll need to switch to something
   226:         // like inode IDs based on (object name, generation) hashes. But then what
   227:         // about the birthday problem? And more importantly, what about our
   228:         // semantic of not minting a new inode ID when the generation changes due
   229:         // to a local action?
   230:         for i := range entries {
   231:                 entries[i].Inode = fuseops.RootInodeID + 1
   232:         }
(dlv) p entrie
Command failed: could not find symbol value for entrie
(dlv) p entries
[]github.com/jacobsa/fuse/fuseutil.Dirent len: 0, cap: 0, nil
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:206 (PC: 0x1955305)
   166:         // Read one batch at a time.
   167:         var tok string
   168:         for {
   169:                 // Read a batch.
   170:                 var batch []fuseutil.Dirent
   171:
   172:                 batch, tok, err = in.ReadEntries(ctx, tok)
   173:                 if err != nil {
   174:                         err = fmt.Errorf("ReadEntries: %w", err)
   175:                         return
   176:                 }
   177:
   178:                 // Accumulate.
   179:                 entries = append(entries, batch...)
   180:
   181:                 // Are we done?
   182:                 if tok == "" {
   183:                         break
   184:                 }
   185:         }
   186:
   187:         // Append local file entries (not synced to GCS).
   188:         entries = append(entries, localEntries...)
   189:
   190:         // Ensure that the entries are sorted, for use in fixConflictingNames
   191:         // below.
   192:         sort.Sort(sortedDirents(entries))
   193:
   194:         // Fix name conflicts.
   195:         // When a local file is synced to GCS but not removed from the local file map,
   196:         // the entries list will have two duplicate entries.
   197:         // To handle this scenario, we had 2 options:
   198:         // Option 1: [Selected]
   199:         // Throw an error while fixing conflicting names. The error will be fixed in
   200:         // subsequent ls calls assuming that entry will be removed from localFileInodes.
   201:         // Option 2: [Not Selected]
   202:         // Restrict fixConflictingNames to only GCS entries and show duplicate
   203:         // entries when ReadDir is called. In this case, a local file can have
   204:         // same name as directory and LookUpInode call will fetch directory details
   205:         // for both of them.
=> 206:         err = fixConflictingNames(entries)
   207:         if err != nil {
   208:                 err = fmt.Errorf("fixConflictingNames: %w", err)
   209:                 return
   210:         }
   211:
   212:         // Fix up offset fields.
   213:         for i := 0; i < len(entries); i++ {
   214:                 entries[i].Offset = fuseops.DirOffset(i) + 1
   215:         }
   216:
   217:         // Return a bogus inode ID for each entry, but not the root inode ID.
   218:         //
   219:         // NOTE: As far as I can tell this is harmless. Minting and
   220:         // returning a real inode ID is difficult because fuse does not count
   221:         // readdir as an operation that increases the inode ID's lookup count, and
   222:         // we therefore don't get a forget for it later, but we would like to not
   223:         // have to remember every inode ID that we've ever minted for readdir.
   224:         //
   225:         // If it turns out this is not harmless, we'll need to switch to something
   226:         // like inode IDs based on (object name, generation) hashes. But then what
   227:         // about the birthday problem? And more importantly, what about our
   228:         // semantic of not minting a new inode ID when the generation changes due
   229:         // to a local action?
   230:         for i := range entries {
   231:                 entries[i].Inode = fuseops.RootInodeID + 1
   232:         }
   233:
   234:         return
   235: }
   236:
   237: // LOCKS_REQUIRED(dh.Mu)
   238: // LOCKS_EXCLUDED(dh.in)
   239: func (dh *DirHandle) ensureEntries(ctx context.Context, localFileEntries []fuseutil.Dirent) (err error) {
   240:         dh.in.Lock()
   241:         defer dh.in.Unlock()
   242:
   243:         // Read entries.
   244:         var entries []fuseutil.Dirent
   245:         entries, err = readAllEntries(ctx, dh.in, localFileEntries)
   246:         if err != nil {
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:207 (PC: 0x195532f)
   167:         var tok string
   168:         for {
   169:                 // Read a batch.
   170:                 var batch []fuseutil.Dirent
   171:
   172:                 batch, tok, err = in.ReadEntries(ctx, tok)
   173:                 if err != nil {
   174:                         err = fmt.Errorf("ReadEntries: %w", err)
   175:                         return
   176:                 }
   177:
   178:                 // Accumulate.
   179:                 entries = append(entries, batch...)
   180:
   181:                 // Are we done?
   182:                 if tok == "" {
   183:                         break
   184:                 }
   185:         }
   186:
   187:         // Append local file entries (not synced to GCS).
   188:         entries = append(entries, localEntries...)
   189:
   190:         // Ensure that the entries are sorted, for use in fixConflictingNames
   191:         // below.
   192:         sort.Sort(sortedDirents(entries))
   193:
   194:         // Fix name conflicts.
   195:         // When a local file is synced to GCS but not removed from the local file map,
   196:         // the entries list will have two duplicate entries.
   197:         // To handle this scenario, we had 2 options:
   198:         // Option 1: [Selected]
   199:         // Throw an error while fixing conflicting names. The error will be fixed in
   200:         // subsequent ls calls assuming that entry will be removed from localFileInodes.
   201:         // Option 2: [Not Selected]
   202:         // Restrict fixConflictingNames to only GCS entries and show duplicate
   203:         // entries when ReadDir is called. In this case, a local file can have
   204:         // same name as directory and LookUpInode call will fetch directory details
   205:         // for both of them.
   206:         err = fixConflictingNames(entries)
=> 207:         if err != nil {
   208:                 err = fmt.Errorf("fixConflictingNames: %w", err)
   209:                 return
   210:         }
   211:
   212:         // Fix up offset fields.
   213:         for i := 0; i < len(entries); i++ {
   214:                 entries[i].Offset = fuseops.DirOffset(i) + 1
   215:         }
   216:
   217:         // Return a bogus inode ID for each entry, but not the root inode ID.
   218:         //
   219:         // NOTE: As far as I can tell this is harmless. Minting and
   220:         // returning a real inode ID is difficult because fuse does not count
   221:         // readdir as an operation that increases the inode ID's lookup count, and
   222:         // we therefore don't get a forget for it later, but we would like to not
   223:         // have to remember every inode ID that we've ever minted for readdir.
   224:         //
   225:         // If it turns out this is not harmless, we'll need to switch to something
   226:         // like inode IDs based on (object name, generation) hashes. But then what
   227:         // about the birthday problem? And more importantly, what about our
   228:         // semantic of not minting a new inode ID when the generation changes due
   229:         // to a local action?
   230:         for i := range entries {
   231:                 entries[i].Inode = fuseops.RootInodeID + 1
   232:         }
   233:
   234:         return
   235: }
   236:
   237: // LOCKS_REQUIRED(dh.Mu)
   238: // LOCKS_EXCLUDED(dh.in)
   239: func (dh *DirHandle) ensureEntries(ctx context.Context, localFileEntries []fuseutil.Dirent) (err error) {
   240:         dh.in.Lock()
   241:         defer dh.in.Unlock()
   242:
   243:         // Read entries.
   244:         var entries []fuseutil.Dirent
   245:         entries, err = readAllEntries(ctx, dh.in, localFileEntries)
   246:         if err != nil {
   247:                 err = fmt.Errorf("readAllEntries: %w", err)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:213 (PC: 0x195545c)
   173:                 if err != nil {
   174:                         err = fmt.Errorf("ReadEntries: %w", err)
   175:                         return
   176:                 }
   177:
   178:                 // Accumulate.
   179:                 entries = append(entries, batch...)
   180:
   181:                 // Are we done?
   182:                 if tok == "" {
   183:                         break
   184:                 }
   185:         }
   186:
   187:         // Append local file entries (not synced to GCS).
   188:         entries = append(entries, localEntries...)
   189:
   190:         // Ensure that the entries are sorted, for use in fixConflictingNames
   191:         // below.
   192:         sort.Sort(sortedDirents(entries))
   193:
   194:         // Fix name conflicts.
   195:         // When a local file is synced to GCS but not removed from the local file map,
   196:         // the entries list will have two duplicate entries.
   197:         // To handle this scenario, we had 2 options:
   198:         // Option 1: [Selected]
   199:         // Throw an error while fixing conflicting names. The error will be fixed in
   200:         // subsequent ls calls assuming that entry will be removed from localFileInodes.
   201:         // Option 2: [Not Selected]
   202:         // Restrict fixConflictingNames to only GCS entries and show duplicate
   203:         // entries when ReadDir is called. In this case, a local file can have
   204:         // same name as directory and LookUpInode call will fetch directory details
   205:         // for both of them.
   206:         err = fixConflictingNames(entries)
   207:         if err != nil {
   208:                 err = fmt.Errorf("fixConflictingNames: %w", err)
   209:                 return
   210:         }
   211:
   212:         // Fix up offset fields.
=> 213:         for i := 0; i < len(entries); i++ {
   214:                 entries[i].Offset = fuseops.DirOffset(i) + 1
   215:         }
   216:
   217:         // Return a bogus inode ID for each entry, but not the root inode ID.
   218:         //
   219:         // NOTE: As far as I can tell this is harmless. Minting and
   220:         // returning a real inode ID is difficult because fuse does not count
   221:         // readdir as an operation that increases the inode ID's lookup count, and
   222:         // we therefore don't get a forget for it later, but we would like to not
   223:         // have to remember every inode ID that we've ever minted for readdir.
   224:         //
   225:         // If it turns out this is not harmless, we'll need to switch to something
   226:         // like inode IDs based on (object name, generation) hashes. But then what
   227:         // about the birthday problem? And more importantly, what about our
   228:         // semantic of not minting a new inode ID when the generation changes due
   229:         // to a local action?
   230:         for i := range entries {
   231:                 entries[i].Inode = fuseops.RootInodeID + 1
   232:         }
   233:
   234:         return
   235: }
   236:
   237: // LOCKS_REQUIRED(dh.Mu)
   238: // LOCKS_EXCLUDED(dh.in)
   239: func (dh *DirHandle) ensureEntries(ctx context.Context, localFileEntries []fuseutil.Dirent) (err error) {
   240:         dh.in.Lock()
   241:         defer dh.in.Unlock()
   242:
   243:         // Read entries.
   244:         var entries []fuseutil.Dirent
   245:         entries, err = readAllEntries(ctx, dh.in, localFileEntries)
   246:         if err != nil {
   247:                 err = fmt.Errorf("readAllEntries: %w", err)
   248:                 return
   249:         }
   250:
   251:         // Update state.
   252:         dh.entries = entries
   253:         dh.entriesValid = true
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:230 (PC: 0x19554c4)
   190:         // Ensure that the entries are sorted, for use in fixConflictingNames
   191:         // below.
   192:         sort.Sort(sortedDirents(entries))
   193:
   194:         // Fix name conflicts.
   195:         // When a local file is synced to GCS but not removed from the local file map,
   196:         // the entries list will have two duplicate entries.
   197:         // To handle this scenario, we had 2 options:
   198:         // Option 1: [Selected]
   199:         // Throw an error while fixing conflicting names. The error will be fixed in
   200:         // subsequent ls calls assuming that entry will be removed from localFileInodes.
   201:         // Option 2: [Not Selected]
   202:         // Restrict fixConflictingNames to only GCS entries and show duplicate
   203:         // entries when ReadDir is called. In this case, a local file can have
   204:         // same name as directory and LookUpInode call will fetch directory details
   205:         // for both of them.
   206:         err = fixConflictingNames(entries)
   207:         if err != nil {
   208:                 err = fmt.Errorf("fixConflictingNames: %w", err)
   209:                 return
   210:         }
   211:
   212:         // Fix up offset fields.
   213:         for i := 0; i < len(entries); i++ {
   214:                 entries[i].Offset = fuseops.DirOffset(i) + 1
   215:         }
   216:
   217:         // Return a bogus inode ID for each entry, but not the root inode ID.
   218:         //
   219:         // NOTE: As far as I can tell this is harmless. Minting and
   220:         // returning a real inode ID is difficult because fuse does not count
   221:         // readdir as an operation that increases the inode ID's lookup count, and
   222:         // we therefore don't get a forget for it later, but we would like to not
   223:         // have to remember every inode ID that we've ever minted for readdir.
   224:         //
   225:         // If it turns out this is not harmless, we'll need to switch to something
   226:         // like inode IDs based on (object name, generation) hashes. But then what
   227:         // about the birthday problem? And more importantly, what about our
   228:         // semantic of not minting a new inode ID when the generation changes due
   229:         // to a local action?
=> 230:         for i := range entries {
   231:                 entries[i].Inode = fuseops.RootInodeID + 1
   232:         }
   233:
   234:         return
   235: }
   236:
   237: // LOCKS_REQUIRED(dh.Mu)
   238: // LOCKS_EXCLUDED(dh.in)
   239: func (dh *DirHandle) ensureEntries(ctx context.Context, localFileEntries []fuseutil.Dirent) (err error) {
   240:         dh.in.Lock()
   241:         defer dh.in.Unlock()
   242:
   243:         // Read entries.
   244:         var entries []fuseutil.Dirent
   245:         entries, err = readAllEntries(ctx, dh.in, localFileEntries)
   246:         if err != nil {
   247:                 err = fmt.Errorf("readAllEntries: %w", err)
   248:                 return
   249:         }
   250:
   251:         // Update state.
   252:         dh.entries = entries
   253:         dh.entriesValid = true
   254:
   255:         return
   256: }
   257:
   258: ////////////////////////////////////////////////////////////////////////
   259: // Public interface
   260: ////////////////////////////////////////////////////////////////////////
   261:
   262: // ReadDir handles a request to read from the directory, without responding.
   263: //
   264: // Special case: we assume that a zero offset indicates that rewinddir has been
   265: // called (since fuse gives us no way to intercept and know for sure), and
   266: // start the listing process over again.
   267: //
   268: // LOCKS_REQUIRED(dh.Mu)
   269: // LOCKS_EXCLUDED(du.in)
   270: func (dh *DirHandle) ReadDir(
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.readAllEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:234 (PC: 0x1955529)
   194:         // Fix name conflicts.
   195:         // When a local file is synced to GCS but not removed from the local file map,
   196:         // the entries list will have two duplicate entries.
   197:         // To handle this scenario, we had 2 options:
   198:         // Option 1: [Selected]
   199:         // Throw an error while fixing conflicting names. The error will be fixed in
   200:         // subsequent ls calls assuming that entry will be removed from localFileInodes.
   201:         // Option 2: [Not Selected]
   202:         // Restrict fixConflictingNames to only GCS entries and show duplicate
   203:         // entries when ReadDir is called. In this case, a local file can have
   204:         // same name as directory and LookUpInode call will fetch directory details
   205:         // for both of them.
   206:         err = fixConflictingNames(entries)
   207:         if err != nil {
   208:                 err = fmt.Errorf("fixConflictingNames: %w", err)
   209:                 return
   210:         }
   211:
   212:         // Fix up offset fields.
   213:         for i := 0; i < len(entries); i++ {
   214:                 entries[i].Offset = fuseops.DirOffset(i) + 1
   215:         }
   216:
   217:         // Return a bogus inode ID for each entry, but not the root inode ID.
   218:         //
   219:         // NOTE: As far as I can tell this is harmless. Minting and
   220:         // returning a real inode ID is difficult because fuse does not count
   221:         // readdir as an operation that increases the inode ID's lookup count, and
   222:         // we therefore don't get a forget for it later, but we would like to not
   223:         // have to remember every inode ID that we've ever minted for readdir.
   224:         //
   225:         // If it turns out this is not harmless, we'll need to switch to something
   226:         // like inode IDs based on (object name, generation) hashes. But then what
   227:         // about the birthday problem? And more importantly, what about our
   228:         // semantic of not minting a new inode ID when the generation changes due
   229:         // to a local action?
   230:         for i := range entries {
   231:                 entries[i].Inode = fuseops.RootInodeID + 1
   232:         }
   233:
=> 234:         return
   235: }
   236:
   237: // LOCKS_REQUIRED(dh.Mu)
   238: // LOCKS_EXCLUDED(dh.in)
   239: func (dh *DirHandle) ensureEntries(ctx context.Context, localFileEntries []fuseutil.Dirent) (err error) {
   240:         dh.in.Lock()
   241:         defer dh.in.Unlock()
   242:
   243:         // Read entries.
   244:         var entries []fuseutil.Dirent
   245:         entries, err = readAllEntries(ctx, dh.in, localFileEntries)
   246:         if err != nil {
   247:                 err = fmt.Errorf("readAllEntries: %w", err)
   248:                 return
   249:         }
   250:
   251:         // Update state.
   252:         dh.entries = entries
   253:         dh.entriesValid = true
   254:
   255:         return
   256: }
   257:
   258: ////////////////////////////////////////////////////////////////////////
   259: // Public interface
   260: ////////////////////////////////////////////////////////////////////////
   261:
   262: // ReadDir handles a request to read from the directory, without responding.
   263: //
   264: // Special case: we assume that a zero offset indicates that rewinddir has been
   265: // called (since fuse gives us no way to intercept and know for sure), and
   266: // start the listing process over again.
   267: //
   268: // LOCKS_REQUIRED(dh.Mu)
   269: // LOCKS_EXCLUDED(du.in)
   270: func (dh *DirHandle) ReadDir(
   271:         ctx context.Context,
   272:         op *fuseops.ReadDirOp,
   273:         localFileEntries []fuseutil.Dirent) (err error) {
   274:         // If the request is for offset zero, we assume that either this is the first
(dlv) so
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs/handle.(*DirHandle).ensureEntries() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/handle/dir_handle.go:245 (PC: 0x1955753)
Values returned:
        entries: []github.com/jacobsa/fuse/fuseutil.Dirent len: 0, cap: 0, nil
        err: error nil

   205:         // for both of them.
   206:         err = fixConflictingNames(entries)
   207:         if err != nil {
   208:                 err = fmt.Errorf("fixConflictingNames: %w", err)
   209:                 return
   210:         }
   211:
   212:         // Fix up offset fields.
   213:         for i := 0; i < len(entries); i++ {
   214:                 entries[i].Offset = fuseops.DirOffset(i) + 1
   215:         }
   216:
   217:         // Return a bogus inode ID for each entry, but not the root inode ID.
   218:         //
   219:         // NOTE: As far as I can tell this is harmless. Minting and
   220:         // returning a real inode ID is difficult because fuse does not count
   221:         // readdir as an operation that increases the inode ID's lookup count, and
   222:         // we therefore don't get a forget for it later, but we would like to not
   223:         // have to remember every inode ID that we've ever minted for readdir.
   224:         //
   225:         // If it turns out this is not harmless, we'll need to switch to something
   226:         // like inode IDs based on (object name, generation) hashes. But then what
   227:         // about the birthday problem? And more importantly, what about our
   228:         // semantic of not minting a new inode ID when the generation changes due
   229:         // to a local action?
   230:         for i := range entries {
   231:                 entries[i].Inode = fuseops.RootInodeID + 1
   232:         }
   233:
   234:         return
   235: }
   236:
   237: // LOCKS_REQUIRED(dh.Mu)
   238: // LOCKS_EXCLUDED(dh.in)
   239: func (dh *DirHandle) ensureEntries(ctx context.Context, localFileEntries []fuseutil.Dirent) (err error) {
   240:         dh.in.Lock()
   241:         defer dh.in.Unlock()
   242:
   243:         // Read entries.
   244:         var entries []fuseutil.Dirent
=> 245:         entries, err = readAllEntries(ctx, dh.in, localFileEntries)
   246:         if err != nil {
   247:                 err = fmt.Errorf("readAllEntries: %w", err)
   248:                 return
   249:         }
   250:
   251:         // Update state.
   252:         dh.entries = entries
   253:         dh.entriesValid = true
   254:
   255:         return
   256: }
   257:
   258: ////////////////////////////////////////////////////////////////////////
   259: // Public interface
   260: ////////////////////////////////////////////////////////////////////////
   261:
   262: // ReadDir handles a request to read from the directory, without responding.
   263: //
   264: // Special case: we assume that a zero offset indicates that rewinddir has been
   265: // called (since fuse gives us no way to intercept and know for sure), and
   266: // start the listing process over again.
   267: //
   268: // LOCKS_REQUIRED(dh.Mu)
   269: // LOCKS_EXCLUDED(du.in)
   270: func (dh *DirHandle) ReadDir(
   271:         ctx context.Context,
   272:         op *fuseops.ReadDirOp,
   273:         localFileEntries []fuseutil.Dirent) (err error) {
   274:         // If the request is for offset zero, we assume that either this is the first
   275:         // call or rewinddir has been called. Reset state.
   276:         if op.Offset == 0 {
   277:                 dh.entries = nil
   278:                 dh.entriesValid = false
   279:         }
   280:
   281:         // Do we need to read entries from GCS?
   282:         if !dh.entriesValid {
   283:                 err = dh.ensureEntries(ctx, localFileEntries)
   284:                 if err != nil {
   285:                         return
(dlv) c
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x483b03)
Warning: debugging optimized function
   519:         MOVQ    $SYS_munmap, AX
   520:         SYSCALL
   521:         CMPQ    AX, $0xfffffffffffff001
   522:         JLS     2(PC)
   523:         MOVL    $0xf1, 0xf1  // crash
   524:         RET
   525:
   526: // Call the function stored in _cgo_munmap using the GCC calling convention.
   527: // This must be called on the system stack.
   528: TEXT runtime·callCgoMunmap(SB),NOSPLIT,$16-16
   529:         MOVQ    addr+0(FP), DI
   530:         MOVQ    n+8(FP), SI
   531:         MOVQ    _cgo_munmap(SB), AX
   532:         MOVQ    SP, BX
   533:         ANDQ    $~15, SP        // alignment as per amd64 psABI
   534:         MOVQ    BX, 0(SP)
   535:         CALL    AX
   536:         MOVQ    0(SP), SP
   537:         RET
   538:
   539: TEXT runtime·madvise(SB),NOSPLIT,$0
   540:         MOVQ    addr+0(FP), DI
   541:         MOVQ    n+8(FP), SI
   542:         MOVL    flags+16(FP), DX
   543:         MOVQ    $SYS_madvise, AX
   544:         SYSCALL
   545:         MOVL    AX, ret+24(FP)
   546:         RET
   547:
   548: // int64 futex(int32 *uaddr, int32 op, int32 val,
   549: //      struct timespec *timeout, int32 *uaddr2, int32 val2);
   550: TEXT runtime·futex(SB),NOSPLIT,$0
   551:         MOVQ    addr+0(FP), DI
   552:         MOVL    op+8(FP), SI
   553:         MOVL    val+12(FP), DX
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
   565:         MOVQ    stk+8(FP), SI
   566:         MOVQ    $0, DX
   567:         MOVQ    $0, R10
   568:         MOVQ    $0, R8
   569:         // Copy mp, gp, fn off parent stack for use by child.
   570:         // Careful: Linux system call clobbers CX and R11.
   571:         MOVQ    mp+16(FP), R13
   572:         MOVQ    gp+24(FP), R9
   573:         MOVQ    fn+32(FP), R12
   574:         CMPQ    R13, $0    // m
   575:         JEQ     nog1
   576:         CMPQ    R9, $0    // g
   577:         JEQ     nog1
   578:         LEAQ    m_tls(R13), R8
   579: #ifdef GOOS_android
   580:         // Android stores the TLS offset in runtime·tls_g.
   581:         SUBQ    runtime·tls_g(SB), R8
   582: #else
   583:         ADDQ    $8, R8  // ELF wants to use -8(FS)
   584: #endif
   585:         ORQ     $0x00080000, DI //add flag CLONE_SETTLS(0x00080000) to call clone
   586: nog1:
   587:         MOVL    $SYS_clone, AX
   588:         SYSCALL
   589:
   590:         // In parent, return.
   591:         CMPQ    AX, $0
   592:         JEQ     3(PC)
   593:         MOVL    AX, ret+40(FP)
   594:         RET
   595:
   596:         // In child, on new stack.
   597:         MOVQ    SI, SP
   598:
   599:         // If g or m are nil, skip Go-related setup.
(dlv) bp
Breakpoint runtime-fatal-throw (enabled) at 0x4464e4,0x446404,0x45f38e for (multiple functions)() <multiple locations>:0 (0)
Breakpoint unrecovered-panic (enabled) at 0x4469a4 for runtime.fatalpanic() /usr/lib/google-golang/src/runtime/panic.go:1219 (0)
        print runtime.curg._panic.arg
Breakpoint 1 (enabled) at 0x18ef1ca for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:292 (1)
Breakpoint 2 (enabled) at 0x18ef299 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:294 (0)
Breakpoint 3 (enabled) at 0x18ef3ab for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:302 (0)
Breakpoint 4 (enabled) at 0x18ef473 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306 (3)
Breakpoint 6 (enabled) at 0x1968a36 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 (2)
Breakpoint 7 (enabled) at 0x1972776 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148 (1)
Breakpoint 8 (enabled) at 0x1972473 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).OpenDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2126 (1)
Breakpoint 9 (enabled) at 0x1968d05 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1335 (2)
Breakpoint 10 (enabled) at 0x18ef5c5 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:324 (3)
(dlv) q 
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ vi ~/.vimrc
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ fusermount -uz $mountpath ; ./creationSituation.sh 1      
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ echo Number of args: 1
Number of args: 1
+ debug=0
+ run=1
+ '[' 1 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 1 -gt 1 ']'
+ '[' 0 -ne 0 ']'
+ echo 'Running ...'
Running ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 0 = 0 ']'
+ go run /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse --config-file=config.yml --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
{"timestamp":{"seconds":1715197410,"nanos":424528406},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
time="08/05/2024 07:43:30.424829" severity=INFO message="Start gcsfuse/unknown (Go version go1.23-20240419-RC02 cl/626470163 +7f76c00fc5 X:fieldtrack,boringcrypto) for app \"\" using mount point: /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4\n"
time="08/05/2024 07:43:30.561993" severity=INFO message="File system has been successfully mounted."
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ fusermount -uz $mountpath ; ./creationSituation.sh 1 debug
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ echo Number of args: 2
Number of args: 2
+ debug=0
+ run=1
+ '[' 2 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 2 -gt 1 ']'
+ debug=1
+ '[' 1 -ne 0 ']'
+ echo 'Debugging ...'
Debugging ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 1 = 0 ']'
+ dlv debug --check-go-version=false /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/. -- --config-file=config.yml --foreground --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
WARNING: undefined behavior - Go version go0.0 is too old for this version of Delve (minimum supported version 1.19)
Type 'help' for list of commands.
(dlv) r
Process restarted with PID 1611852
(dlv) c
{"timestamp":{"seconds":1715198021,"nanos":500967085},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x483b03)
Warning: debugging optimized function
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
(dlv) config source-list-line-count 30
(dlv) 
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:292
Breakpoint 1 set at 0x18ef1ca for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:292
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:294
Breakpoint 2 set at 0x18ef299 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:294
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:302
Breakpoint 3 set at 0x18ef3ab for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:302
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306
Breakpoint 4 set at 0x18ef473 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:324
Breakpoint 5 set at 0x18ef5c5 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:324
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode
Breakpoint 6 set at 0x1968a36 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir
Breakpoint 7 set at 0x1972776 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148 (hits goroutine(357):1 total:1) (PC: 0x1972776)
  2118:         if err := fs.invalidateChildFileCacheIfExist(parent, fileName.GcsObjectName()); err != nil {
  2119:                 return fmt.Errorf("Unlink: while invalidating cache for delete file: %w", err)
  2120:         }
  2121:
  2122:         return
  2123: }
  2124:
  2125: // LOCKS_EXCLUDED(fs.mu)
  2126: func (fs *fileSystem) OpenDir(
  2127:         ctx context.Context,
  2128:         op *fuseops.OpenDirOp) (err error) {
  2129:         fs.mu.Lock()
  2130:         defer fs.mu.Unlock()
  2131:
  2132:         // Make sure the inode still exists and is a directory. If not, something has
  2133:         // screwed up because the VFS layer shouldn't have let us forget the inode
  2134:         // before opening it.
  2135:         in := fs.dirInodeOrDie(op.Inode)
  2136:
  2137:         // Allocate a handle.
  2138:         handleID := fs.nextHandleID
  2139:         fs.nextHandleID++
  2140:
  2141:         fs.handles[handleID] = handle.NewDirHandle(in, fs.implicitDirs)
  2142:         op.Handle = handleID
  2143:
  2144:         return
  2145: }
  2146:
  2147: // LOCKS_EXCLUDED(fs.mu)
=>2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
  2150:         op *fuseops.ReadDirOp) (err error) {
  2151:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  2152:                 // When ignore interrupts config is set, we are creating a new context not
  2153:                 // cancellable by parent context.
  2154:                 var cancel context.CancelFunc
  2155:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  2156:                 defer cancel()
  2157:         }
  2158:         // Find the handle.
  2159:         fs.mu.Lock()
  2160:         dh := fs.handles[op.Handle].(*handle.DirHandle)
  2161:         in := fs.dirInodeOrDie(op.Inode)
  2162:         // Fetch local file entries beforehand and pass it to directory handle as
  2163:         // we need fs lock to fetch local file entries.
  2164:         localFileEntries := in.LocalFileEntries(fs.localFileInodes)
  2165:         fs.mu.Unlock()
  2166:
  2167:         dh.Mu.Lock()
  2168:         defer dh.Mu.Unlock()
  2169:         // Serve the request.
  2170:         if err := dh.ReadDir(ctx, op, localFileEntries); err != nil {
  2171:                 return err
  2172:         }
  2173:
  2174:         return
  2175: }
  2176:
  2177: // LOCKS_EXCLUDED(fs.mu)
  2178: func (fs *fileSystem) ReleaseDirHandle(
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2151 (PC: 0x19727a6)
  2121:
  2122:         return
  2123: }
  2124:
  2125: // LOCKS_EXCLUDED(fs.mu)
  2126: func (fs *fileSystem) OpenDir(
  2127:         ctx context.Context,
  2128:         op *fuseops.OpenDirOp) (err error) {
  2129:         fs.mu.Lock()
  2130:         defer fs.mu.Unlock()
  2131:
  2132:         // Make sure the inode still exists and is a directory. If not, something has
  2133:         // screwed up because the VFS layer shouldn't have let us forget the inode
  2134:         // before opening it.
  2135:         in := fs.dirInodeOrDie(op.Inode)
  2136:
  2137:         // Allocate a handle.
  2138:         handleID := fs.nextHandleID
  2139:         fs.nextHandleID++
  2140:
  2141:         fs.handles[handleID] = handle.NewDirHandle(in, fs.implicitDirs)
  2142:         op.Handle = handleID
  2143:
  2144:         return
  2145: }
  2146:
  2147: // LOCKS_EXCLUDED(fs.mu)
  2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
  2150:         op *fuseops.ReadDirOp) (err error) {
=>2151:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  2152:                 // When ignore interrupts config is set, we are creating a new context not
  2153:                 // cancellable by parent context.
  2154:                 var cancel context.CancelFunc
  2155:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  2156:                 defer cancel()
  2157:         }
  2158:         // Find the handle.
  2159:         fs.mu.Lock()
  2160:         dh := fs.handles[op.Handle].(*handle.DirHandle)
  2161:         in := fs.dirInodeOrDie(op.Inode)
  2162:         // Fetch local file entries beforehand and pass it to directory handle as
  2163:         // we need fs lock to fetch local file entries.
  2164:         localFileEntries := in.LocalFileEntries(fs.localFileInodes)
  2165:         fs.mu.Unlock()
  2166:
  2167:         dh.Mu.Lock()
  2168:         defer dh.Mu.Unlock()
  2169:         // Serve the request.
  2170:         if err := dh.ReadDir(ctx, op, localFileEntries); err != nil {
  2171:                 return err
  2172:         }
  2173:
  2174:         return
  2175: }
  2176:
  2177: // LOCKS_EXCLUDED(fs.mu)
  2178: func (fs *fileSystem) ReleaseDirHandle(
  2179:         ctx context.Context,
  2180:         op *fuseops.ReleaseDirHandleOp) (err error) {
  2181:         fs.mu.Lock()
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2159 (PC: 0x19728af)
  2129:         fs.mu.Lock()
  2130:         defer fs.mu.Unlock()
  2131:
  2132:         // Make sure the inode still exists and is a directory. If not, something has
  2133:         // screwed up because the VFS layer shouldn't have let us forget the inode
  2134:         // before opening it.
  2135:         in := fs.dirInodeOrDie(op.Inode)
  2136:
  2137:         // Allocate a handle.
  2138:         handleID := fs.nextHandleID
  2139:         fs.nextHandleID++
  2140:
  2141:         fs.handles[handleID] = handle.NewDirHandle(in, fs.implicitDirs)
  2142:         op.Handle = handleID
  2143:
  2144:         return
  2145: }
  2146:
  2147: // LOCKS_EXCLUDED(fs.mu)
  2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
  2150:         op *fuseops.ReadDirOp) (err error) {
  2151:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  2152:                 // When ignore interrupts config is set, we are creating a new context not
  2153:                 // cancellable by parent context.
  2154:                 var cancel context.CancelFunc
  2155:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  2156:                 defer cancel()
  2157:         }
  2158:         // Find the handle.
=>2159:         fs.mu.Lock()
  2160:         dh := fs.handles[op.Handle].(*handle.DirHandle)
  2161:         in := fs.dirInodeOrDie(op.Inode)
  2162:         // Fetch local file entries beforehand and pass it to directory handle as
  2163:         // we need fs lock to fetch local file entries.
  2164:         localFileEntries := in.LocalFileEntries(fs.localFileInodes)
  2165:         fs.mu.Unlock()
  2166:
  2167:         dh.Mu.Lock()
  2168:         defer dh.Mu.Unlock()
  2169:         // Serve the request.
  2170:         if err := dh.ReadDir(ctx, op, localFileEntries); err != nil {
  2171:                 return err
  2172:         }
  2173:
  2174:         return
  2175: }
  2176:
  2177: // LOCKS_EXCLUDED(fs.mu)
  2178: func (fs *fileSystem) ReleaseDirHandle(
  2179:         ctx context.Context,
  2180:         op *fuseops.ReleaseDirHandleOp) (err error) {
  2181:         fs.mu.Lock()
  2182:         defer fs.mu.Unlock()
  2183:
  2184:         // Sanity check that this handle exists and is of the correct type.
  2185:         _ = fs.handles[op.Handle].(*handle.DirHandle)
  2186:
  2187:         // Clear the entry from the map.
  2188:         delete(fs.handles, op.Handle)
  2189:
(dlv) p op
("*github.com/jacobsa/fuse/fuseops.ReadDirOp")(0xc000b14140)
*github.com/jacobsa/fuse/fuseops.ReadDirOp {
        Inode: 1,
        Handle: 26,
        Offset: 0,
        Dst: []uint8 len: 4096, cap: 4096, [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...+4032 more],
        BytesRead: 0,
        OpContext: github.com/jacobsa/fuse/fuseops.OpContext {FuseID: 392, Pid: 1612448, Uid: 1012083},}
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306 (hits goroutine(357):1 total:1) (PC: 0x18ef473)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 // Do not list unsupported directories such as '.', '..',
   285:                                 // '/', and '\0' as prefixes, which become implicit directories,
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
   292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
=> 306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
   323:         listing = &list
   324:         return
   325: }
   326:
   327: func (b *bucketHandle) UpdateObject(ctx context.Context, req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   328:         obj := b.bucket.Object(req.Name)
   329:
   330:         if req.Generation != 0 {
   331:                 obj = obj.Generation(req.Generation)
   332:         }
   333:
   334:         if req.MetaGenerationPrecondition != nil {
   335:                 obj = obj.If(storage.Conditions{MetagenerationMatch: *req.MetaGenerationPrecondition})
   336:         }
(dlv) p attrs.Name
"14"
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:292 (hits goroutine(357):1 total:1) (PC: 0x18ef1ca)
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("Error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 // Do not list unsupported directories such as '.', '..',
   285:                                 // '/', and '\0' as prefixes, which become implicit directories,
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
=> 292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
(dlv) p attrs.Prefix
"\x00/"
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:317 (PC: 0x18ef52e)
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
   292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
=> 317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
   323:         listing = &list
   324:         return
   325: }
   326:
   327: func (b *bucketHandle) UpdateObject(ctx context.Context, req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   328:         obj := b.bucket.Object(req.Name)
   329:
   330:         if req.Generation != 0 {
   331:                 obj = obj.Generation(req.Generation)
   332:         }
   333:
   334:         if req.MetaGenerationPrecondition != nil {
   335:                 obj = obj.If(storage.Conditions{MetagenerationMatch: *req.MetaGenerationPrecondition})
   336:         }
   337:
   338:         updateQuery := storage.ObjectAttrsToUpdate{}
   339:
   340:         if req.ContentType != nil {
   341:                 updateQuery.ContentType = *req.ContentType
   342:         }
   343:
   344:         if req.ContentEncoding != nil {
   345:                 updateQuery.ContentEncoding = *req.ContentEncoding
   346:         }
   347:
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:292 (hits goroutine(357):2 total:2) (PC: 0x18ef1ca)
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("Error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 // Do not list unsupported directories such as '.', '..',
   285:                                 // '/', and '\0' as prefixes, which become implicit directories,
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
=> 292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
(dlv) p attrs.Prefix
"../"
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:292 (hits goroutine(357):3 total:3) (PC: 0x18ef1ca)
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("Error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 // Do not list unsupported directories such as '.', '..',
   285:                                 // '/', and '\0' as prefixes, which become implicit directories,
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
=> 292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
(dlv) p attrs.Prefix
"./"
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:292 (hits goroutine(357):4 total:4) (PC: 0x18ef1ca)
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("Error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 // Do not list unsupported directories such as '.', '..',
   285:                                 // '/', and '\0' as prefixes, which become implicit directories,
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
=> 292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
(dlv) p attrs.Prefix
"/"
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:294 (hits goroutine(357):1 total:1) (PC: 0x18ef299)
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("Error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 // Do not list unsupported directories such as '.', '..',
   285:                                 // '/', and '\0' as prefixes, which become implicit directories,
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
   292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
=> 294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
   323:         listing = &list
   324:         return
(dlv) p attrs.Prefix
"a/"
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:324 (hits goroutine(357):1 total:1) (PC: 0x18ef5c5)
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
   323:         listing = &list
=> 324:         return
   325: }
   326:
   327: func (b *bucketHandle) UpdateObject(ctx context.Context, req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   328:         obj := b.bucket.Object(req.Name)
   329:
   330:         if req.Generation != 0 {
   331:                 obj = obj.Generation(req.Generation)
   332:         }
   333:
   334:         if req.MetaGenerationPrecondition != nil {
   335:                 obj = obj.If(storage.Conditions{MetagenerationMatch: *req.MetaGenerationPrecondition})
   336:         }
   337:
   338:         updateQuery := storage.ObjectAttrsToUpdate{}
   339:
   340:         if req.ContentType != nil {
   341:                 updateQuery.ContentType = *req.ContentType
   342:         }
   343:
   344:         if req.ContentEncoding != nil {
   345:                 updateQuery.ContentEncoding = *req.ContentEncoding
   346:         }
   347:
   348:         if req.ContentLanguage != nil {
   349:                 updateQuery.ContentLanguage = *req.ContentLanguage
   350:         }
   351:
   352:         if req.CacheControl != nil {
   353:                 updateQuery.CacheControl = *req.CacheControl
   354:         }
(dlv) p list
github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing {
        Objects: []*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object len: 1, cap: 1, [
                *(*"github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object")(0xc000885540),
        ],
        CollapsedRuns: []string len: 1, cap: 1, ["a/"],
        ContinuationToken: "",}
(dlv) p listing
("*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing")(0xc000acc6c0)
*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing {
        Objects: []*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object len: 1, cap: 1, [
                *(*"github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object")(0xc000885540),
        ],
        CollapsedRuns: []string len: 1, cap: 1, ["a/"],
        ContinuationToken: "",}
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 (hits goroutine(359):1 total:1) (PC: 0x1968a36)
  1284: func (fs *fileSystem) Destroy() {
  1285:         fs.bucketManager.ShutDown()
  1286:         if fs.fileCacheHandler != nil {
  1287:                 _ = fs.fileCacheHandler.Destroy()
  1288:         }
  1289: }
  1290:
  1291: func (fs *fileSystem) StatFS(
  1292:         ctx context.Context,
  1293:         op *fuseops.StatFSOp) (err error) {
  1294:         // Simulate a large amount of free space so that the Finder doesn't refuse to
  1295:         // copy in files. (See issue #125.) Use 2^17 as the block size because that
  1296:         // is the largest that OS X will pass on.
  1297:         op.BlockSize = 1 << 17
  1298:         op.Blocks = 1 << 33
  1299:         op.BlocksFree = op.Blocks
  1300:         op.BlocksAvailable = op.Blocks
  1301:
  1302:         // Similarly with inodes.
  1303:         op.Inodes = 1 << 50
  1304:         op.InodesFree = op.Inodes
  1305:
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
=>1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
(dlv) p op
("*github.com/jacobsa/fuse/fuseops.LookUpInodeOp")(0xc000b1a0f0)
*github.com/jacobsa/fuse/fuseops.LookUpInodeOp {
        Parent: 1,
        Name: "14",
        Entry: github.com/jacobsa/fuse/fuseops.ChildInodeEntry {
                Child: 0,
                Generation: 0,
                Attributes: (*"github.com/jacobsa/fuse/fuseops.InodeAttributes")(0xc000b1a118),
                AttributesExpiration: (*time.Time)(0xc000b1a198),
                EntryExpiration: (*time.Time)(0xc000b1a1b0),},
        OpContext: github.com/jacobsa/fuse/fuseops.OpContext {FuseID: 396, Pid: 1612448, Uid: 1012083},}
(dlv) n
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1317 (PC: 0x1968a66)
  1287:                 _ = fs.fileCacheHandler.Destroy()
  1288:         }
  1289: }
  1290:
  1291: func (fs *fileSystem) StatFS(
  1292:         ctx context.Context,
  1293:         op *fuseops.StatFSOp) (err error) {
  1294:         // Simulate a large amount of free space so that the Finder doesn't refuse to
  1295:         // copy in files. (See issue #125.) Use 2^17 as the block size because that
  1296:         // is the largest that OS X will pass on.
  1297:         op.BlockSize = 1 << 17
  1298:         op.Blocks = 1 << 33
  1299:         op.BlocksFree = op.Blocks
  1300:         op.BlocksAvailable = op.Blocks
  1301:
  1302:         // Similarly with inodes.
  1303:         op.Inodes = 1 << 50
  1304:         op.InodesFree = op.Inodes
  1305:
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
=>1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
  1345:
  1346:         return
  1347: }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1325 (PC: 0x1968b72)
  1295:         // copy in files. (See issue #125.) Use 2^17 as the block size because that
  1296:         // is the largest that OS X will pass on.
  1297:         op.BlockSize = 1 << 17
  1298:         op.Blocks = 1 << 33
  1299:         op.BlocksFree = op.Blocks
  1300:         op.BlocksAvailable = op.Blocks
  1301:
  1302:         // Similarly with inodes.
  1303:         op.Inodes = 1 << 50
  1304:         op.InodesFree = op.Inodes
  1305:
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
=>1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
  1345:
  1346:         return
  1347: }
  1348:
  1349: // LOCKS_EXCLUDED(fs.mu)
  1350: func (fs *fileSystem) GetInodeAttributes(
  1351:         ctx context.Context,
  1352:         op *fuseops.GetInodeAttributesOp) (err error) {
  1353:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1354:                 // When ignore interrupts config is set, we are creating a new context not
  1355:                 // cancellable by parent context.
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1326 (PC: 0x1968b8f)
  1296:         // is the largest that OS X will pass on.
  1297:         op.BlockSize = 1 << 17
  1298:         op.Blocks = 1 << 33
  1299:         op.BlocksFree = op.Blocks
  1300:         op.BlocksAvailable = op.Blocks
  1301:
  1302:         // Similarly with inodes.
  1303:         op.Inodes = 1 << 50
  1304:         op.InodesFree = op.Inodes
  1305:
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
=>1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
  1345:
  1346:         return
  1347: }
  1348:
  1349: // LOCKS_EXCLUDED(fs.mu)
  1350: func (fs *fileSystem) GetInodeAttributes(
  1351:         ctx context.Context,
  1352:         op *fuseops.GetInodeAttributesOp) (err error) {
  1353:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1354:                 // When ignore interrupts config is set, we are creating a new context not
  1355:                 // cancellable by parent context.
  1356:                 var cancel context.CancelFunc
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1327 (PC: 0x1968bc1)
  1297:         op.BlockSize = 1 << 17
  1298:         op.Blocks = 1 << 33
  1299:         op.BlocksFree = op.Blocks
  1300:         op.BlocksAvailable = op.Blocks
  1301:
  1302:         // Similarly with inodes.
  1303:         op.Inodes = 1 << 50
  1304:         op.InodesFree = op.Inodes
  1305:
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
=>1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
  1345:
  1346:         return
  1347: }
  1348:
  1349: // LOCKS_EXCLUDED(fs.mu)
  1350: func (fs *fileSystem) GetInodeAttributes(
  1351:         ctx context.Context,
  1352:         op *fuseops.GetInodeAttributesOp) (err error) {
  1353:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1354:                 // When ignore interrupts config is set, we are creating a new context not
  1355:                 // cancellable by parent context.
  1356:                 var cancel context.CancelFunc
  1357:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1330 (PC: 0x1968bde)
  1300:         op.BlocksAvailable = op.Blocks
  1301:
  1302:         // Similarly with inodes.
  1303:         op.Inodes = 1 << 50
  1304:         op.InodesFree = op.Inodes
  1305:
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
  1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
=>1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
  1345:
  1346:         return
  1347: }
  1348:
  1349: // LOCKS_EXCLUDED(fs.mu)
  1350: func (fs *fileSystem) GetInodeAttributes(
  1351:         ctx context.Context,
  1352:         op *fuseops.GetInodeAttributesOp) (err error) {
  1353:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1354:                 // When ignore interrupts config is set, we are creating a new context not
  1355:                 // cancellable by parent context.
  1356:                 var cancel context.CancelFunc
  1357:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1358:                 defer cancel()
  1359:         }
  1360:         // Find the inode.
(dlv) s
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).lookUpOrCreateChildInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:911 (PC: 0x1965976)
   881:                         existingInode.Unlock()
   882:                         return
   883:                 }
   884:
   885:                 // The backing object is newer than the existing inode, while
   886:                 // holding the inode lock, excluding concurrent actions by the inode (in
   887:                 // particular concurrent calls to Sync, which changes generation numbers).
   888:                 // This means we've proven that the record cannot have been caused by the
   889:                 // inode's actions, and therefore this is not the inode we want.
   890:                 //
   891:                 // Replace it with a newly-mintend inode and then go around, acquiring its
   892:                 // lock in accordance with our lock ordering rules.
   893:                 existingInode.Unlock()
   894:
   895:                 in = fs.mintInode(ic)
   896:                 fs.generationBackedInodes[in.Name()] = in.(inode.GenerationBackedInode)
   897:
   898:                 continue
   899:         }
   900: }
   901:
   902: // Look up the child with the given name within the parent, then return an
   903: // existing inode for that child or create a new one if necessary. Return
   904: // ENOENT if the child doesn't exist.
   905: //
   906: // Return the child locked, incrementing its lookup count.
   907: //
   908: // LOCKS_EXCLUDED(fs.mu)
   909: // LOCKS_EXCLUDED(parent)
   910: // LOCK_FUNCTION(child)
=> 911: func (fs *fileSystem) lookUpOrCreateChildInode(
   912:         ctx context.Context,
   913:         parent inode.DirInode,
   914:         childName string) (child inode.Inode, err error) {
   915:         // First check if the requested child is a localFileInode.
   916:         child = fs.lookUpLocalFileInode(parent, childName)
   917:         if child != nil {
   918:                 return
   919:         }
   920:
   921:         // If the requested child is not a localFileInode, continue with the existing
   922:         // flow of checking GCS for file/directory.
   923:
   924:         // Set up a function that will find a lookup result for the child with the
   925:         // given name. Expects no locks to be held.
   926:         getLookupResult := func() (*inode.Core, error) {
   927:                 parent.Lock()
   928:                 defer parent.Unlock()
   929:                 return parent.LookUpChild(ctx, childName)
   930:         }
   931:
   932:         // Run a retry loop around lookUpOrCreateInodeIfNotStale.
   933:         const maxTries = 3
   934:         for n := 0; n < maxTries; n++ {
   935:                 // Create a record.
   936:                 var core *inode.Core
   937:                 core, err = getLookupResult()
   938:
   939:                 if err != nil {
   940:                         return
   941:                 }
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:324 (hits goroutine(304):1 total:2) (PC: 0x18ef5c5)
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
   323:         listing = &list
=> 324:         return
   325: }
   326:
   327: func (b *bucketHandle) UpdateObject(ctx context.Context, req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   328:         obj := b.bucket.Object(req.Name)
   329:
   330:         if req.Generation != 0 {
   331:                 obj = obj.Generation(req.Generation)
   332:         }
   333:
   334:         if req.MetaGenerationPrecondition != nil {
   335:                 obj = obj.If(storage.Conditions{MetagenerationMatch: *req.MetaGenerationPrecondition})
   336:         }
   337:
   338:         updateQuery := storage.ObjectAttrsToUpdate{}
   339:
   340:         if req.ContentType != nil {
   341:                 updateQuery.ContentType = *req.ContentType
   342:         }
   343:
   344:         if req.ContentEncoding != nil {
   345:                 updateQuery.ContentEncoding = *req.ContentEncoding
   346:         }
   347:
   348:         if req.ContentLanguage != nil {
   349:                 updateQuery.ContentLanguage = *req.ContentLanguage
   350:         }
   351:
   352:         if req.CacheControl != nil {
   353:                 updateQuery.CacheControl = *req.CacheControl
   354:         }
(dlv) p listing
("*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing")(0xc000acc180)
*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing {
        Objects: []*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object len: 0, cap: 0, nil,
        CollapsedRuns: []string len: 0, cap: 0, nil,
        ContinuationToken: "",}
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314 (hits goroutine(370):1 total:2) (PC: 0x1968a36)
  1284: func (fs *fileSystem) Destroy() {
  1285:         fs.bucketManager.ShutDown()
  1286:         if fs.fileCacheHandler != nil {
  1287:                 _ = fs.fileCacheHandler.Destroy()
  1288:         }
  1289: }
  1290:
  1291: func (fs *fileSystem) StatFS(
  1292:         ctx context.Context,
  1293:         op *fuseops.StatFSOp) (err error) {
  1294:         // Simulate a large amount of free space so that the Finder doesn't refuse to
  1295:         // copy in files. (See issue #125.) Use 2^17 as the block size because that
  1296:         // is the largest that OS X will pass on.
  1297:         op.BlockSize = 1 << 17
  1298:         op.Blocks = 1 << 33
  1299:         op.BlocksFree = op.Blocks
  1300:         op.BlocksAvailable = op.Blocks
  1301:
  1302:         // Similarly with inodes.
  1303:         op.Inodes = 1 << 50
  1304:         op.InodesFree = op.Inodes
  1305:
  1306:         // Prefer large transfers. This is the largest value that OS X will
  1307:         // faithfully pass on, according to fuseops/ops.go.
  1308:         op.IoSize = 1 << 20
  1309:
  1310:         return
  1311: }
  1312:
  1313: // LOCKS_EXCLUDED(fs.mu)
=>1314: func (fs *fileSystem) LookUpInode(
  1315:         ctx context.Context,
  1316:         op *fuseops.LookUpInodeOp) (err error) {
  1317:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  1318:                 // When ignore interrupts config is set, we are creating a new context not
  1319:                 // cancellable by parent context.
  1320:                 var cancel context.CancelFunc
  1321:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  1322:                 defer cancel()
  1323:         }
  1324:         // Find the parent directory in question.
  1325:         fs.mu.Lock()
  1326:         parent := fs.dirInodeOrDie(op.Parent)
  1327:         fs.mu.Unlock()
  1328:
  1329:         // Find or create the child inode.
  1330:         child, err := fs.lookUpOrCreateChildInode(ctx, parent, op.Name)
  1331:         if err != nil {
  1332:                 return err
  1333:         }
  1334:
  1335:         defer fs.unlockAndMaybeDisposeOfInode(child, &err)
  1336:
  1337:         // Fill out the response.
  1338:         e := &op.Entry
  1339:         e.Child = child.ID()
  1340:         e.Attributes, e.AttributesExpiration, err = fs.getAttributes(ctx, child)
  1341:
  1342:         if err != nil {
  1343:                 return err
  1344:         }
(dlv) p op
("*github.com/jacobsa/fuse/fuseops.LookUpInodeOp")(0xc0001b81e0)
*github.com/jacobsa/fuse/fuseops.LookUpInodeOp {
        Parent: 1,
        Name: "a",
        Entry: github.com/jacobsa/fuse/fuseops.ChildInodeEntry {
                Child: 0,
                Generation: 0,
                Attributes: (*"github.com/jacobsa/fuse/fuseops.InodeAttributes")(0xc0001b8208),
                AttributesExpiration: (*time.Time)(0xc0001b8288),
                EntryExpiration: (*time.Time)(0xc0001b82a0),},
        OpContext: github.com/jacobsa/fuse/fuseops.OpContext {FuseID: 402, Pid: 1612448, Uid: 1012083},}
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:302 (hits goroutine(361):1 total:1) (PC: 0x18ef3ab)
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("Error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 // Do not list unsupported directories such as '.', '..',
   285:                                 // '/', and '\0' as prefixes, which become implicit directories,
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
   292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
=> 302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
   323:         listing = &list
   324:         return
   325: }
   326:
   327: func (b *bucketHandle) UpdateObject(ctx context.Context, req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   328:         obj := b.bucket.Object(req.Name)
   329:
   330:         if req.Generation != 0 {
   331:                 obj = obj.Generation(req.Generation)
   332:         }
(dlv) p attrs.Name  
"a/../8"
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306 (hits goroutine(361):1 total:2) (PC: 0x18ef473)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 // Do not list unsupported directories such as '.', '..',
   285:                                 // '/', and '\0' as prefixes, which become implicit directories,
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
   292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
=> 306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
   323:         listing = &list
   324:         return
   325: }
   326:
   327: func (b *bucketHandle) UpdateObject(ctx context.Context, req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   328:         obj := b.bucket.Object(req.Name)
   329:
   330:         if req.Generation != 0 {
   331:                 obj = obj.Generation(req.Generation)
   332:         }
   333:
   334:         if req.MetaGenerationPrecondition != nil {
   335:                 obj = obj.If(storage.Conditions{MetagenerationMatch: *req.MetaGenerationPrecondition})
   336:         }
(dlv) p attrs.Name
"a/../8"
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:324 (hits goroutine(361):1 total:3) (PC: 0x18ef5c5)
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
   323:         listing = &list
=> 324:         return
   325: }
   326:
   327: func (b *bucketHandle) UpdateObject(ctx context.Context, req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   328:         obj := b.bucket.Object(req.Name)
   329:
   330:         if req.Generation != 0 {
   331:                 obj = obj.Generation(req.Generation)
   332:         }
   333:
   334:         if req.MetaGenerationPrecondition != nil {
   335:                 obj = obj.If(storage.Conditions{MetagenerationMatch: *req.MetaGenerationPrecondition})
   336:         }
   337:
   338:         updateQuery := storage.ObjectAttrsToUpdate{}
   339:
   340:         if req.ContentType != nil {
   341:                 updateQuery.ContentType = *req.ContentType
   342:         }
   343:
   344:         if req.ContentEncoding != nil {
   345:                 updateQuery.ContentEncoding = *req.ContentEncoding
   346:         }
   347:
   348:         if req.ContentLanguage != nil {
   349:                 updateQuery.ContentLanguage = *req.ContentLanguage
   350:         }
   351:
   352:         if req.CacheControl != nil {
   353:                 updateQuery.CacheControl = *req.CacheControl
   354:         }
(dlv) 
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148 (hits goroutine(362):1 total:2) (PC: 0x1972776)
  2118:         if err := fs.invalidateChildFileCacheIfExist(parent, fileName.GcsObjectName()); err != nil {
  2119:                 return fmt.Errorf("Unlink: while invalidating cache for delete file: %w", err)
  2120:         }
  2121:
  2122:         return
  2123: }
  2124:
  2125: // LOCKS_EXCLUDED(fs.mu)
  2126: func (fs *fileSystem) OpenDir(
  2127:         ctx context.Context,
  2128:         op *fuseops.OpenDirOp) (err error) {
  2129:         fs.mu.Lock()
  2130:         defer fs.mu.Unlock()
  2131:
  2132:         // Make sure the inode still exists and is a directory. If not, something has
  2133:         // screwed up because the VFS layer shouldn't have let us forget the inode
  2134:         // before opening it.
  2135:         in := fs.dirInodeOrDie(op.Inode)
  2136:
  2137:         // Allocate a handle.
  2138:         handleID := fs.nextHandleID
  2139:         fs.nextHandleID++
  2140:
  2141:         fs.handles[handleID] = handle.NewDirHandle(in, fs.implicitDirs)
  2142:         op.Handle = handleID
  2143:
  2144:         return
  2145: }
  2146:
  2147: // LOCKS_EXCLUDED(fs.mu)
=>2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
  2150:         op *fuseops.ReadDirOp) (err error) {
  2151:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  2152:                 // When ignore interrupts config is set, we are creating a new context not
  2153:                 // cancellable by parent context.
  2154:                 var cancel context.CancelFunc
  2155:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  2156:                 defer cancel()
  2157:         }
  2158:         // Find the handle.
  2159:         fs.mu.Lock()
  2160:         dh := fs.handles[op.Handle].(*handle.DirHandle)
  2161:         in := fs.dirInodeOrDie(op.Inode)
  2162:         // Fetch local file entries beforehand and pass it to directory handle as
  2163:         // we need fs lock to fetch local file entries.
  2164:         localFileEntries := in.LocalFileEntries(fs.localFileInodes)
  2165:         fs.mu.Unlock()
  2166:
  2167:         dh.Mu.Lock()
  2168:         defer dh.Mu.Unlock()
  2169:         // Serve the request.
  2170:         if err := dh.ReadDir(ctx, op, localFileEntries); err != nil {
  2171:                 return err
  2172:         }
  2173:
  2174:         return
  2175: }
  2176:
  2177: // LOCKS_EXCLUDED(fs.mu)
  2178: func (fs *fileSystem) ReleaseDirHandle(
(dlv) p op
("*github.com/jacobsa/fuse/fuseops.ReadDirOp")(0xc000b84a50)
*github.com/jacobsa/fuse/fuseops.ReadDirOp {
        Inode: 1,
        Handle: 26,
        Offset: 2,
        Dst: []uint8 len: 4096, cap: 4096, [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...+4032 more],
        BytesRead: 0,
        OpContext: github.com/jacobsa/fuse/fuseops.OpContext {FuseID: 406, Pid: 1612448, Uid: 1012083},}
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148 (hits goroutine(385):1 total:3) (PC: 0x1972776)
  2118:         if err := fs.invalidateChildFileCacheIfExist(parent, fileName.GcsObjectName()); err != nil {
  2119:                 return fmt.Errorf("Unlink: while invalidating cache for delete file: %w", err)
  2120:         }
  2121:
  2122:         return
  2123: }
  2124:
  2125: // LOCKS_EXCLUDED(fs.mu)
  2126: func (fs *fileSystem) OpenDir(
  2127:         ctx context.Context,
  2128:         op *fuseops.OpenDirOp) (err error) {
  2129:         fs.mu.Lock()
  2130:         defer fs.mu.Unlock()
  2131:
  2132:         // Make sure the inode still exists and is a directory. If not, something has
  2133:         // screwed up because the VFS layer shouldn't have let us forget the inode
  2134:         // before opening it.
  2135:         in := fs.dirInodeOrDie(op.Inode)
  2136:
  2137:         // Allocate a handle.
  2138:         handleID := fs.nextHandleID
  2139:         fs.nextHandleID++
  2140:
  2141:         fs.handles[handleID] = handle.NewDirHandle(in, fs.implicitDirs)
  2142:         op.Handle = handleID
  2143:
  2144:         return
  2145: }
  2146:
  2147: // LOCKS_EXCLUDED(fs.mu)
=>2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
  2150:         op *fuseops.ReadDirOp) (err error) {
  2151:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  2152:                 // When ignore interrupts config is set, we are creating a new context not
  2153:                 // cancellable by parent context.
  2154:                 var cancel context.CancelFunc
  2155:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  2156:                 defer cancel()
  2157:         }
  2158:         // Find the handle.
  2159:         fs.mu.Lock()
  2160:         dh := fs.handles[op.Handle].(*handle.DirHandle)
  2161:         in := fs.dirInodeOrDie(op.Inode)
  2162:         // Fetch local file entries beforehand and pass it to directory handle as
  2163:         // we need fs lock to fetch local file entries.
  2164:         localFileEntries := in.LocalFileEntries(fs.localFileInodes)
  2165:         fs.mu.Unlock()
  2166:
  2167:         dh.Mu.Lock()
  2168:         defer dh.Mu.Unlock()
  2169:         // Serve the request.
  2170:         if err := dh.ReadDir(ctx, op, localFileEntries); err != nil {
  2171:                 return err
  2172:         }
  2173:
  2174:         return
  2175: }
  2176:
  2177: // LOCKS_EXCLUDED(fs.mu)
  2178: func (fs *fileSystem) ReleaseDirHandle(
(dlv) q
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ fusermount -uz $mountpath ; ./creationSituation.sh 1      
+ echo Number of args: 1
Number of args: 1
+ debug=0
+ run=1
+ '[' 1 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 1 -gt 1 ']'
+ '[' 0 -ne 0 ']'
+ echo 'Running ...'
Running ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 0 = 0 ']'
+ go run /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse --config-file=config.yml --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
{"timestamp":{"seconds":1715198368,"nanos":928283770},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
time="08/05/2024 07:59:28.929143" severity=INFO message="Start gcsfuse/unknown (Go version go1.23-20240419-RC02 cl/626470163 +7f76c00fc5 X:fieldtrack,boringcrypto) for app \"\" using mount point: /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4\n"
time="08/05/2024 07:59:29.057342" severity=INFO message="File system has been successfully mounted."
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issu
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ fusermount -uz $mountpath ; ./creationSituation.sh 1      
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ echo Number of args: 1
Number of args: 1
+ debug=0
+ run=1
+ '[' 1 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 1 -gt 1 ']'
+ '[' 0 -ne 0 ']'
+ echo 'Running ...'
Running ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 0 = 0 ']'
+ go run /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse --config-file=config.yml --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
{"timestamp":{"seconds":1715228708,"nanos":738556791},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
time="09/05/2024 04:25:08.739046" severity=INFO message="Start gcsfuse/unknown (Go version go1.23-20240419-RC02 cl/626470163 +7f76c00fc5 X:fieldtrack,boringcrypto) for app \"\" using mount point: /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4\n"
time="09/05/2024 04:25:08.880079" severity=INFO message="File system has been successfully mounted."
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ ls -l $mountpath
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ fusermount -uz $mountpath ; ./creationSituation.sh 1 debug
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ echo Number of args: 2
Number of args: 2
+ debug=0
+ run=1
+ '[' 2 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 2 -gt 1 ']'
+ debug=1
+ '[' 1 -ne 0 ']'
+ echo 'Debugging ...'
Debugging ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 1 = 0 ']'
+ dlv debug --check-go-version=false /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/. -- --config-file=config.yml --foreground --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
WARNING: undefined behavior - Go version go0.0 is too old for this version of Delve (minimum supported version 1.19)
Type 'help' for list of commands.
(dlv) r
Process restarted with PID 1791672
(dlv) c
{"timestamp":{"seconds":1715229066,"nanos":514990663},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x483b03)
Warning: debugging optimized function
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
(dlv) config source-list-line-count 30
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:292
Breakpoint 1 set at 0x18ef1ca for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:292
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:294
Breakpoint 2 set at 0x18ef299 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:294
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:302
Breakpoint 3 set at 0x18ef3ab for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:302
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306
Breakpoint 4 set at 0x18ef473 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode
Breakpoint 5 set at 0x1968a36 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir
Breakpoint 6 set at 0x1972776 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148 (hits goroutine(103):1 total:1) (PC: 0x1972776)
  2118:         if err := fs.invalidateChildFileCacheIfExist(parent, fileName.GcsObjectName()); err != nil {
  2119:                 return fmt.Errorf("Unlink: while invalidating cache for delete file: %w", err)
  2120:         }
  2121:
  2122:         return
  2123: }
  2124:
  2125: // LOCKS_EXCLUDED(fs.mu)
  2126: func (fs *fileSystem) OpenDir(
  2127:         ctx context.Context,
  2128:         op *fuseops.OpenDirOp) (err error) {
  2129:         fs.mu.Lock()
  2130:         defer fs.mu.Unlock()
  2131:
  2132:         // Make sure the inode still exists and is a directory. If not, something has
  2133:         // screwed up because the VFS layer shouldn't have let us forget the inode
  2134:         // before opening it.
  2135:         in := fs.dirInodeOrDie(op.Inode)
  2136:
  2137:         // Allocate a handle.
  2138:         handleID := fs.nextHandleID
  2139:         fs.nextHandleID++
  2140:
  2141:         fs.handles[handleID] = handle.NewDirHandle(in, fs.implicitDirs)
  2142:         op.Handle = handleID
  2143:
  2144:         return
  2145: }
  2146:
  2147: // LOCKS_EXCLUDED(fs.mu)
=>2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
  2150:         op *fuseops.ReadDirOp) (err error) {
  2151:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  2152:                 // When ignore interrupts config is set, we are creating a new context not
  2153:                 // cancellable by parent context.
  2154:                 var cancel context.CancelFunc
  2155:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  2156:                 defer cancel()
  2157:         }
  2158:         // Find the handle.
  2159:         fs.mu.Lock()
  2160:         dh := fs.handles[op.Handle].(*handle.DirHandle)
  2161:         in := fs.dirInodeOrDie(op.Inode)
  2162:         // Fetch local file entries beforehand and pass it to directory handle as
  2163:         // we need fs lock to fetch local file entries.
  2164:         localFileEntries := in.LocalFileEntries(fs.localFileInodes)
  2165:         fs.mu.Unlock()
  2166:
  2167:         dh.Mu.Lock()
  2168:         defer dh.Mu.Unlock()
  2169:         // Serve the request.
  2170:         if err := dh.ReadDir(ctx, op, localFileEntries); err != nil {
  2171:                 return err
  2172:         }
  2173:
  2174:         return
  2175: }
  2176:
  2177: // LOCKS_EXCLUDED(fs.mu)
  2178: func (fs *fileSystem) ReleaseDirHandle(
(dlv) l
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148 (hits goroutine(103):1 total:1) (PC: 0x1972776)
  2118:         if err := fs.invalidateChildFileCacheIfExist(parent, fileName.GcsObjectName()); err != nil {
  2119:                 return fmt.Errorf("Unlink: while invalidating cache for delete file: %w", err)
  2120:         }
  2121:
  2122:         return
  2123: }
  2124:
  2125: // LOCKS_EXCLUDED(fs.mu)
  2126: func (fs *fileSystem) OpenDir(
  2127:         ctx context.Context,
  2128:         op *fuseops.OpenDirOp) (err error) {
  2129:         fs.mu.Lock()
  2130:         defer fs.mu.Unlock()
  2131:
  2132:         // Make sure the inode still exists and is a directory. If not, something has
  2133:         // screwed up because the VFS layer shouldn't have let us forget the inode
  2134:         // before opening it.
  2135:         in := fs.dirInodeOrDie(op.Inode)
  2136:
  2137:         // Allocate a handle.
  2138:         handleID := fs.nextHandleID
  2139:         fs.nextHandleID++
  2140:
  2141:         fs.handles[handleID] = handle.NewDirHandle(in, fs.implicitDirs)
  2142:         op.Handle = handleID
  2143:
  2144:         return
  2145: }
  2146:
  2147: // LOCKS_EXCLUDED(fs.mu)
=>2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
  2150:         op *fuseops.ReadDirOp) (err error) {
  2151:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  2152:                 // When ignore interrupts config is set, we are creating a new context not
  2153:                 // cancellable by parent context.
  2154:                 var cancel context.CancelFunc
  2155:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  2156:                 defer cancel()
  2157:         }
  2158:         // Find the handle.
  2159:         fs.mu.Lock()
  2160:         dh := fs.handles[op.Handle].(*handle.DirHandle)
  2161:         in := fs.dirInodeOrDie(op.Inode)
  2162:         // Fetch local file entries beforehand and pass it to directory handle as
  2163:         // we need fs lock to fetch local file entries.
  2164:         localFileEntries := in.LocalFileEntries(fs.localFileInodes)
  2165:         fs.mu.Unlock()
  2166:
  2167:         dh.Mu.Lock()
  2168:         defer dh.Mu.Unlock()
  2169:         // Serve the request.
  2170:         if err := dh.ReadDir(ctx, op, localFileEntries); err != nil {
  2171:                 return err
  2172:         }
  2173:
  2174:         return
  2175: }
  2176:
  2177: // LOCKS_EXCLUDED(fs.mu)
  2178: func (fs *fileSystem) ReleaseDirHandle(
(dlv) p op
("*github.com/jacobsa/fuse/fuseops.ReadDirOp")(0xc0008bcf00)
*github.com/jacobsa/fuse/fuseops.ReadDirOp {
        Inode: 1,
        Handle: 0,
        Offset: 0,
        Dst: []uint8 len: 4096, cap: 4096, [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...+4032 more],
        BytesRead: 0,
        OpContext: github.com/jacobsa/fuse/fuseops.OpContext {FuseID: 12, Pid: 1792451, Uid: 1012083},}
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:292 (hits goroutine(103):1 total:1) (PC: 0x18ef1ca)
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("Error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 // Do not list unsupported directories such as '.', '..',
   285:                                 // '/', and '\0' as prefixes, which become implicit directories,
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
=> 292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
(dlv) p attrs.Prefix
"/"
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:324
Breakpoint 7 set at 0x18ef5c5 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:324
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:324 (hits goroutine(103):1 total:1) (PC: 0x18ef5c5)
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
   323:         listing = &list
=> 324:         return
   325: }
   326:
   327: func (b *bucketHandle) UpdateObject(ctx context.Context, req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   328:         obj := b.bucket.Object(req.Name)
   329:
   330:         if req.Generation != 0 {
   331:                 obj = obj.Generation(req.Generation)
   332:         }
   333:
   334:         if req.MetaGenerationPrecondition != nil {
   335:                 obj = obj.If(storage.Conditions{MetagenerationMatch: *req.MetaGenerationPrecondition})
   336:         }
   337:
   338:         updateQuery := storage.ObjectAttrsToUpdate{}
   339:
   340:         if req.ContentType != nil {
   341:                 updateQuery.ContentType = *req.ContentType
   342:         }
   343:
   344:         if req.ContentEncoding != nil {
   345:                 updateQuery.ContentEncoding = *req.ContentEncoding
   346:         }
   347:
   348:         if req.ContentLanguage != nil {
   349:                 updateQuery.ContentLanguage = *req.ContentLanguage
   350:         }
   351:
   352:         if req.CacheControl != nil {
   353:                 updateQuery.CacheControl = *req.CacheControl
   354:         }
(dlv) p listing
("*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing")(0xc000ac6640)
*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing {
        Objects: []*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object len: 0, cap: 0, nil,
        CollapsedRuns: []string len: 0, cap: 0, nil,
        ContinuationToken: "",}
(dlv) c
received SIGINT, stopping process (will not forward signal)
> internal/runtime/syscall.Syscall6() /usr/lib/google-golang/src/internal/runtime/syscall/asm_linux_amd64.s:36 (PC: 0x488fce)
Warning: debugging optimized function
     6:
     7: // func Syscall6(num, a1, a2, a3, a4, a5, a6 uintptr) (r1, r2, errno uintptr)
     8: //
     9: // We need to convert to the syscall ABI.
    10: //
    11: // arg | ABIInternal | Syscall
    12: // ---------------------------
    13: // num | AX          | AX
    14: // a1  | BX          | DI
    15: // a2  | CX          | SI
    16: // a3  | DI          | DX
    17: // a4  | SI          | R10
    18: // a5  | R8          | R8
    19: // a6  | R9          | R9
    20: //
    21: // r1  | AX          | AX
    22: // r2  | BX          | DX
    23: // err | CX          | part of AX
    24: //
    25: // Note that this differs from "standard" ABI convention, which would pass 4th
    26: // arg in CX, not R10.
    27: TEXT ·Syscall6<ABIInternal>(SB),NOSPLIT,$0
    28:         // a6 already in R9.
    29:         // a5 already in R8.
    30:         MOVQ    SI, R10 // a4
    31:         MOVQ    DI, DX  // a3
    32:         MOVQ    CX, SI  // a2
    33:         MOVQ    BX, DI  // a1
    34:         // num already in AX.
    35:         SYSCALL
=>  36:         CMPQ    AX, $0xfffffffffffff001
    37:         JLS     ok
    38:         NEGQ    AX
    39:         MOVQ    AX, CX  // errno
    40:         MOVQ    $-1, AX // r1
    41:         MOVQ    $0, BX  // r2
    42:         RET
    43: ok:
    44:         // r1 already in AX.
    45:         MOVQ    DX, BX // r2
    46:         MOVQ    $0, CX // errno
    47:         RET
(dlv) q
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ fusermount -uz $mountpath ; ./creationSituation.sh 1 debug
+ echo Number of args: 2
Number of args: 2
+ debug=0
+ run=1
+ '[' 2 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 2 -gt 1 ']'
+ debug=1
+ '[' 1 -ne 0 ']'
+ echo 'Debugging ...'
Debugging ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 1 = 0 ']'
+ dlv debug --check-go-version=false /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/. -- --config-file=config.yml --foreground --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
WARNING: undefined behavior - Go version go0.0 is too old for this version of Delve (minimum supported version 1.19)
Type 'help' for list of commands.
(dlv) c
{"timestamp":{"seconds":1715230091,"nanos":799607038},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x483b03)
Warning: debugging optimized function
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
(dlv) q
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ fusermount -uz $mountpath ; ./creationSituation.sh 1 debug
+ echo Number of args: 2
Number of args: 2
+ debug=0
+ run=1
+ '[' 2 -gt 0 ']'
+ '[' 1 = 2 ']'
+ '[' 2 -gt 1 ']'
+ debug=1
+ '[' 1 -ne 0 ']'
+ echo 'Debugging ...'
Debugging ...
+ '[' 1 -gt 1 ']'
+ echo 'fix branch (1) ...'
fix branch (1) ...
+ bucket=gargnitin-test-empty-dirname-asia-se1
+ filename=hello.txt
+ gcspath=gs://gargnitin-test-empty-dirname-asia-se1//hello.txt
+ '[' 1 -gt 1 ']'
+ mountpath=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ logfile=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log
+ gcsfuse_src_dir=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse
+ mkdir -pv /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
+ echo ''
+ fusermount -uz /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
fusermount: entry for /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4 not found in /etc/mtab
+ true
+ '[' 1 = 0 ']'
+ dlv debug --check-go-version=false /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/. -- --config-file=config.yml --foreground --implicit-dirs --log-file=/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1.log --log-format=text gargnitin-test-empty-dirname-asia-se1 /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/test_buckets/gargnitin-test-empty-dirname-asia-se1-mount4
WARNING: undefined behavior - Go version go0.0 is too old for this version of Delve (minimum supported version 1.19)
Type 'help' for list of commands.
(dlv) r
Process restarted with PID 1808420
(dlv) c
{"timestamp":{"seconds":1715230177,"nanos":333861829},"severity":"INFO","message":"Value of [config-file] resolved from [config.yml] to [/usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch/config.yml]\n"}
received SIGINT, stopping process (will not forward signal)
> runtime.futex() /usr/lib/google-golang/src/runtime/sys_linux_amd64.s:559 (PC: 0x483b03)
Warning: debugging optimized function
   554:         MOVQ    ts+16(FP), R10
   555:         MOVQ    addr2+24(FP), R8
   556:         MOVL    val3+32(FP), R9
   557:         MOVL    $SYS_futex, AX
   558:         SYSCALL
=> 559:         MOVL    AX, ret+40(FP)
   560:         RET
   561:
   562: // int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
   563: TEXT runtime·clone(SB),NOSPLIT|NOFRAME,$0
   564:         MOVL    flags+0(FP), DI
(dlv) config source-list-line-count 30
(dlv) 
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:292
Breakpoint 1 set at 0x18ef1ca for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:292
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:294
Breakpoint 2 set at 0x18ef299 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:294
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:302
Breakpoint 3 set at 0x18ef3ab for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:302
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306
Breakpoint 4 set at 0x18ef473 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306
(dlv) 
Command failed: Breakpoint exists at /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:306 at 18ef473
(dlv) # Return
Command failed: command not available
(dlv) b /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:324
Breakpoint 6 set at 0x18ef5c5 for github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:324
(dlv) # fs operations from kernel
Command failed: command not available
(dlv) 
Command failed: command not available
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode
Breakpoint 7 set at 0x1968a36 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).LookUpInode() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:1314
(dlv) b github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir
Breakpoint 8 set at 0x1972776 for github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/fs.(*fileSystem).ReadDir() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/fs/fs.go:2148 (hits goroutine(127):1 total:1) (PC: 0x1972776)
  2118:         if err := fs.invalidateChildFileCacheIfExist(parent, fileName.GcsObjectName()); err != nil {
  2119:                 return fmt.Errorf("Unlink: while invalidating cache for delete file: %w", err)
  2120:         }
  2121:
  2122:         return
  2123: }
  2124:
  2125: // LOCKS_EXCLUDED(fs.mu)
  2126: func (fs *fileSystem) OpenDir(
  2127:         ctx context.Context,
  2128:         op *fuseops.OpenDirOp) (err error) {
  2129:         fs.mu.Lock()
  2130:         defer fs.mu.Unlock()
  2131:
  2132:         // Make sure the inode still exists and is a directory. If not, something has
  2133:         // screwed up because the VFS layer shouldn't have let us forget the inode
  2134:         // before opening it.
  2135:         in := fs.dirInodeOrDie(op.Inode)
  2136:
  2137:         // Allocate a handle.
  2138:         handleID := fs.nextHandleID
  2139:         fs.nextHandleID++
  2140:
  2141:         fs.handles[handleID] = handle.NewDirHandle(in, fs.implicitDirs)
  2142:         op.Handle = handleID
  2143:
  2144:         return
  2145: }
  2146:
  2147: // LOCKS_EXCLUDED(fs.mu)
=>2148: func (fs *fileSystem) ReadDir(
  2149:         ctx context.Context,
  2150:         op *fuseops.ReadDirOp) (err error) {
  2151:         if fs.mountConfig.FileSystemConfig.IgnoreInterrupts {
  2152:                 // When ignore interrupts config is set, we are creating a new context not
  2153:                 // cancellable by parent context.
  2154:                 var cancel context.CancelFunc
  2155:                 ctx, cancel = util.IsolateContextFromParentContext(ctx)
  2156:                 defer cancel()
  2157:         }
  2158:         // Find the handle.
  2159:         fs.mu.Lock()
  2160:         dh := fs.handles[op.Handle].(*handle.DirHandle)
  2161:         in := fs.dirInodeOrDie(op.Inode)
  2162:         // Fetch local file entries beforehand and pass it to directory handle as
  2163:         // we need fs lock to fetch local file entries.
  2164:         localFileEntries := in.LocalFileEntries(fs.localFileInodes)
  2165:         fs.mu.Unlock()
  2166:
  2167:         dh.Mu.Lock()
  2168:         defer dh.Mu.Unlock()
  2169:         // Serve the request.
  2170:         if err := dh.ReadDir(ctx, op, localFileEntries); err != nil {
  2171:                 return err
  2172:         }
  2173:
  2174:         return
  2175: }
  2176:
  2177: // LOCKS_EXCLUDED(fs.mu)
  2178: func (fs *fileSystem) ReleaseDirHandle(
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:292 (hits goroutine(127):1 total:1) (PC: 0x18ef1ca)
   262:         pi.Token = req.ContinuationToken
   263:         var list gcs.Listing
   264:
   265:         // Iterating through all the objects in the bucket and one by one adding them to the list.
   266:         for {
   267:                 var attrs *storage.ObjectAttrs
   268:
   269:                 attrs, err = itr.Next()
   270:                 if err == iterator.Done {
   271:                         err = nil
   272:                         break
   273:                 }
   274:                 if err != nil {
   275:                         err = fmt.Errorf("Error in iterating through objects: %w", err)
   276:                         return
   277:                 }
   278:
   279:                 // Prefix attribute will be set for the objects returned as part of Prefix[] array in list response.
   280:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/storage.go#L1304
   281:                 // https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/cloud.google.com/go/storage/http_client.go#L370
   282:                 if attrs.Prefix != "" {
   283:                         if util.IsUnsupportedDirectoryName(attrs.Prefix) {
   284:                                 // Do not list unsupported directories such as '.', '..',
   285:                                 // '/', and '\0' as prefixes, which become implicit directories,
   286:                                 // unless there are explicit GCS objects corresponding to them.
   287:                                 // Unix environments see these directories
   288:                                 // as having special meanings e.g. a/b/../ is treated as a/, similarly,
   289:                                 // a/./ as a/, a//b/ as a/b/. 'a/\00/b' is not a valid substring file/directory
   290:                                 // in any unix file/directory name. GCSFuse simulates the same behvaiour
   291:                                 // by ignoring the GCS objects which have these specially reserved/unsupported unix names/substrings.
=> 292:                                 logger.Warnf("Ignoring unsupported object-prefix: \"%s\"", attrs.Prefix)
   293:                         } else {
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
(dlv) p attrsPrefix
Command failed: could not find symbol value for attrsPrefix
(dlv) p attrs.Prefix
"/"
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:324 (hits goroutine(127):1 total:1) (PC: 0x18ef5c5)
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
   323:         listing = &list
=> 324:         return
   325: }
   326:
   327: func (b *bucketHandle) UpdateObject(ctx context.Context, req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   328:         obj := b.bucket.Object(req.Name)
   329:
   330:         if req.Generation != 0 {
   331:                 obj = obj.Generation(req.Generation)
   332:         }
   333:
   334:         if req.MetaGenerationPrecondition != nil {
   335:                 obj = obj.If(storage.Conditions{MetagenerationMatch: *req.MetaGenerationPrecondition})
   336:         }
   337:
   338:         updateQuery := storage.ObjectAttrsToUpdate{}
   339:
   340:         if req.ContentType != nil {
   341:                 updateQuery.ContentType = *req.ContentType
   342:         }
   343:
   344:         if req.ContentEncoding != nil {
   345:                 updateQuery.ContentEncoding = *req.ContentEncoding
   346:         }
   347:
   348:         if req.ContentLanguage != nil {
   349:                 updateQuery.ContentLanguage = *req.ContentLanguage
   350:         }
   351:
   352:         if req.CacheControl != nil {
   353:                 updateQuery.CacheControl = *req.CacheControl
   354:         }
(dlv) p listing
("*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing")(0xc0002fe4c0)
*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Listing {
        Objects: []*github.com/googlecloudplatform/gcsfuse/v2/internal/storage/gcs.Object len: 0, cap: 0, nil,
        CollapsedRuns: []string len: 0, cap: 0, nil,
        ContinuationToken: "",}
(dlv) c
> github.com/googlecloudplatform/gcsfuse/v2/internal/storage.(*bucketHandle).ListObjects() /usr/local/google/home/gargnitin/work/cloud/storage/client/gcsfuse/src/gcsfuse/internal/storage/bucket_handle.go:324 (hits goroutine(308):1 total:2) (PC: 0x18ef5c5)
   294:                                 list.CollapsedRuns = append(list.CollapsedRuns, attrs.Prefix)
   295:                         }
   296:                 } else {
   297:                         if util.IsUnsupportedObjectName(attrs.Name) {
   298:                                 // For GCS objects, which have the unsupported substrings i.e. //, /./, /../, \0'
   299:                                 // in their names, should be warned against as they can not be properly
   300:                                 // mapped by GCSFuse, as these are either specially reserved/unsupported
   301:                                 // names in unix environments.
   302:                                 logger.Warnf("Encoutered unsupported object-name: \"%s\"", attrs.Name)
   303:                         }
   304:
   305:                         // Converting attrs to *Object type.
   306:                         currObject := storageutil.ObjectAttrsToBucketObject(attrs)
   307:                         list.Objects = append(list.Objects, currObject)
   308:                 }
   309:
   310:                 // itr.next returns all the objects present in the bucket. Hence adding a
   311:                 // check to break after iterating over the current page. pi.Remaining()
   312:                 // function returns number of items (items + prefixes) remaining in current
   313:                 // page to be iterated by iterator (itr). The func returns (number of items in current page - 1)
   314:                 // after first itr.Next() call and becomes 0 when iteration is done.
   315:                 // If req.MaxResults is 0, then wait till iterator is done. This is similar
   316:                 // to https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/vendor/github.com/jacobsa/gcloud/gcs/bucket.go#L164
   317:                 if req.MaxResults != 0 && (pi.Remaining() == 0) {
   318:                         break
   319:                 }
   320:         }
   321:
   322:         list.ContinuationToken = itr.PageInfo().Token
   323:         listing = &list
=> 324:         return
   325: }
   326:
   327: func (b *bucketHandle) UpdateObject(ctx context.Context, req *gcs.UpdateObjectRequest) (o *gcs.Object, err error) {
   328:         obj := b.bucket.Object(req.Name)
   329:
   330:         if req.Generation != 0 {
   331:                 obj = obj.Generation(req.Generation)
   332:         }
   333:
   334:         if req.MetaGenerationPrecondition != nil {
   335:                 obj = obj.If(storage.Conditions{MetagenerationMatch: *req.MetaGenerationPrecondition})
   336:         }
   337:
   338:         updateQuery := storage.ObjectAttrsToUpdate{}
   339:
   340:         if req.ContentType != nil {
   341:                 updateQuery.ContentType = *req.ContentType
   342:         }
   343:
   344:         if req.ContentEncoding != nil {
   345:                 updateQuery.ContentEncoding = *req.ContentEncoding
   346:         }
   347:
   348:         if req.ContentLanguage != nil {
   349:                 updateQuery.ContentLanguage = *req.ContentLanguage
   350:         }
   351:
   352:         if req.CacheControl != nil {
   353:                 updateQuery.CacheControl = *req.CacheControl
   354:         }
(dlv) q
gargnitin@gargnitin:~/work/cloud/storage/client/gcsfuse/tasks/20240429-fix-empty-dirname-issue/fix-branch$ 
